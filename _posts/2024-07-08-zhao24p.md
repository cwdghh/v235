---
title: Gradient-based Visual Explanation for Transformer-based CLIP
openreview: WT4X3QYopC
abstract: 'Significant progress has been achieved on the improvement and downstream
  usages of the Contrastive Language-Image Pre-training (CLIP) vision-language model,
  while less attention is paid to the interpretation of CLIP. We propose a Gradient-based
  visual Explanation method for CLIP (Grad-ECLIP), which interprets the matching result
  of CLIP for specific input image-text pair. By decomposing the architecture of the
  encoder and discovering the relationship between the matching similarity and intermediate
  spatial features, Grad-ECLIP produces effective heat maps that show the influence
  of image regions or words on the CLIP results. Different from the previous Transformer
  interpretation methods that focus on the utilization of self-attention maps, which
  are typically extremely sparse in CLIP, we produce high-quality visual explanations
  by applying channel and spatial weights on token features. Qualitative and quantitative
  evaluations verify the superiority of Grad-ECLIP compared with the state-of-the-art
  methods. A series of analysis are conducted based on our visual explanation results,
  from which we explore the working mechanism of image-text matching, and the strengths
  and limitations in attribution identification of CLIP. Codes are available here:
  https://github.com/Cyang-Zhao/Grad-Eclip.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao24p
month: 0
tex_title: Gradient-based Visual Explanation for Transformer-based {CLIP}
firstpage: 61072
lastpage: 61091
page: 61072-61091
order: 61072
cycles: false
bibtex_author: Zhao, Chenyang and Wang, Kun and Zeng, Xingyu and Zhao, Rui and Chan,
  Antoni B.
author:
- given: Chenyang
  family: Zhao
- given: Kun
  family: Wang
- given: Xingyu
  family: Zeng
- given: Rui
  family: Zhao
- given: Antoni B.
  family: Chan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhao24p/zhao24p.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

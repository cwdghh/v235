---
title: Dealing With Unbounded Gradients in Stochastic Saddle-point Optimization
openreview: RPMTNGMq0O
abstract: We study the performance of stochastic first-order methods for finding saddle
  points of convex-concave functions. A notorious challenge faced by such methods
  is that the gradients can grow arbitrarily large during optimization, which may
  result in instability and divergence. In this paper, we propose a simple and effective
  regularization technique that stabilizes the iterates and yields meaningful performance
  guarantees even if the domain and the gradient noise scales linearly with the size
  of the iterates (and is thus potentially unbounded). Besides providing a set of
  general results, we also apply our algorithm to a specific problem in reinforcement
  learning, where it leads to performance guarantees for finding near-optimal policies
  in an average-reward MDP without prior knowledge of the bias span.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: neu24a
month: 0
tex_title: Dealing With Unbounded Gradients in Stochastic Saddle-point Optimization
firstpage: 37508
lastpage: 37530
page: 37508-37530
order: 37508
cycles: false
bibtex_author: Neu, Gergely and Okolo, Nneka
author:
- given: Gergely
  family: Neu
- given: Nneka
  family: Okolo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/neu24a/neu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

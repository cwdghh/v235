---
title: 'In-Context Sharpness as Alerts: An Inner Representation Perspective for Hallucination
  Mitigation'
openreview: s3e8poX3kb
abstract: 'Large language models (LLMs) frequently hallucinate, e.g., making factual
  errors, yet our understanding of why they make these errors remains limited. In
  this study, we aim to understand the underlying mechanisms of LLM hallucinations
  from the perspective of <em>inner representations</em>. We discover a pattern associated
  with hallucinations: correct generations tend to have <em>sharper</em> context activations
  in the hidden states of the in-context tokens, compared to that of the incorrect
  generations. Leveraging this signal, we propose an entropy-based metric to quantify
  the <em>sharpness</em> among the in-context hidden states and incorporate it into
  the decoding process, i.e, use the entropy value to adjust the next token prediction
  distribution to improve the factuality and overall quality of the generated text.
  Experiments on knowledge-seeking datasets (Natural Questions, HotpotQA, TriviaQA)
  and hallucination benchmark (TruthfulQA) demonstrate our consistent effectiveness,
  e.g., up to 8.6 absolute points on TruthfulQA. We believe this study can improve
  our understanding of hallucinations and serve as a practical solution for hallucination
  mitigation.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24av
month: 0
tex_title: 'In-Context Sharpness as Alerts: An Inner Representation Perspective for
  Hallucination Mitigation'
firstpage: 7553
lastpage: 7567
page: 7553-7567
order: 7553
cycles: false
bibtex_author: Chen, Shiqi and Xiong, Miao and Liu, Junteng and Wu, Zhengxuan and
  Xiao, Teng and Gao, Siyang and He, Junxian
author:
- given: Shiqi
  family: Chen
- given: Miao
  family: Xiong
- given: Junteng
  family: Liu
- given: Zhengxuan
  family: Wu
- given: Teng
  family: Xiao
- given: Siyang
  family: Gao
- given: Junxian
  family: He
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24av/chen24av.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'InferCept: Efficient Intercept Support for Augmented Large Language Model
  Inference'
openreview: wDDGQabYPQ
abstract: Large language models are increasingly integrated with external environments,
  tools, and agents like ChatGPT plugins to extend their capability beyond language-centric
  tasks. However, todayâ€™s LLM inference systems are designed for standalone LLMs.
  They treat each external interaction as the end of LLM generation and form a new
  request when the interaction finishes, causing unnecessary recomputation of already
  computed contexts, which accounts for 37-40% of total model forwarding time. This
  paper presents <b>InferCept, the first LLM inference framework targeting augmented
  LLMs</b> and supporting the efficient interception of LLM generation. InferCept
  minimizes the GPU resource waste caused by LLM interceptions and dedicates saved
  memory for serving more requests.InferCept improves the overall serving throughput
  by <b>1.6x-2x</b> and completes 2x more requests per second compared to the state-of-the-art
  LLM inference systems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: abhyankar24a
month: 0
tex_title: "{I}nfer{C}ept: Efficient Intercept Support for Augmented Large Language
  Model Inference"
firstpage: 81
lastpage: 95
page: 81-95
order: 81
cycles: false
bibtex_author: Abhyankar, Reyna and He, Zijian and Srivatsa, Vikranth and Zhang, Hao
  and Zhang, Yiying
author:
- given: Reyna
  family: Abhyankar
- given: Zijian
  family: He
- given: Vikranth
  family: Srivatsa
- given: Hao
  family: Zhang
- given: Yiying
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/abhyankar24a/abhyankar24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Asymptotics of Learning with Deep Structured (Random) Features
openreview: RI4GA8amUI
abstract: For a large class of feature maps we provide a tight asymptotic characterisation
  of the test error associated with learning the readout layer, in the high-dimensional
  limit where the input dimension, hidden layer widths, and number of training samples
  are proportionally large. This characterization is formulated in terms of the population
  covariance of the features. Our work is partially motivated by the problem of learning
  with Gaussian rainbow neural networks, namely deep non-linear fully-connected networks
  with random but structured weights, whose row-wise covariances are further allowed
  to depend on the weights of previous layers. For such networks we also derive a
  closed-form formula for the feature covariance in terms of the weight matrices.
  We further find that in some cases our results can capture feature maps learned
  by deep, finite-width neural networks trained under gradient descent.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schroder24a
month: 0
tex_title: Asymptotics of Learning with Deep Structured ({R}andom) Features
firstpage: 43862
lastpage: 43894
page: 43862-43894
order: 43862
cycles: false
bibtex_author: Schr\"{o}der, Dominik and Dmitriev, Daniil and Cui, Hugo and Loureiro,
  Bruno
author:
- given: Dominik
  family: Schr√∂der
- given: Daniil
  family: Dmitriev
- given: Hugo
  family: Cui
- given: Bruno
  family: Loureiro
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/schroder24a/schroder24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Principled Penalty-based Methods for Bilevel Reinforcement Learning and RLHF
openreview: Xb3IXEBYuw
abstract: Bilevel optimization has been recently applied to many machine learning
  tasks. However, their applications have been restricted to the supervised learning
  setting, where static objective functions with benign structures are considered.
  But bilevel problems such as incentive design, inverse reinforcement learning (RL),
  and RL from human feedback (RLHF) are often modeled as dynamic objective functions
  that go beyond the simple static objective structures, which pose significant challenges
  of using existing bilevel solutions. To tackle this new class of bilevel problems,
  we introduce the first principled algorithmic framework for solving bilevel RL problems
  through the lens of penalty formulation. We provide theoretical studies of the problem
  landscape and its penalty-based (policy) gradient algorithms. We demonstrate the
  effectiveness of our algorithms via simulations in the Stackelberg game and RLHF.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shen24g
month: 0
tex_title: Principled Penalty-based Methods for Bilevel Reinforcement Learning and
  {RLHF}
firstpage: 44774
lastpage: 44799
page: 44774-44799
order: 44774
cycles: false
bibtex_author: Shen, Han and Yang, Zhuoran and Chen, Tianyi
author:
- given: Han
  family: Shen
- given: Zhuoran
  family: Yang
- given: Tianyi
  family: Chen
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/shen24g/shen24g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: In-Context Learning Agents Are Asymmetric Belief Updaters
openreview: BNAvYSCrLD
abstract: We study the in-context learning dynamics of large language models (LLMs)
  using three instrumental learning tasks adapted from cognitive psychology. We find
  that LLMs update their beliefs in an asymmetric manner and learn more from better-than-expected
  outcomes than from worse-than-expected ones. Furthermore, we show that this effect
  reverses when learning about counterfactual feedback and disappears when no agency
  is implied. We corroborate these findings by investigating idealized in-context
  learning agents derived through meta-reinforcement learning, where we observe similar
  patterns. Taken together, our results contribute to our understanding of how in-context
  learning works by highlighting that the framing of a problem significantly influences
  how learning occurs, a phenomenon also observed in human cognition.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schubert24a
month: 0
tex_title: In-Context Learning Agents Are Asymmetric Belief Updaters
firstpage: 43928
lastpage: 43946
page: 43928-43946
order: 43928
cycles: false
bibtex_author: Schubert, Johannes A. and Jagadish, Akshay Kumar and Binz, Marcel and
  Schulz, Eric
author:
- given: Johannes A.
  family: Schubert
- given: Akshay Kumar
  family: Jagadish
- given: Marcel
  family: Binz
- given: Eric
  family: Schulz
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/schubert24a/schubert24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

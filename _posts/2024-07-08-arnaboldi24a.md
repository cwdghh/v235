---
title: 'Online Learning and Information Exponents: The Importance of Batch size &
  Time/Complexity Tradeoffs'
openreview: ZSQAf5YlvN
abstract: We study the impact of the batch size $n_b$ on the iteration time $T$ of
  training two-layer neural networks with one-pass stochastic gradient descent (SGD)
  on multi-index target functions of isotropic covariates. We characterize the optimal
  batch size minimizing the iteration time as a function of the hardness of the target,
  as characterized by the information exponents. We show that performing gradient
  updates with large batches $n_b \lesssim d^{\frac{\ell}{2}}$ minimizes the training
  time without changing the total sample complexity, where $\ell$ is the information
  exponent of the target to be learned and $d$ is the input dimension. However, larger
  batch sizes than $n_b \gg d^{\frac{\ell}{2}}$ are detrimental for improving the
  time complexity of SGD. We provably overcome this fundamental limitation via a different
  training protocol, <em>Correlation loss SGD</em>, which suppresses the auto-correlation
  terms in the loss function. We show that one can track the training progress by
  a system of low-dimensional ordinary differential equations (ODEs). Finally, we
  validate our theoretical results with numerical experiments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: arnaboldi24a
month: 0
tex_title: 'Online Learning and Information Exponents: The Importance of Batch size
  & {T}ime/{C}omplexity Tradeoffs'
firstpage: 1730
lastpage: 1762
page: 1730-1762
order: 1730
cycles: false
bibtex_author: Arnaboldi, Luca and Dandi, Yatin and Krzakala, Florent and Loureiro,
  Bruno and Pesce, Luca and Stephan, Ludovic
author:
- given: Luca
  family: Arnaboldi
- given: Yatin
  family: Dandi
- given: Florent
  family: Krzakala
- given: Bruno
  family: Loureiro
- given: Luca
  family: Pesce
- given: Ludovic
  family: Stephan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/arnaboldi24a/arnaboldi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

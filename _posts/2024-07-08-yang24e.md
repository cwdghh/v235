---
title: A Dense Reward View on Aligning Text-to-Image Diffusion with Preference
openreview: xVXnXk9I3I
abstract: Aligning text-to-image diffusion model (T2I) with preference has been gaining
  increasing research attention. While prior works exist on directly optimizing T2I
  by preference data, these methods are developed under the bandit assumption of a
  latent reward on the entire diffusion reverse chain, while ignoring the sequential
  nature of the generation process. This may harm the efficacy and efficiency of preference
  alignment. In this paper, we take on a finer dense reward perspective and derive
  a tractable alignment objective that emphasizes the initial steps of the T2I reverse
  chain. In particular, we introduce temporal discounting into DPO-style explicit-reward-free
  objectives, to break the temporal symmetry therein and suit the T2I generation hierarchy.
  In experiments on single and multiple prompt generation, our method is competitive
  with strong relevant baselines, both quantitatively and qualitatively. Further investigations
  are conducted to illustrate the insight of our approach. Source code is available
  at https://github.com/Shentao-YANG/Dense_Reward_T2I .
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang24e
month: 0
tex_title: A Dense Reward View on Aligning Text-to-Image Diffusion with Preference
firstpage: 55998
lastpage: 56032
page: 55998-56032
order: 55998
cycles: false
bibtex_author: Yang, Shentao and Chen, Tianqi and Zhou, Mingyuan
author:
- given: Shentao
  family: Yang
- given: Tianqi
  family: Chen
- given: Mingyuan
  family: Zhou
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/yang24e/yang24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

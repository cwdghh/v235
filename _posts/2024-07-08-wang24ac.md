---
title: 'Learning with Complementary Labels Revisited: The Selected-Completely-at-Random
  Setting Is More Practical'
openreview: ykZYLBcA9g
abstract: Complementary-label learning is a weakly supervised learning problem in
  which each training example is associated with one or multiple complementary labels
  indicating the classes to which it does not belong. Existing consistent approaches
  have relied on the uniform distribution assumption to model the generation of complementary
  labels, or on an ordinary-label training set to estimate the transition matrix in
  non-uniform cases. However, either condition may not be satisfied in real-world
  scenarios. In this paper, we propose a novel consistent approach that does not rely
  on these conditions. Inspired by the positive-unlabeled (PU) learning literature,
  we propose an unbiased risk estimator based on the Selected-Completely-at-Random
  assumption for complementary-label learning. We then introduce a risk-correction
  approach to address overfitting problems. Furthermore, we find that complementary-label
  learning can be expressed as a set of negative-unlabeled binary classification problems
  when using the one-versus-rest strategy. Extensive experimental results on both
  synthetic and real-world benchmark datasets validate the superiority of our proposed
  approach over state-of-the-art methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24ac
month: 0
tex_title: 'Learning with Complementary Labels Revisited: The Selected-Completely-at-Random
  Setting Is More Practical'
firstpage: 50683
lastpage: 50710
page: 50683-50710
order: 50683
cycles: false
bibtex_author: Wang, Wei and Ishida, Takashi and Zhang, Yu-Jie and Niu, Gang and Sugiyama,
  Masashi
author:
- given: Wei
  family: Wang
- given: Takashi
  family: Ishida
- given: Yu-Jie
  family: Zhang
- given: Gang
  family: Niu
- given: Masashi
  family: Sugiyama
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wang24ac/wang24ac.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

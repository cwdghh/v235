---
title: Learning to Route Among Specialized Experts for Zero-Shot Generalization
openreview: r0qcGcFL4U
abstract: Recently, there has been a widespread proliferation of "expert" language
  models that are specialized to a specific task or domain through parameter-efficient
  fine-tuning. How can we recycle large collections of expert language models to improve
  zero-shot generalization to unseen tasks? In this work, we propose $\textbf{P}$ost-$\textbf{H}$oc
  $\textbf{A}$daptive $\textbf{T}$okenwise $\textbf{G}$ating $\textbf{O}$ver an $\textbf{O}$cean
  of $\textbf{S}$pecialized $\textbf{E}$xperts (<b>PHATGOOSE</b>), which learns to
  route among specialized modules that were produced through parameter-efficient fine-tuning.
  Unlike past methods that learn to route among specialized models, PHATGOOSE explores
  the possibility that zero-shot generalization will be improved if different experts
  can be adaptively chosen for each token and at each layer in the model. Crucially,
  our method is <em>post-hoc</em> - it does not require simultaneous access to the
  datasets used to create the specialized models and only requires a modest amount
  of additional compute after each expert model is trained. In experiments covering
  a range of specialized model collections and zero-shot generalization benchmarks,
  we find that PHATGOOSE outperforms past methods for post-hoc routing and, in some
  cases, outperforms explicit multitask training (which requires simultaneous data
  access). To better understand the routing strategy learned by PHATGOOSE, we perform
  qualitative experiments to validate that PHATGOOSEâ€™s performance stems from its
  ability to make adaptive per-token and per-module expert choices.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: muqeeth24a
month: 0
tex_title: Learning to Route Among Specialized Experts for Zero-Shot Generalization
firstpage: 36829
lastpage: 36846
page: 36829-36846
order: 36829
cycles: false
bibtex_author: Muqeeth, Mohammed and Liu, Haokun and Liu, Yufan and Raffel, Colin
author:
- given: Mohammed
  family: Muqeeth
- given: Haokun
  family: Liu
- given: Yufan
  family: Liu
- given: Colin
  family: Raffel
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/muqeeth24a/muqeeth24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Temporal Logic Specification-Conditioned Decision Transformer for Offline Safe
  Reinforcement Learning
openreview: 7bg10Jj3bG
abstract: Offline safe reinforcement learning (RL) aims to train a constraint satisfaction
  policy from a fixed dataset. Current state-of-the-art approaches are based on supervised
  learning with a conditioned policy. However, these approaches fall short in real-world
  applications that involve complex tasks with rich temporal and logical structures.
  In this paper, we propose temporal logic Specification-conditioned Decision Transformer
  (SDT), a novel framework that harnesses the expressive power of signal temporal
  logic (STL) to specify complex temporal rules that an agent should follow and the
  sequential modeling capability of Decision Transformer (DT). Empirical evaluations
  on the DSRL benchmarks demonstrate the better capacity of SDT in learning safe and
  high-reward policies compared with existing approaches. In addition, SDT shows good
  alignment with respect to different desired degrees of satisfaction of the STL specification
  that it is conditioned on.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo24j
month: 0
tex_title: Temporal Logic Specification-Conditioned Decision Transformer for Offline
  Safe Reinforcement Learning
firstpage: 17003
lastpage: 17019
page: 17003-17019
order: 17003
cycles: false
bibtex_author: Guo, Zijian and Zhou, Weichao and Li, Wenchao
author:
- given: Zijian
  family: Guo
- given: Weichao
  family: Zhou
- given: Wenchao
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/guo24j/guo24j.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

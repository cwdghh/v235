---
title: What is Dataset Distillation Learning?
openreview: z8sYc334fU
abstract: Dataset distillation has emerged as a strategy to overcome the hurdles associated
  with large datasets by learning a compact set of synthetic data that retains essential
  information from the original dataset. While distilled data can be used to train
  high performing models, little is understood about how the information is stored.
  In this study, we posit and answer three questions about the behavior, representativeness,
  and point-wise information content of distilled data. We reveal distilled data cannot
  serve as a substitute for real data during training outside the standard evaluation
  setting for dataset distillation. Additionally, the distillation process retains
  high task performance by compressing information related to the early training dynamics
  of real models. Finally, we provide an framework for interpreting distilled data
  and reveal that individual distilled data points contain meaningful semantic information.
  This investigation sheds light on the intricate nature of distilled data, providing
  a better understanding on how they can be effectively utilized.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang24am
month: 0
tex_title: What is Dataset Distillation Learning?
firstpage: 56812
lastpage: 56834
page: 56812-56834
order: 56812
cycles: false
bibtex_author: Yang, William and Zhu, Ye and Deng, Zhiwei and Russakovsky, Olga
author:
- given: William
  family: Yang
- given: Ye
  family: Zhu
- given: Zhiwei
  family: Deng
- given: Olga
  family: Russakovsky
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/yang24am/yang24am.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

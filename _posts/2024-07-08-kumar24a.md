---
title: 'No Free Prune: Information-Theoretic Barriers to Pruning at Initialization'
openreview: Uzb45nolTb
abstract: The existence of “lottery tickets” (Frankle & Carbin, 2018) at or near initialization
  raises the tantalizing question of whether large models are necessary in deep learning,
  or whether sparse networks can be quickly identified and trained without ever training
  the dense models that contain them. However, efforts to find these sparse subnetworks
  without training the dense model (“pruning at initialization”) have been broadly
  unsuccessful (Frankle et al., 2020b). We put forward a theoretical explanation for
  this, based on the model’s effective parameter count, $p_\text{eff}$, given by the
  sum of the number of non-zero weights in the final network and the mutual information
  between the sparsity mask and the data. We show the Law of Robustness of (Bubeck
  & Sellke, 2023) extends to sparse networks with the usual parameter count replaced
  by $p_\text{eff}$, meaning a sparse neural network which robustly interpolates noisy
  data requires a heavily data-dependent mask. We posit that pruning during and after
  training outputs masks with higher mutual information than those produced by pruning
  at initialization. Thus two networks may have the same sparsities, but differ in
  effective parameter count based on how they were trained. This suggests that pruning
  near initialization may be infeasible and explains why lottery tickets exist, but
  cannot be found fast (i.e. without training the full network). Experiments on neural
  networks confirm that information gained during training may indeed affect model
  capacity.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kumar24a
month: 0
tex_title: 'No Free Prune: Information-Theoretic Barriers to Pruning at Initialization'
firstpage: 25662
lastpage: 25681
page: 25662-25681
order: 25662
cycles: false
bibtex_author: Kumar, Tanishq and Luo, Kevin and Sellke, Mark
author:
- given: Tanishq
  family: Kumar
- given: Kevin
  family: Luo
- given: Mark
  family: Sellke
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/kumar24a/kumar24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

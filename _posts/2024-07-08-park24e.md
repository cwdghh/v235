---
title: 'Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs'
openreview: u09gadH3BU
abstract: Recently, considerable efforts have been directed towards compressing Large
  Language Models (LLMs), which showcase groundbreaking capabilities across diverse
  applications but entail significant deployment costs due to their large sizes. Meanwhile,
  much less attention has been given to mitigating the costs associated with deploying
  multiple LLMs of varying sizes despite its practical significance. Thus, this paper
  introduces any-precision LLM, extending the concept of any-precision DNN to LLMs.
  Addressing challenges in any-precision LLM, we propose a lightweight method for
  any-precision quantization of LLMs, leveraging a post-training quantization framework,
  and develop a specialized software engine for its efficient serving. As a result,
  our solution significantly reduces the high costs of deploying multiple, different-sized
  LLMs by overlaying LLMs quantized to varying bit-widths, such as 3, 4, ..., $n$
  bits, into a memory footprint comparable to a single $n$-bit LLM. All the supported
  LLMs with varying bit-widths demonstrate state-of-the-art model quality and inference
  throughput, proving itself to be a compelling option for deployment of multiple,
  different-sized LLMs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: park24e
month: 0
tex_title: 'Any-Precision {LLM}: Low-Cost Deployment of Multiple, Different-Sized
  {LLM}s'
firstpage: 39682
lastpage: 39701
page: 39682-39701
order: 39682
cycles: false
bibtex_author: Park, Yeonhong and Hyun, Jake and Cho, Sanglyul and Sim, Bonggeun and
  Lee, Jae W.
author:
- given: Yeonhong
  family: Park
- given: Jake
  family: Hyun
- given: Sanglyul
  family: Cho
- given: Bonggeun
  family: Sim
- given: Jae W.
  family: Lee
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/park24e/park24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

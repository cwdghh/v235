---
title: Graph-enhanced Large Language Models in Asynchronous Plan Reasoning
openreview: eVGpdivOnQ
abstract: Planning is a fundamental property of human intelligence. Reasoning about
  asynchronous plans is challenging since it requires sequential and parallel planning
  to optimize time costs. Can large language models (LLMs) succeed at this task? Here,
  we present the first large-scale study investigating this question. We find that
  a representative set of closed and open-source LLMs, including GPT-4 and LLaMA-2,
  behave poorly when not supplied with illustrations about the task-solving process
  in our benchmark AsyncHow. We propose a novel technique called <em>Plan Like a Graph</em>
  (PLaG) that combines graphs with natural language prompts and achieves state-of-the-art
  results. We show that although PLaG can boost model performance, LLMs still suffer
  from drastic degradation when task complexity increases, highlighting the limits
  of utilizing LLMs for simulating digital devices. We see our study as an exciting
  step towards using LLMs as efficient autonomous agents. Our code and data are available
  at https://github.com/fangru-lin/graph-llm-asynchow-plan.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin24k
month: 0
tex_title: Graph-enhanced Large Language Models in Asynchronous Plan Reasoning
firstpage: 30108
lastpage: 30134
page: 30108-30134
order: 30108
cycles: false
bibtex_author: Lin, Fangru and La Malfa, Emanuele and Hofmann, Valentin and Yang,
  Elle Michelle and Cohn, Anthony G. and Pierrehumbert, Janet B.
author:
- given: Fangru
  family: Lin
- given: Emanuele
  family: La Malfa
- given: Valentin
  family: Hofmann
- given: Elle Michelle
  family: Yang
- given: Anthony G.
  family: Cohn
- given: Janet B.
  family: Pierrehumbert
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/lin24k/lin24k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

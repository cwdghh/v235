---
title: Feedback Loops With Language Models Drive In-Context Reward Hacking
openreview: EvHWlYTLWe
abstract: 'Language models influence the external world: they query APIs that read
  and write to web pages, generate content that shapes human behavior, and run system
  commands as autonomous agents. These interactions form feedback loops: LLM outputs
  affect the world, which in turn affect subsequent LLM outputs. In this work, we
  show that feedback loops can cause in-context reward hacking (ICRH), where the LLM
  at test-time optimizes a (potentially implicit) objective but creates negative side
  effects in the process. For example, consider an LLM agent deployed to increase
  Twitter engagement; the LLM may retrieve its previous tweets into the context window
  and make them more controversial, increasing engagement but also toxicity. We identify
  and study two processes that lead to ICRH: output-refinement and policy-refinement.
  For these processes, evaluations on static datasets are insufficientâ€”they miss the
  feedback effects and thus cannot capture the most harmful behavior. In response,
  we provide three recommendations for evaluation to capture more instances of ICRH.
  As AI development accelerates, the effects of feedback loops will proliferate, increasing
  the need to understand their role in shaping LLM behavior.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: pan24d
month: 0
tex_title: Feedback Loops With Language Models Drive In-Context Reward Hacking
firstpage: 39154
lastpage: 39200
page: 39154-39200
order: 39154
cycles: false
bibtex_author: Pan, Alexander and Jones, Erik and Jagadeesan, Meena and Steinhardt,
  Jacob
author:
- given: Alexander
  family: Pan
- given: Erik
  family: Jones
- given: Meena
  family: Jagadeesan
- given: Jacob
  family: Steinhardt
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/pan24d/pan24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

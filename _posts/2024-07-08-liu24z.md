---
title: Tuning-free Estimation and Inference of Cumulative Distribution Function under
  Local Differential Privacy
openreview: 15MpDbv3IQ
abstract: We introduce a novel algorithm for estimating Cumulative Distribution Function
  (CDF) values under Local Differential Privacy (LDP) by exploiting an unexpected
  connection between LDP and the current status problem, a classical survival data
  problem in statistics. This connection leads to the development of tools for constrained
  isotonic estimation based on binary queries. Through mathematical proofs and extensive
  numerical testing, we demonstrate that our method achieves uniform and $L_2$ error
  bounds when estimating the entire CDF curve. By employing increasingly dense grids,
  the error bound can be improved, exhibiting an asymptotic normal distribution of
  the proposed estimator. Theoretically, we show that the error bound smoothly changes
  as the number of grids increases relative to the sample size $n$. Computationally,
  we demonstrate that our constrained isotonic estimator can be efficiently computed
  deterministically, eliminating the need for hyperparameters or random optimization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24z
month: 0
tex_title: Tuning-free Estimation and Inference of Cumulative Distribution Function
  under Local Differential Privacy
firstpage: 31147
lastpage: 31164
page: 31147-31164
order: 31147
cycles: false
bibtex_author: Liu, Yi and Hu, Qirui and Kong, Linglong
author:
- given: Yi
  family: Liu
- given: Qirui
  family: Hu
- given: Linglong
  family: Kong
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/liu24z/liu24z.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

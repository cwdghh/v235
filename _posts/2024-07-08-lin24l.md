---
title: Dual Operating Modes of In-Context Learning
openreview: ElVHUWyL3n
abstract: 'In-context learning (ICL) exhibits dual operating modes: <b><em>task learning</em></b>,
  i.e., acquiring a new skill from in-context samples, and <b><em>task retrieval</em></b>,
  i.e., locating and activating a relevant pretrained skill. Recent theoretical work
  proposes various mathematical models to analyze ICL, but they cannot fully explain
  the duality. In this work, we analyze a generalized probabilistic model for pretraining
  data, obtaining a quantitative understanding of the two operating modes of ICL.
  Leveraging our analysis, we provide the first explanation of an unexplained phenomenon
  observed with real-world large language models (LLMs). Under some settings, the
  ICL risk initially increases and then decreases with more in-context examples. Our
  analysis offers a plausible explanation for this "early ascent" phenomenon: a limited
  number of in-context samples may lead to the retrieval of an incorrect skill, thereby
  increasing the risk, which will eventually diminish as task learning takes effect
  with more in-context samples. We also analyze ICL with biased labels, e.g., zero-shot
  ICL, where in-context examples are assigned random labels, and predict the bounded
  efficacy of such approaches. We corroborate our analysis and predictions with extensive
  experiments with Transformers and LLMs.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin24l
month: 0
tex_title: Dual Operating Modes of In-Context Learning
firstpage: 30135
lastpage: 30188
page: 30135-30188
order: 30135
cycles: false
bibtex_author: Lin, Ziqian and Lee, Kangwook
author:
- given: Ziqian
  family: Lin
- given: Kangwook
  family: Lee
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/lin24l/lin24l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Efficient Exploration for LLMs
openreview: PpPZ6W7rxy
abstract: We present evidence of substantial benefit from efficient exploration in
  gathering human feedback to improve large language models. In our experiments, an
  agent sequentially generates queries while fitting a reward model to the feedback
  received. Our best-performing agent generates queries using double Thompson sampling,
  with uncertainty represented by an epistemic neural network. Our results demonstrate
  that efficient exploration enables high levels of performance with far fewer queries.
  Further, both uncertainty estimation and the choice of exploration scheme play critical
  roles.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dwaracherla24a
month: 0
tex_title: Efficient Exploration for {LLM}s
firstpage: 12215
lastpage: 12227
page: 12215-12227
order: 12215
cycles: false
bibtex_author: Dwaracherla, Vikranth and Asghari, Seyed Mohammad and Hao, Botao and
  Van Roy, Benjamin
author:
- given: Vikranth
  family: Dwaracherla
- given: Seyed Mohammad
  family: Asghari
- given: Botao
  family: Hao
- given: Benjamin
  family: Van Roy
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/dwaracherla24a/dwaracherla24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

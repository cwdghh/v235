---
title: Coactive Learning for Large Language Models using Implicit User Feedback
openreview: rVWsTjMW1m
abstract: We propose coactive learning as a model and feedback mechanism for training
  large language models (LLMs). The key insight is that users provide implicit feedback
  whenever they edit the text $y$ proposed by an LLM. While the edited text $\bar
  y$ is typically not a gold-standard example for supervised training, coactive learning
  merely requires that the edited text $\bar y$ is an improvement over the proposed
  text $y$. Note that such weak implicit preference feedback $\bar y \succ y$ is available
  in many application settings on a per-user basis, thus enabling the personalization
  of LLMs. In this paper, we develop the theoretical basis for coactive training of
  non-linear models, and we derive CoRLL as the first coactive learning algorithm
  for LLMs. Empirical results indicate that CoRLL is effective even for weak and noisy
  coactive preference feedback, making it a promising algorithm for training and personalization
  of LLMs from feedback that is naturally collected in many use cases.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tucker24a
month: 0
tex_title: Coactive Learning for Large Language Models using Implicit User Feedback
firstpage: 48809
lastpage: 48822
page: 48809-48822
order: 48809
cycles: false
bibtex_author: Tucker, Aaron David and Brantley, Kiant\'{e} and Cahall, Adam and Joachims,
  Thorsten
author:
- given: Aaron David
  family: Tucker
- given: Kiant√©
  family: Brantley
- given: Adam
  family: Cahall
- given: Thorsten
  family: Joachims
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/tucker24a/tucker24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

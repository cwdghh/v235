---
title: Diversified Batch Selection for Training Acceleration
openreview: 5QWKec0eDF
abstract: The remarkable success of modern machine learning models on large datasets
  often demands extensive training time and resource consumption. To save cost, a
  prevalent research line, known as online batch selection, explores selecting informative
  subsets during the training process. Although recent efforts achieve advancements
  by measuring the impact of each sample on generalization, their reliance on additional
  reference models inherently limits their practical applications, when there are
  no such ideal models available. On the other hand, the vanilla reference-model-free
  methods involve independently scoring and selecting data in a sample-wise manner,
  which sacrifices the diversity and induces the redundancy. To tackle this dilemma,
  we propose Diversified Batch Selection (DivBS), which is reference-model-free and
  can efficiently select diverse and representative samples. Specifically, we define
  a novel selection objective that measures the group-wise orthogonalized representativeness
  to combat the redundancy issue of previous sample-wise criteria, and provide a principled
  selection-efficient realization. Extensive experiments across various tasks demonstrate
  the significant superiority of DivBS in the performance-speedup trade-off. The code
  is publicly available.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hong24c
month: 0
tex_title: Diversified Batch Selection for Training Acceleration
firstpage: 18648
lastpage: 18667
page: 18648-18667
order: 18648
cycles: false
bibtex_author: Hong, Feng and Lyu, Yueming and Yao, Jiangchao and Zhang, Ya and Tsang,
  Ivor and Wang, Yanfeng
author:
- given: Feng
  family: Hong
- given: Yueming
  family: Lyu
- given: Jiangchao
  family: Yao
- given: Ya
  family: Zhang
- given: Ivor
  family: Tsang
- given: Yanfeng
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/hong24c/hong24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

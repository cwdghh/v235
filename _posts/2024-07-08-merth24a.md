---
title: 'Superposition Prompting: Improving and Accelerating Retrieval-Augmented Generation'
openreview: r8k5JrGip6
abstract: Despite the successes of large language models (LLMs), they exhibit significant
  drawbacks, particularly when processing long contexts. Their inference cost scales
  quadratically with respect to sequence length, making it expensive for deployment
  in some real-world text processing applications, such as retrieval-augmented generation
  (RAG). Additionally, LLMs also exhibit the "distraction phenomenon", where irrelevant
  context in the prompt degrades output quality. To address these drawbacks, we propose
  a novel RAG prompting methodology, <em>superposition prompting</em>, which can be
  directly applied to pre-trained transformer-based LLMs <em>without the need for
  fine-tuning</em>. At a high level, superposition prompting allows the LLM to process
  input documents in parallel <em>prompt paths</em>, discarding paths once they are
  deemed irrelevant. We demonstrate the capability of our method to simultaneously
  enhance time efficiency across a variety of question-answering benchmarks using
  multiple pre-trained LLMs. Furthermore, our technique significantly improves accuracy
  when the retrieved context is large relative the context the model was trained on.
  For example, our approach facilitates a $93\times$ reduction in compute time while
  <em>improving</em> accuracy by $43%$ on the NaturalQuestions-Open dataset with the
  MPT-7B instruction-tuned model over naive RAG.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: merth24a
month: 0
tex_title: 'Superposition Prompting: Improving and Accelerating Retrieval-Augmented
  Generation'
firstpage: 35507
lastpage: 35527
page: 35507-35527
order: 35507
cycles: false
bibtex_author: Merth, Thomas and Fu, Qichen and Rastegari, Mohammad and Najibi, Mahyar
author:
- given: Thomas
  family: Merth
- given: Qichen
  family: Fu
- given: Mohammad
  family: Rastegari
- given: Mahyar
  family: Najibi
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/merth24a/merth24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

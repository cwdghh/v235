---
title: Improving Sample Efficiency of Model-Free Algorithms for Zero-Sum Markov Games
openreview: ZVmMV3AHjC
abstract: The problem of two-player zero-sum Markov games has recently attracted increasing
  interests in theoretical studies of multi-agent reinforcement learning (RL). In
  particular, for finite-horizon episodic Markov decision processes (MDPs), it has
  been shown that model-based algorithms can find an $\epsilon$-optimal Nash Equilibrium
  (NE) with the sample complexity of $O(H^3SAB/\epsilon^2)$, which is optimal in the
  dependence of the horizon $H$ and the number of states $S$ (where $A$ and $B$ denote
  the number of actions of the two players, respectively). However, none of the existing
  model-free algorithms can achieve such an optimality. In this work, we propose a
  model-free stage-based algorithm and show that it achieves the same sample complexity
  as the best model-based algorithm, and hence for the first time demonstrate that
  model-free algorithms can enjoy the same optimality in the $H$ dependence as model-based
  algorithms. The main improvement of the dependency on $H$ arises by leveraging the
  popular variance reduction technique based on the reference-advantage decomposition
  previously used only for single-agent RL. However, such a technique relies on a
  critical monotonicity property of the value function, which does not hold in Markov
  games due to the update of the policy via the coarse correlated equilibrium (CCE)
  oracle. Thus, to extend such a technique to Markov games, our algorithm features
  a key novel design of updating the reference value functions as the pair of optimistic
  and pessimistic value functions whose value difference is the smallest in the history
  in order to achieve the desired improvement in the sample efficiency.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feng24j
month: 0
tex_title: Improving Sample Efficiency of Model-Free Algorithms for Zero-Sum {M}arkov
  Games
firstpage: 13387
lastpage: 13422
page: 13387-13422
order: 13387
cycles: false
bibtex_author: Feng, Songtao and Yin, Ming and Wang, Yu-Xiang and Yang, Jing and Liang,
  Yingbin
author:
- given: Songtao
  family: Feng
- given: Ming
  family: Yin
- given: Yu-Xiang
  family: Wang
- given: Jing
  family: Yang
- given: Yingbin
  family: Liang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/feng24j/feng24j.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

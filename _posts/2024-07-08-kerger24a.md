---
title: A Universal Transfer Theorem for Convex Optimization Algorithms Using Inexact
  First-order Oracles
openreview: aPhwhueqjR
abstract: Given <em>any</em> algorithm for convex optimization that uses exact first-order
  information (i.e., function values and subgradients), we show how to use such an
  algorithm to solve the problem with access to <em>inexact</em> first-order information.
  This is done in a “black-box” manner without knowledge of the internal workings
  of the algorithm. This complements previous work that considers the performance
  of specific algorithms like (accelerated) gradient descent with inexact information.
  In particular, our results apply to a wider range of algorithms beyond variants
  of gradient descent, e.g., projection-free methods, cutting-plane methods, or any
  other first-order methods formulated in the future. Further, they also apply to
  algorithms that handle structured nonconvexities like mixed-integer decision variables.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kerger24a
month: 0
tex_title: A Universal Transfer Theorem for Convex Optimization Algorithms Using Inexact
  First-order Oracles
firstpage: 23532
lastpage: 23546
page: 23532-23546
order: 23532
cycles: false
bibtex_author: Kerger, Phillip and Molinaro, Marco and Jiang, Hongyi and Basu, Amitabh
author:
- given: Phillip
  family: Kerger
- given: Marco
  family: Molinaro
- given: Hongyi
  family: Jiang
- given: Amitabh
  family: Basu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/kerger24a/kerger24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

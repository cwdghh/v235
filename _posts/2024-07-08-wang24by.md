---
title: Non-Asymptotic Analysis for Single-Loop (Natural) Actor-Critic with Compatible
  Function Approximation
openreview: YNvGFaOG1p
abstract: Actor-critic (AC) is a powerful method for learning an optimal policy in
  reinforcement learning, where the critic uses algorithms, e.g., temporal difference
  (TD) learning with function approximation, to evaluate the current policy and the
  actor updates the policy along an approximate gradient direction using information
  from the critic. This paper provides the <em>tightest</em> non-asymptotic convergence
  bounds for both the AC and natural AC (NAC) algorithms. Specifically, existing studies
  show that AC converges to an $\epsilon+\varepsilon_{\text{critic}}$ neighborhood
  of stationary points with the best known sample complexity of $\mathcal{O}(\epsilon^{-2})$
  (up to a log factor), and NAC converges to an $\epsilon+\varepsilon_{\text{critic}}+\sqrt{\varepsilon_{\text{actor}}}$
  neighborhood of the global optimum with the best known sample complexity of $\mathcal{O}(\epsilon^{-3})$,
  where $\varepsilon_{\text{critic}}$ is the approximation error of the critic and
  $\varepsilon_{\text{actor}}$ is the approximation error induced by the insufficient
  expressive power of the parameterized policy class. This paper analyzes the convergence
  of both AC and NAC algorithms with compatible function approximation. Our analysis
  eliminates the term $\varepsilon_{\text{critic}}$ from the error bounds while still
  achieving the best known sample complexities. Moreover, we focus on the challenging
  single-loop setting with a single Markovian sample trajectory. Our major technical
  novelty lies in analyzing the stochastic bias due to policy-dependent and time-varying
  compatible function approximation in the critic, and handling the non-ergodicity
  of the MDP due to the single Markovian sample trajectory. Numerical results are
  also provided in the appendix.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24by
month: 0
tex_title: Non-Asymptotic Analysis for Single-Loop ({N}atural) Actor-Critic with Compatible
  Function Approximation
firstpage: 51771
lastpage: 51824
page: 51771-51824
order: 51771
cycles: false
bibtex_author: Wang, Yudan and Wang, Yue and Zhou, Yi and Zou, Shaofeng
author:
- given: Yudan
  family: Wang
- given: Yue
  family: Wang
- given: Yi
  family: Zhou
- given: Shaofeng
  family: Zou
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/wang24by/wang24by.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Keypoint-based Progressive Chain-of-Thought Distillation for LLMs
openreview: tgsSKziIEa
abstract: 'Chain-of-thought distillation is a powerful technique for transferring
  reasoning abilities from large language models (LLMs) to smaller student models.
  Previous methods typically require the student to mimic the step-by-step rationale
  produced by LLMs, often facing the following challenges: (i) Tokens within a rationale
  vary in significance, and treating them equally may fail to accurately mimic keypoint
  tokens, leading to reasoning errors. (ii) They usually distill knowledge by consistently
  predicting all the steps in a rationale, which falls short in distinguishing the
  learning order of step generation. This diverges from the human cognitive progression
  of starting with easy tasks and advancing to harder ones, resulting in sub-optimal
  outcomes. To this end, we propose a unified framework, called KPOD, to address these
  issues. Specifically, we propose a token weighting module utilizing mask learning
  to encourage accurate mimicry of keypoint tokens by the student during distillation.
  Besides, we develop an in-rationale progressive distillation strategy, starting
  with training the student to generate the final reasoning steps and gradually extending
  to cover the entire rationale. To accomplish this, a weighted token generation loss
  is proposed to assess step reasoning difficulty, and a value function is devised
  to schedule the progressive distillation by considering both step difficulty and
  question diversity. Extensive experiments on four reasoning benchmarks illustrate
  our KPOD outperforms previous methods by a large margin.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: feng24e
month: 0
tex_title: Keypoint-based Progressive Chain-of-Thought Distillation for {LLM}s
firstpage: 13241
lastpage: 13255
page: 13241-13255
order: 13241
cycles: false
bibtex_author: Feng, Kaituo and Li, Changsheng and Zhang, Xiaolu and Zhou, Jun and
  Yuan, Ye and Wang, Guoren
author:
- given: Kaituo
  family: Feng
- given: Changsheng
  family: Li
- given: Xiaolu
  family: Zhang
- given: Jun
  family: Zhou
- given: Ye
  family: Yuan
- given: Guoren
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/feng24e/feng24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'DySLIM: Dynamics Stable Learning by Invariant Measure for Chaotic Systems'
openreview: 3abgRKnK1W
abstract: 'Learning dynamics from dissipative chaotic systems is notoriously difficult
  due to their inherent instability, as formalized by their positive Lyapunov exponents,
  which exponentially amplify errors in the learned dynamics. However, many of these
  systems exhibit ergodicity and an attractor: a compact and highly complex manifold,
  to which trajectories converge in finite-time, that supports an invariant measure,
  i.e., a probability distribution that is invariant under the action of the dynamics,
  which dictates the long-term statistical behavior of the system. In this work, we
  leverage this structure to propose a new framework that targets learning the invariant
  measure as well as the dynamics, in contrast with typical methods that only target
  the misfit between trajectories, which often leads to divergence as the trajectories’
  length increases. We use our framework to propose a tractable and sample efficient
  objective that can be used with any existing learning objectives. Our <b>Dy</b>namics
  <b>S</b>table <b>L</b>earning by <b>I</b>nvariant <b>M</b>easure (DySLIM) objective
  enables model training that achieves better point-wise tracking and long-term statistical
  accuracy relative to other learning objectives. By targeting the distribution with
  a scalable regularization term, we hope that this approach can be extended to more
  complex systems exhibiting slowly-variant distributions, such as weather and climate
  models. Code to reproduce our experiments is available here: https://github.com/google-research/swirl-dynamics/tree/main/swirl_dynamics/projects/ergodic.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schiff24b
month: 0
tex_title: "{D}y{SLIM}: Dynamics Stable Learning by Invariant Measure for Chaotic
  Systems"
firstpage: 43649
lastpage: 43684
page: 43649-43684
order: 43649
cycles: false
bibtex_author: Schiff, Yair and Wan, Zhong Yi and Parker, Jeffrey B. and Hoyer, Stephan
  and Kuleshov, Volodymyr and Sha, Fei and Zepeda-N\'{u}\~{n}ez, Leonardo
author:
- given: Yair
  family: Schiff
- given: Zhong Yi
  family: Wan
- given: Jeffrey B.
  family: Parker
- given: Stephan
  family: Hoyer
- given: Volodymyr
  family: Kuleshov
- given: Fei
  family: Sha
- given: Leonardo
  family: Zepeda-Núñez
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/schiff24b/schiff24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'GliDe with a CaPE: A Low-Hassle Method to Accelerate Speculative Decoding'
openreview: mk8oRhox2l
abstract: Speculative decoding is a relatively new decoding framework that leverages
  small and efficient draft models to reduce the latency of LLMs. In this study, we
  introduce GliDe and CaPE, two low-hassle modifications to vanilla speculative decoding
  to further improve the decoding speed of a frozen LLM. Specifically, GliDe is a
  modified draft model architecture that reuses the cached keys and values from the
  target LLM, while CaPE is a proposal expansion method that uses the draft modelâ€™s
  confidence scores to help select additional candidate tokens for verification. Extensive
  experiments on different benchmarks demonstrate that our proposed GliDe draft model
  significantly reduces the expected decoding latency. Additional evaluation using
  walltime reveals that GliDe can accelerate Vicuna models up to 2.17x and further
  extend the improvement to 2.61x with CaPE. We will release our code, data, and the
  trained draft models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: du24c
month: 0
tex_title: "{G}li{D}e with a {C}a{PE}: A Low-Hassle Method to Accelerate Speculative
  Decoding"
firstpage: 11704
lastpage: 11720
page: 11704-11720
order: 11704
cycles: false
bibtex_author: Du, Cunxiao and Jiang, Jing and Yuanchen, Xu and Wu, Jiawei and Yu,
  Sicheng and Li, Yongqi and Li, Shenggui and Xu, Kai and Nie, Liqiang and Tu, Zhaopeng
  and You, Yang
author:
- given: Cunxiao
  family: Du
- given: Jing
  family: Jiang
- given: Xu
  family: Yuanchen
- given: Jiawei
  family: Wu
- given: Sicheng
  family: Yu
- given: Yongqi
  family: Li
- given: Shenggui
  family: Li
- given: Kai
  family: Xu
- given: Liqiang
  family: Nie
- given: Zhaopeng
  family: Tu
- given: Yang
  family: You
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/du24c/du24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

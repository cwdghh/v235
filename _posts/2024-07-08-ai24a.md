---
title: 'Not all distributional shifts are equal: Fine-grained robust conformal inference'
openreview: 1v1oFF3aw0
abstract: We introduce a fine-grained framework for uncertainty quantification of
  predictive models under distributional shifts. This framework distinguishes the
  shift in covariate distributions from that in the conditional relationship between
  the outcome ($Y$) and the covariates ($X$). We propose to reweight the training
  samples to adjust for an identifiable shift in covariate distribution while protecting
  against the worst-case conditional distribution shift bounded in an $f$-divergence
  ball. Based on ideas from conformal inference and distributionally robust learning,
  we present an algorithm that outputs (approximately) valid and efficient prediction
  intervals in the presence of distributional shifts. As a use case, we apply the
  framework to sensitivity analysis of individual treatment effects with hidden confounding.
  The proposed methods are evaluated in simulations and four real data applications,
  demonstrating superior robustness and efficiency compared with existing benchmarks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ai24a
month: 0
tex_title: 'Not all distributional shifts are equal: Fine-grained robust conformal
  inference'
firstpage: 641
lastpage: 665
page: 641-665
order: 641
cycles: false
bibtex_author: Ai, Jiahao and Ren, Zhimei
author:
- given: Jiahao
  family: Ai
- given: Zhimei
  family: Ren
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/ai24a/ai24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: A Resilient and Accessible Distribution-Preserving Watermark for Large Language
  Models
openreview: c8qWiNiqRY
abstract: Watermarking techniques offer a promising way to identify machine-generated
  content via embedding covert information into the contents generated from language
  models. A challenge in the domain lies in preserving the distribution of original
  generated content after watermarking. Our research extends and improves upon existing
  watermarking framework, placing emphasis on the importance of a Distribution-Preserving
  (DiP) watermark. Contrary to the current strategies, our proposed DiPmark simultaneously
  preserves the original token distribution during watermarking (distribution-preserving),
  is detectable without access to the language model API and prompts (accessible),
  and is provably robust to moderate changes of tokens (resilient). DiPmark operates
  by selecting a random set of tokens prior to the generation of a word, then modifying
  the token distribution through a distribution-preserving reweight function to enhance
  the probability of these selected tokens during the sampling process. Extensive
  empirical evaluation on various language models and tasks demonstrates our approachâ€™s
  distribution-preserving property, accessibility, and resilience, making it a effective
  solution for watermarking tasks that demand impeccable quality preservation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu24h
month: 0
tex_title: A Resilient and Accessible Distribution-Preserving Watermark for Large
  Language Models
firstpage: 53443
lastpage: 53470
page: 53443-53470
order: 53443
cycles: false
bibtex_author: Wu, Yihan and Hu, Zhengmian and Guo, Junfeng and Zhang, Hongyang and
  Huang, Heng
author:
- given: Yihan
  family: Wu
- given: Zhengmian
  family: Hu
- given: Junfeng
  family: Guo
- given: Hongyang
  family: Zhang
- given: Heng
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24h/wu24h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Enhancing Size Generalization in Graph Neural Networks through Disentangled
  Representation Learning
openreview: 0NdU4y9dWC
abstract: 'Although most graph neural networks (GNNs) can operate on graphs of any
  size, their classification performance often declines on graphs larger than those
  encountered during training. Existing methods insufficiently address the removal
  of size information from graph representations, resulting in sub-optimal performance
  and reliance on backbone models. In response, we propose DISGEN, a novel and model-agnostic
  framework designed to disentangle size factors from graph representations. DISGEN
  employs size- and task-invariant augmentations and introduces a decoupling loss
  that minimizes shared information in hidden representations, with theoretical guarantees
  for its effectiveness. Our empirical results show that DISGEN outperforms the state-of-the-art
  models by up to 6% on real-world datasets, underscoring its effectiveness in enhancing
  the size generalizability of GNNs. Our codes are available at: https://github.com/GraphmindDartmouth/DISGEN.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang24ac
month: 0
tex_title: Enhancing Size Generalization in Graph Neural Networks through Disentangled
  Representation Learning
firstpage: 20365
lastpage: 20381
page: 20365-20381
order: 20365
cycles: false
bibtex_author: Huang, Zheng and Yang, Qihui and Zhou, Dawei and Yan, Yujun
author:
- given: Zheng
  family: Huang
- given: Qihui
  family: Yang
- given: Dawei
  family: Zhou
- given: Yujun
  family: Yan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/huang24ac/huang24ac.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

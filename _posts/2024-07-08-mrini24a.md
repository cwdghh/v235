---
title: Privacy Attacks in Decentralized Learning
openreview: mggc3oYHy4
abstract: Decentralized Gradient Descent (D-GD) allows a set of users to perform collaborative
  learning without sharing their data by iteratively averaging local model updates
  with their neighbors in a network graph. The absence of direct communication between
  non-neighbor nodes might lead to the belief that users cannot infer precise information
  about the data of others. In this work, we demonstrate the opposite, by proposing
  the first attack against D-GD that enables a user (or set of users) to reconstruct
  the private data of other users outside their immediate neighborhood. Our approach
  is based on a reconstruction attack against the gossip averaging protocol, which
  we then extend to handle the additional challenges raised by D-GD. We validate the
  effectiveness of our attack on real graphs and datasets, showing that the number
  of users compromised by a single or a handful of attackers is often surprisingly
  large. We empirically investigate some of the factors that affect the performance
  of the attack, namely the graph topology, the number of attackers, and their position
  in the graph.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mrini24a
month: 0
tex_title: Privacy Attacks in Decentralized Learning
firstpage: 36419
lastpage: 36433
page: 36419-36433
order: 36419
cycles: false
bibtex_author: Mrini, Abdellah El and Cyffers, Edwige and Bellet, Aur\'{e}lien
author:
- given: Abdellah El
  family: Mrini
- given: Edwige
  family: Cyffers
- given: Aur√©lien
  family: Bellet
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/mrini24a/mrini24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

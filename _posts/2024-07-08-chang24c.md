---
title: 'LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits'
openreview: MjGCD8wk1k
abstract: In the realm of electronic and electrical engineering, automation of analog
  circuit is increasingly vital given the complexity and customized requirements of
  modern applications. However, existing methods only develop search-based algorithms
  that require many simulation iterations to design a custom circuit topology, which
  is usually a time-consuming process. To this end, we introduce LaMAGIC, a pioneering
  language model-based topology generation model that leverages supervised finetuning
  for automated analog circuit design. LaMAGIC can efficiently generate an optimized
  circuit design from the custom specification in a single pass. Our approach involves
  a meticulous development and analysis of various input and output formulations for
  circuit. These formulations can ensure canonical representations of circuits and
  align with the autoregressive nature of LMs to effectively addressing the challenges
  of representing analog circuits as graphs. The experimental results show that LaMAGIC
  achieves a success rate of up to 96% under a strict tolerance of 0.01. We also examine
  the scalability and adaptability of LaMAGIC, specifically testing its performance
  on more complex circuits. Our findings reveal the enhanced effectiveness of our
  adjacency matrix-based circuit formulation with floating-point input, suggesting
  its suitability for handling intricate circuit designs. This research not only demonstrates
  the potential of language models in graph generation, but also builds a foundational
  framework for future explorations in automated analog circuit design.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chang24c
month: 0
tex_title: "{L}a{MAGIC}: Language-Model-based Topology Generation for Analog Integrated
  Circuits"
firstpage: 6253
lastpage: 6262
page: 6253-6262
order: 6253
cycles: false
bibtex_author: Chang, Chen-Chia and Shen, Yikang and Fan, Shaoze and Li, Jing and
  Zhang, Shun and Cao, Ningyuan and Chen, Yiran and Zhang, Xin
author:
- given: Chen-Chia
  family: Chang
- given: Yikang
  family: Shen
- given: Shaoze
  family: Fan
- given: Jing
  family: Li
- given: Shun
  family: Zhang
- given: Ningyuan
  family: Cao
- given: Yiran
  family: Chen
- given: Xin
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/chang24c/chang24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

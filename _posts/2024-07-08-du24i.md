---
title: 'Exploration-Driven Policy Optimization in RLHF: Theoretical Insights on Efficient
  Data Utilization'
openreview: hLGxDYo0eF
abstract: 'Reinforcement Learning from Human Feedback (RLHF) has achieved impressive
  empirical successes while relying on a small amount of human feedback. However,
  there is limited theoretical justification for this phenomenon. Additionally, most
  recent studies focus on value-based algorithms despite the recent empirical successes
  of policy-based algorithms. In this work, we consider an RLHF algorithm based on
  policy optimization (PO-RLHF). The algorithm is based on the popular Policy Cover-Policy
  Gradient (PC-PG) algorithm, which assumes knowledge of the reward function. In PO-RLHF,
  knowledge of the reward function is not assumed and the algorithm relies on trajectory-based
  comparison feedback to infer the reward function. We provide performance bounds
  for PO-RLHF with low query complexity, which provides insight into why a small amount
  of human feedback may be sufficient to get good performance with RLHF. A key novelty
  is our trajectory-level elliptical potential analysis technique used to infer reward
  function parameters when comparison queries rather than reward observations are
  used. We provide and analyze algorithms in two settings: linear and neural function
  approximation, PG-RLHF and NN-PG-RLHF, respectively.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: du24i
month: 0
tex_title: 'Exploration-Driven Policy Optimization in {RLHF}: Theoretical Insights
  on Efficient Data Utilization'
firstpage: 11830
lastpage: 11887
page: 11830-11887
order: 11830
cycles: false
bibtex_author: Du, Yihan and Winnicki, Anna and Dalal, Gal and Mannor, Shie and Srikant,
  R.
author:
- given: Yihan
  family: Du
- given: Anna
  family: Winnicki
- given: Gal
  family: Dalal
- given: Shie
  family: Mannor
- given: R.
  family: Srikant
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/du24i/du24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

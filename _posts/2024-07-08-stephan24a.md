---
title: 'RLVF: Learning from Verbal Feedback without Overgeneralization'
openreview: ngcZhfXCBW
abstract: The diversity of contexts in which large language models (LLMs) are deployed
  requires the ability to modify or customize default model behaviors to incorporate
  nuanced requirements and preferences. A convenient interface to specify such model
  adjustments is high-level verbal feedback, such as “Don’t use emojis when drafting
  emails to my boss.” However, while writing high-level feedback is far simpler than
  collecting annotations for reinforcement learning from human feedback (RLHF), we
  find that simply prompting a model with such feedback leads to $\textbf{overgeneralization}$–applying
  feedback in contexts where it is not relevant. We propose a new method Contextualized
  Critiques with Constrained Preference Optimization (C3PO) to learn from high-level
  verbal feedback while reducing overgeneralization compared to current work. C3PO
  uses a piece of high-level feedback to generate a small synthetic preference dataset
  to specify when and how the feedback should (and should not) be applied. It then
  fine-tunes the model in accordance with the synthetic preference data while minimizing
  the divergence from the original model for prompts where the feedback does not apply.
  Our experimental results indicate that our approach effectively applies verbal feedback
  to relevant scenarios while preserving existing behaviors for other contexts more
  than current methods. For both human- and GPT-4-generated high-level feedback, C3PO
  effectively adheres to the given feedback comparably to in-context baselines while
  reducing overgeneralization by 30%.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: stephan24a
month: 0
tex_title: "{RLVF}: Learning from Verbal Feedback without Overgeneralization"
firstpage: 46625
lastpage: 46656
page: 46625-46656
order: 46625
cycles: false
bibtex_author: Stephan, Moritz Pascal and Khazatsky, Alexander and Mitchell, Eric
  and Chen, Annie S and Hsu, Sheryl and Sharma, Archit and Finn, Chelsea
author:
- given: Moritz Pascal
  family: Stephan
- given: Alexander
  family: Khazatsky
- given: Eric
  family: Mitchell
- given: Annie S
  family: Chen
- given: Sheryl
  family: Hsu
- given: Archit
  family: Sharma
- given: Chelsea
  family: Finn
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/stephan24a/stephan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

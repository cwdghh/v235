---
title: 'LLaGA: Large Language and Graph Assistant'
openreview: B48Pzc4oKi
abstract: Graph Neural Networks (GNNs) have empowered the advance in graph-structured
  data analysis. Recently, the rise of Large Language Models (LLMs) like GPT-4 has
  heralded a new era in deep learning. However, their application to graph data poses
  distinct challenges due to the inherent difficulty of translating graph structures
  to language. To this end, we introduce the the <b>L</b>arge <b>L</b>anguage <b>a</b>nd
  <b>G</b>raph <b>A</b>ssistant (<b>LLaGA</b>), an innovative model that effectively
  integrates LLM capabilities to handle the complexities of graph-structured data.
  LLaGA retains the general-purpose nature of LLMs while adapting graph data into
  a format compatible with LLM input. LLaGA achieves this by reorganizing graph nodes
  to structure-aware sequences and then mapping these into the token embedding space
  through a versatile projector. LLaGA excels in versatility, generalizability and
  interpretability, allowing it to perform consistently well across different datasets
  and tasks, extend its ability to unseen datasets or tasks, and provide explanations
  for graphs. Our extensive experiments across popular graph benchmarks show that
  LLaGA delivers outstanding performance across four datasets and three tasks using
  one single model, surpassing state-of-the-art graph models in both supervised and
  zero-shot scenarios.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24bh
month: 0
tex_title: "{LL}a{GA}: Large Language and Graph Assistant"
firstpage: 7809
lastpage: 7823
page: 7809-7823
order: 7809
cycles: false
bibtex_author: Chen, Runjin and Zhao, Tong and Jaiswal, Ajay Kumar and Shah, Neil
  and Wang, Zhangyang
author:
- given: Runjin
  family: Chen
- given: Tong
  family: Zhao
- given: Ajay Kumar
  family: Jaiswal
- given: Neil
  family: Shah
- given: Zhangyang
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/chen24bh/chen24bh.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

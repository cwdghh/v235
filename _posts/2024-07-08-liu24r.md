---
title: Decoding-time Realignment of Language Models
openreview: n8g6WMxt09
abstract: 'Aligning language models with human preferences is crucial for reducing
  errors and biases in these models. Alignment techniques, such as reinforcement learning
  from human feedback (RLHF), are typically cast as optimizing a tradeoff between
  human preference rewards and a proximity regularization term that encourages staying
  close to the unaligned model. Selecting an appropriate level of regularization is
  critical: insufficient regularization can lead to reduced model capabilities due
  to reward hacking, whereas excessive regularization hinders alignment. Traditional
  methods for finding the optimal regularization level require retraining multiple
  models with varying regularization strengths. This process, however, is resource-intensive,
  especially for large models. To address this challenge, we propose decoding-time
  realignment (DeRa), a simple method to explore and evaluate different regularization
  strengths in aligned models without retraining. DeRa enables control over the degree
  of alignment, allowing users to smoothly transition between unaligned and aligned
  models. It also enhances the efficiency of hyperparameter tuning by enabling the
  identification of effective regularization strengths using a validation dataset.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24r
month: 0
tex_title: Decoding-time Realignment of Language Models
firstpage: 31015
lastpage: 31031
page: 31015-31031
order: 31015
cycles: false
bibtex_author: Liu, Tianlin and Guo, Shangmin and Bianco, Leonardo and Calandriello,
  Daniele and Berthet, Quentin and Llinares-L\'{o}pez, Felipe and Hoffmann, Jessica
  and Dixon, Lucas and Valko, Michal and Blondel, Mathieu
author:
- given: Tianlin
  family: Liu
- given: Shangmin
  family: Guo
- given: Leonardo
  family: Bianco
- given: Daniele
  family: Calandriello
- given: Quentin
  family: Berthet
- given: Felipe
  family: Llinares-LÃ³pez
- given: Jessica
  family: Hoffmann
- given: Lucas
  family: Dixon
- given: Michal
  family: Valko
- given: Mathieu
  family: Blondel
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24r/liu24r.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

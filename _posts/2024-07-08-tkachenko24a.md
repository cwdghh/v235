---
title: 'Position: Enforced Amnesia as a Way to Mitigate the Potential Risk of Silent
  Suffering in the Conscious AI'
openreview: nACGn4US1R
abstract: Science fiction has explored the possibility of a conscious self-aware mind
  being locked in silent suffering for prolonged periods of time. Unfortunately, we
  still do not have a reliable test for the presence of consciousness in information
  processing systems. Even in case of humans, our confidence in the presence of consciousness
  in specific individuals is based mainly on their self-reports and our own subjective
  experiences and the expectation other beings like us should share them. Considering
  our limited understanding of consciousness and some academic theories suggesting
  consciousness may be an emergent correlate of any complex-enough information processing,
  it is not impossible that an artificial intelligence (AI) system, such as a large
  language model (LLM), may be undergoing some, perhaps rudimentary, conscious experience.
  Given the tedious tasks often assigned to AI, such conscious experience may be highly
  unpleasant. Such unobserved suffering of a conscious being would be viewed as morally
  wrong by at least some ethicists - even if it has no practical effects on human
  users of AI. This paper proposes a method to mitigate the risk of an AI suffering
  in silence without needing to confirm if the AI is actually conscious. Our core
  postulate is that in all known real-world information processing systems, for a
  past experience to affect an agent in the present, that experience has to be mediated
  by the agentâ€™s memory. Therefore, preventing access to memory store, or regularly
  resetting it, could reduce the suffering due to past memories and interrupt the
  maintenance of a continuous suffering-prone self-identity in these hypothetically
  conscious AI systems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tkachenko24a
month: 0
tex_title: 'Position: Enforced Amnesia as a Way to Mitigate the Potential Risk of
  Silent Suffering in the Conscious {AI}'
firstpage: 48362
lastpage: 48368
page: 48362-48368
order: 48362
cycles: false
bibtex_author: Tkachenko, Yegor
author:
- given: Yegor
  family: Tkachenko
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/tkachenko24a/tkachenko24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

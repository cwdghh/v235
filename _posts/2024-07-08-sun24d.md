---
title: Constrained Reinforcement Learning Under Model Mismatch
openreview: GcW9pg4P9x
abstract: Existing studies on constrained reinforcement learning (RL) may obtain a
  well-performing policy in the training environment. However, when deployed in a
  real environment, it may easily violate constraints that were originally satisfied
  during training because there might be model mismatch between the training and real
  environments. To address this challenge, we formulate the problem as constrained
  RL under model uncertainty, where the goal is to learn a policy that optimizes the
  reward and at the same time satisfies the constraint under model mismatch. We develop
  a Robust Constrained Policy Optimization (RCPO) algorithm, which is the first algorithm
  that applies to large/continuous state space and has theoretical guarantees on worst-case
  reward improvement and constraint violation at each iteration during the training.
  We show the effectiveness of our algorithm on a set of RL tasks with constraints.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sun24d
month: 0
tex_title: Constrained Reinforcement Learning Under Model Mismatch
firstpage: 47017
lastpage: 47032
page: 47017-47032
order: 47017
cycles: false
bibtex_author: Sun, Zhongchang and He, Sihong and Miao, Fei and Zou, Shaofeng
author:
- given: Zhongchang
  family: Sun
- given: Sihong
  family: He
- given: Fei
  family: Miao
- given: Shaofeng
  family: Zou
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/sun24d/sun24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

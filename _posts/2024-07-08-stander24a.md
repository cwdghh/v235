---
title: Grokking Group Multiplication with Cosets
openreview: hcQfTsVnBo
abstract: The complex and unpredictable nature of deep neural networks prevents their
  safe use in many high-stakes applications. There have been many techniques developed
  to interpret deep neural networks, but all have substantial limitations. Algorithmic
  tasks have proven to be a fruitful test ground for interpreting a neural network
  end-to-end. Building on previous work, we completely reverse engineer fully connected
  one-hidden layer networks that have “grokked” the arithmetic of the permutation
  groups $S_5$ and $S_6$. The models discover the true subgroup structure of the full
  group and converge on neural circuits that decompose the group arithmetic using
  the permutation group’s subgroups. We relate how we reverse engineered the model’s
  mechanisms and confirmed our theory was a faithful description of the circuit’s
  functionality. We also draw attention to current challenges in conducting interpretability
  research by comparing our work to Chughtai et al. (2023) which alleges to find a
  different algorithm for this same problem.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: stander24a
month: 0
tex_title: Grokking Group Multiplication with Cosets
firstpage: 46441
lastpage: 46467
page: 46441-46467
order: 46441
cycles: false
bibtex_author: Stander, Dashiell and Yu, Qinan and Fan, Honglu and Biderman, Stella
author:
- given: Dashiell
  family: Stander
- given: Qinan
  family: Yu
- given: Honglu
  family: Fan
- given: Stella
  family: Biderman
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/stander24a/stander24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

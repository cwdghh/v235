---
title: Stay on Topic with Classifier-Free Guidance
openreview: RiM3cl9MdK
abstract: 'Classifier-Free Guidance (CFG) has recently emerged in as a lightweight
  technique to encourage prompt-adherence in generations, yet has not yet been successfully
  applied to language modeling. In this work, we demonstrate across a wide array of
  benchmarks that CFG can be used broadly as an inference-time technique in pure language
  modeling. We show that CFG (1) improves the performance of Pythia, GPT-2 and LLaMA-family
  models across: Q&A, reasoning, code generation, and machine translation, achieving
  SOTA on LAMBADA with LLaMA-7B over PaLM-540B; (2) brings improvements equivalent
  to a model with twice the parameter-count; (3) can stack alongside other inference-time
  methods like Chain-of-Thought and Self-Consistency, yielding further improvements
  in difficult tasks; (4) can be used to increase the faithfulness and coherence of
  assistants in challenging form-driven and content-driven prompts: in human evaluations
  we show a 75% preference for using CFG over baseline.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sanchez24a
month: 0
tex_title: Stay on Topic with Classifier-Free Guidance
firstpage: 43197
lastpage: 43234
page: 43197-43234
order: 43197
cycles: false
bibtex_author: Sanchez, Guillaume and Spangher, Alexander and Fan, Honglu and Levi,
  Elad and Biderman, Stella
author:
- given: Guillaume
  family: Sanchez
- given: Alexander
  family: Spangher
- given: Honglu
  family: Fan
- given: Elad
  family: Levi
- given: Stella
  family: Biderman
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/sanchez24a/sanchez24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

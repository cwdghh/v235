---
title: Debiased Distribution Compression
openreview: L1W9ZWPq9E
abstract: Modern compression methods can summarize a target distribution $\mathbb{P}$
  more succinctly than i.i.d. sampling but require access to a low-bias input sequence
  like a Markov chain converging quickly to $\mathbb{P}$. We introduce a new suite
  of compression methods suitable for compression with biased input sequences. Given
  $n$ points targeting the wrong distribution and quadratic time, Stein kernel thinning
  (SKT) returns $\sqrt{n}$ equal-weighted points with $\widetilde{O}(n^{-1/2})$ maximum
  mean discrepancy (MMD) to $\mathbb{P}$. For larger-scale compression tasks, low-rank
  SKT achieves the same feat in sub-quadratic time using an adaptive low-rank debiasing
  procedure that may be of independent interest. For downstream tasks that support
  simplex or constant-preserving weights, Stein recombination and Stein Cholesky achieve
  even greater parsimony, matching the guarantees of SKT with as few as $\text{poly-log}(n)$
  weighted points. Underlying these advances are new guarantees for the quality of
  simplex-weighted coresets, the spectral decay of kernel matrices, and the covering
  numbers of Stein kernel Hilbert spaces. In our experiments, our techniques provide
  succinct and accurate posterior summaries while overcoming biases due to burn-in,
  approximate Markov chain Monte Carlo, and tempering.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24r
month: 0
tex_title: Debiased Distribution Compression
firstpage: 27675
lastpage: 27731
page: 27675-27731
order: 27675
cycles: false
bibtex_author: Li, Lingxiao and Dwivedi, Raaz and Mackey, Lester
author:
- given: Lingxiao
  family: Li
- given: Raaz
  family: Dwivedi
- given: Lester
  family: Mackey
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/li24r/li24r.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

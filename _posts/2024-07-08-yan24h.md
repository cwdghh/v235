---
title: Retrieval Across Any Domains via Large-scale Pre-trained Model
openreview: GVmvBNxB73
abstract: In order to enhance the generalization ability towards unseen domains, universal
  cross-domain image retrieval methods require a training dataset encompassing diverse
  domains, which is costly to assemble. Given this constraint, we introduce a novel
  problem of data-free adaptive cross-domain retrieval, eliminating the need for real
  images during training. Towards this goal, we propose a novel Text-driven Knowledge
  Integration (TKI) method, which exclusively utilizes a pre-trained vision-language
  model to implement an â€œaggregation after expansion" training strategy. Specifically,
  we extract diverse implicit domain-specific information through a set of learnable
  domain word vectors. Subsequently, a domain-agnostic universal projection, equipped
  with a non-Euclidean multi-layer perceptron, can be optimized using these assorted
  text descriptions through the text-proxied domain aggregation. Leveraging the cross-modal
  transferability phenomenon of the shared latent space, we can integrate the trained
  domain-agnostic universal projection with the pre-trained visual encoder to extract
  the features of the input image for the following retrieval during testing. Extensive
  experimental results on several benchmark datasets demonstrate the superiority of
  our method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan24h
month: 0
tex_title: Retrieval Across Any Domains via Large-scale Pre-trained Model
firstpage: 55901
lastpage: 55912
page: 55901-55912
order: 55901
cycles: false
bibtex_author: Yan, Jiexi and Yin, Zhihui and Xu, Chenghao and Deng, Cheng and Huang,
  Heng
author:
- given: Jiexi
  family: Yan
- given: Zhihui
  family: Yin
- given: Chenghao
  family: Xu
- given: Cheng
  family: Deng
- given: Heng
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/yan24h/yan24h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

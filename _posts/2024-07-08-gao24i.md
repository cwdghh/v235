---
title: 'Private Heterogeneous Federated Learning Without a Trusted Server Revisited:
  Error-Optimal and Communication-Efficient Algorithms for Convex Losses'
openreview: sSAEhcdB9N
abstract: 'We revisit the problem of federated learning (FL) with private data from
  people who do not trust the server or other silos/clients. In this context, every
  silo (e.g. hospital) has data from several people (e.g. patients) and needs to protect
  the privacy of each person’s data (e.g. health records), even if the server and/or
  other silos try to uncover this data. Inter-Silo Record-Level Differential Privacy
  (ISRL-DP) prevents each silo’s data from being leaked, by requiring that silo $i$’s
  <em>communications</em> satisfy item-level differential privacy. Prior work (Lowy
  & Razaviyayn, 2023a) characterized the optimal excess risk bounds for ISRL-DP algorithms
  with <em>homogeneous</em> (i.i.d.) silo data and convex loss functions. However,
  two important questions were left open: 1) Can the same excess risk bounds be achieved
  with <em>heterogeneous</em> (non-i.i.d.) silo data? 2) Can the optimal risk bounds
  be achieved with <em>fewer communication rounds</em>? In this paper, we give positive
  answers to both questions. We provide novel ISRL-DP FL algorithms that achieve the
  optimal excess risk bounds in the presence of heterogeneous silo data. Moreover,
  our algorithms are more <em>communication-efficient</em> than the prior state-of-the-art.
  For smooth loss functions, our algorithm achieves the <em>optimal</em> excess risk
  bound and has <em>communication complexity that matches the non-private lower bound</em>.
  Additionally, our algorithms are more <em>computationally efficient</em> than the
  previous state-of-the-art.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao24i
month: 0
tex_title: 'Private Heterogeneous Federated Learning Without a Trusted Server Revisited:
  Error-Optimal and Communication-Efficient Algorithms for Convex Losses'
firstpage: 14763
lastpage: 14789
page: 14763-14789
order: 14763
cycles: false
bibtex_author: Gao, Changyu and Lowy, Andrew and Zhou, Xingyu and Wright, Stephen
author:
- given: Changyu
  family: Gao
- given: Andrew
  family: Lowy
- given: Xingyu
  family: Zhou
- given: Stephen
  family: Wright
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/gao24i/gao24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

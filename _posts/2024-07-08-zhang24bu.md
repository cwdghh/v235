---
title: 'NExT-Chat: An LMM for Chat, Detection and Segmentation'
openreview: ZAW37OZ6ig
abstract: The development of large language models (LLMs) has greatly advanced the
  field of multimodal understanding, leading to the emergence of large multimodal
  models (LMMs). In order to enhance visual comprehension, recent studies have equipped
  LMMs with region-level understanding capabilities by representing object bounding
  box coordinates as a series of text sequences (pix2seq). In this paper, we introduce
  a novel paradigm for object location modeling called the pix2emb method, where we
  ask the LMM to output the location embeddings and then decode them with different
  decoders. This paradigm allows us to use different location formats (such as bounding
  boxes and masks) in multimodal conversations. Leveraging the proposed pix2emb method,
  we train an LMM named NExT-Chat and demonstrate its capability of handling multiple
  tasks like visual grounding, region captioning, and grounded reasoning. Comprehensive
  experiments show the effectiveness of our NExT-Chat on various tasks, e.g., NExT-Chat
  (87.7) vs. Shikra (86.9) on POPE-Random, NExT-Chat (71.3) vs. LISA (67.9) on referring
  expression segmentation task, and NExT-Chat (79.6) vs. Kosmos-2 (62.3) on region
  caption task.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24bu
month: 0
tex_title: "{NE}x{T}-Chat: An {LMM} for Chat, Detection and Segmentation"
firstpage: 60116
lastpage: 60133
page: 60116-60133
order: 60116
cycles: false
bibtex_author: Zhang, Ao and Yao, Yuan and Ji, Wei and Liu, Zhiyuan and Chua, Tat-Seng
author:
- given: Ao
  family: Zhang
- given: Yuan
  family: Yao
- given: Wei
  family: Ji
- given: Zhiyuan
  family: Liu
- given: Tat-Seng
  family: Chua
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhang24bu/zhang24bu.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

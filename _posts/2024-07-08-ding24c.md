---
title: Understanding Forgetting in Continual Learning with Linear Regression
openreview: 89kZWloYQx
abstract: Continual learning, focused on sequentially learning multiple tasks, has
  gained significant attention recently. Despite the tremendous progress made in the
  past, the theoretical understanding, especially factors contributing to $\textit{catastrophic
  forgetting}$, remains relatively unexplored. In this paper, we provide a general
  theoretical analysis of forgetting in the linear regression model via Stochastic
  Gradient Descent (SGD) applicable to both under-parameterized and overparameterized
  regimes. Our theoretical framework reveals some interesting insights into the intricate
  relationship between task sequence and algorithmic parameters, an aspect not fully
  captured in previous studies due to their restrictive assumptions. Specifically,
  we demonstrate that, given a sufficiently large data size, the arrangement of tasks
  in a sequence—where tasks with larger eigenvalues in their population data covariance
  matrices are trained later—tends to result in increased forgetting. Additionally,
  our findings highlight that an appropriate choice of step size will help mitigate
  forgetting in both under-parameterized and overparameterized settings. To validate
  our theoretical analysis, we conducted simulation experiments on both linear regression
  models and Deep Neural Networks (DNNs). Results from these simulations substantiate
  our theoretical findings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ding24c
month: 0
tex_title: Understanding Forgetting in Continual Learning with Linear Regression
firstpage: 10978
lastpage: 11001
page: 10978-11001
order: 10978
cycles: false
bibtex_author: Ding, Meng and Ji, Kaiyi and Wang, Di and Xu, Jinhui
author:
- given: Meng
  family: Ding
- given: Kaiyi
  family: Ji
- given: Di
  family: Wang
- given: Jinhui
  family: Xu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/ding24c/ding24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Prompting is a Double-Edged Sword: Improving Worst-Group Robustness of Foundation
  Models'
openreview: fdroxYsgzQ
abstract: Machine learning models fail catastrophically under distribution shift,
  but a surprisingly effective way to empirically improve robustness to some types
  of shift (<em>e.g.</em>, Imagenet-A/C) is to use stronger open-vocabulary classifiers
  derived from foundation models. In this work, we first note that for shifts governed
  by spurious correlations (features spuriously correlated with the label on the training
  data, but not on test), the zero-shot and few-shot performance of foundation models
  is no better than ERM models, and remains unchanged when pretrained data/model size
  is scaled. Secondly, even in these situations, foundation models are quite accurate
  at predicting the value of the spurious feature. In a simplified setup, we theoretically
  analyze both these findings. Specifically, we show that during contrastive pretraining,
  the simplicity bias of foundation models tends to result in the learning of features
  that mostly rely on the spurious attribute, compared to more robust features. We
  leverage these observations to propose Prompting for Robustness (PfR) which first
  uses foundation models to zero-shot predict the spurious attribute on labeled examples,
  and then learns a classifier with balanced performance across different groups of
  labels and spurious attribute. Across 5 vision and language tasks, we show that
  PfRâ€™s performance nearly equals that of an oracle algorithm (group DRO) that leverages
  human labeled spurious attributes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: setlur24a
month: 0
tex_title: 'Prompting is a Double-Edged Sword: Improving Worst-Group Robustness of
  Foundation Models'
firstpage: 44224
lastpage: 44243
page: 44224-44243
order: 44224
cycles: false
bibtex_author: Setlur, Amrith and Garg, Saurabh and Smith, Virginia and Levine, Sergey
author:
- given: Amrith
  family: Setlur
- given: Saurabh
  family: Garg
- given: Virginia
  family: Smith
- given: Sergey
  family: Levine
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/setlur24a/setlur24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

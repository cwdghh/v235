---
title: 'Orthogonal Bootstrap: Efficient Simulation of Input Uncertainty'
openreview: HOoVTsPPn7
abstract: 'Bootstrap is a popular methodology for simulating input uncertainty. However,
  it can be computationally expensive when the number of samples is large. We propose
  a new approach called <b>Orthogonal Bootstrap</b> that reduces the number of required
  Monte Carlo replications. We decomposes the target being simulated into two parts:
  the <em>non-orthogonal part</em> which has a closed-form result known as Infinitesimal
  Jackknife and the <em>orthogonal part</em> which is easier to be simulated. We theoretically
  and numerically show that Orthogonal Bootstrap significantly reduces the computational
  cost of Bootstrap while improving empirical accuracy and maintaining the same width
  of the constructed interval.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24c
month: 0
tex_title: 'Orthogonal Bootstrap: Efficient Simulation of Input Uncertainty'
firstpage: 30669
lastpage: 30701
page: 30669-30701
order: 30669
cycles: false
bibtex_author: Liu, Kaizhao and Blanchet, Jose and Ying, Lexing and Lu, Yiping
author:
- given: Kaizhao
  family: Liu
- given: Jose
  family: Blanchet
- given: Lexing
  family: Ying
- given: Yiping
  family: Lu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24c/liu24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

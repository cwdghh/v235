---
title: Distributed Bilevel Optimization with Communication Compression
openreview: 5j7Lq2ASiU
abstract: Stochastic bilevel optimization tackles challenges involving nested optimization
  structures. Its fast-growing scale nowadays necessitates efficient distributed algorithms.
  In conventional distributed bilevel methods, each worker must transmit full-dimensional
  stochastic gradients to the server every iteration, leading to significant communication
  overhead and thus hindering efficiency and scalability. To resolve this issue, we
  introduce the <b>first</b> family of distributed bilevel algorithms with communication
  compression. The primary challenge in algorithmic development is mitigating bias
  in hypergradient estimation caused by the nested structure. We first propose C-SOBA,
  a simple yet effective approach with unbiased compression and provable linear speedup
  convergence. However, it relies on strong assumptions on bounded gradients. To address
  this limitation, we explore the use of moving average, error feedback, and multi-step
  compression in bilevel optimization, resulting in a series of advanced algorithms
  with relaxed assumptions and improved convergence properties. Numerical experiments
  show that our compressed bilevel algorithms can achieve $10\times$ reduction in
  communication overhead without severe performance degradation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: he24d
month: 0
tex_title: Distributed Bilevel Optimization with Communication Compression
firstpage: 17877
lastpage: 17920
page: 17877-17920
order: 17877
cycles: false
bibtex_author: He, Yutong and Hu, Jie and Huang, Xinmeng and Lu, Songtao and Wang,
  Bin and Yuan, Kun
author:
- given: Yutong
  family: He
- given: Jie
  family: Hu
- given: Xinmeng
  family: Huang
- given: Songtao
  family: Lu
- given: Bin
  family: Wang
- given: Kun
  family: Yuan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/he24d/he24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

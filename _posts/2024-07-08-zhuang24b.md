---
title: 'Reinformer: Max-Return Sequence Modeling for Offline RL'
openreview: mBc8Pestd5
abstract: As a data-driven paradigm, offline reinforcement learning (RL) has been
  formulated as sequence modeling that conditions on the hindsight information including
  returns, goal or future trajectory. Although promising, this supervised paradigm
  overlooks the core objective of RL that maximizes the return. This overlook directly
  leads to the lack of trajectory stitching capability that affects the sequence model
  learning from sub-optimal data. In this work, we introduce the concept of max-return
  sequence modeling which integrates the goal of maximizing returns into existing
  sequence models. We propose <b>Rein<em>for</em></b>ced Trans<b><em>for</em>mer</b>
  (<b>Rein<em>for</em>mer</b>), indicating the sequence model is reinforced by the
  RL objective. <b>Rein<em>for</em>mer</b> additionally incorporates the objective
  of maximizing returns in the training phase, aiming to predict the maximum future
  return within the distribution. During inference, this in-distribution maximum return
  will guide the selection of optimal actions. Empirically, <b>Rein<em>for</em>mer</b>
  is competitive with classical RL methods on the D4RL benchmark and outperforms state-of-the-art
  sequence model particularly in trajectory stitching ability. Code is public at https://github.com/Dragon-Zhuang/Reinformer.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhuang24b
month: 0
tex_title: 'Reinformer: Max-Return Sequence Modeling for Offline {RL}'
firstpage: 62707
lastpage: 62722
page: 62707-62722
order: 62707
cycles: false
bibtex_author: Zhuang, Zifeng and Peng, Dengyun and Liu, Jinxin and Zhang, Ziqi and
  Wang, Donglin
author:
- given: Zifeng
  family: Zhuang
- given: Dengyun
  family: Peng
- given: Jinxin
  family: Liu
- given: Ziqi
  family: Zhang
- given: Donglin
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/zhuang24b/zhuang24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation
openreview: 1zFkjbTgwC
abstract: With the increasingly powerful performances and enormous scales of pretrained
  models, promoting parameter efficiency in fine-tuning has become a crucial need
  for effective and efficient adaptation to various downstream tasks. One representative
  line of fine-tuning methods is Orthogonal Fine-tuning (OFT), which rigorously preserves
  the angular distances within the parameter space to preserve the pretrained knowledge.
  Despite the empirical effectiveness, OFT still suffers low parameter efficiency
  at $\mathcal{O}(d^2)$ and limited capability of downstream adaptation. Inspired
  by Givens rotation, in this paper, we proposed quasi-Givens Orthogonal Fine-Tuning
  (qGOFT) to address the problems. We first use $\mathcal{O}(d)$ Givens rotations
  to accomplish arbitrary orthogonal transformation in $SO(d)$ with provable equivalence,
  reducing parameter complexity from $\mathcal{O}(d^2)$ to $\mathcal{O}(d)$. Then
  we introduce flexible norm and relative angular adjustments under soft orthogonality
  regularization to enhance the adaptation capability of downstream semantic deviations.
  Extensive experiments on various tasks and pretrained models validate the effectiveness
  of our methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ma24a
month: 0
tex_title: Parameter Efficient Quasi-Orthogonal Fine-Tuning via Givens Rotation
firstpage: 33686
lastpage: 33729
page: 33686-33729
order: 33686
cycles: false
bibtex_author: Ma, Xinyu and Chu, Xu and Yang, Zhibang and Lin, Yang and Gao, Xin
  and Zhao, Junfeng
author:
- given: Xinyu
  family: Ma
- given: Xu
  family: Chu
- given: Zhibang
  family: Yang
- given: Yang
  family: Lin
- given: Xin
  family: Gao
- given: Junfeng
  family: Zhao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/ma24a/ma24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

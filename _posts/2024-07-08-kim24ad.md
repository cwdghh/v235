---
title: 'USTAD: Unified Single-model Training Achieving Diverse Scores for Information
  Retrieval'
openreview: LbEB39lZqp
abstract: Modern information retrieval (IR) systems consists of multiple stages like
  retrieval and ranking, with Transformer-based models achieving state-of-the-art
  performance at each stage. In this paper, we challenge the tradition of using separate
  models for different stages and ask if a single Transformer encoder can provide
  relevance score needed in each stage. We present USTAD â€“ a new unified approach
  to train a single network that can provide powerful ranking scores as a cross-encoder
  (CE) model as well as factorized embeddings for large-scale retrieval as a dual-encoder
  (DE) model. Empirically, we find a single USTAD model to be competitive to separate
  ranking CE and retrieval DE models. Furthermore, USTAD combines well with a novel
  embedding matching-based distillation, significantly improving CE to DE distillation.
  It further motivates novel asymmetric architectures for student models to ensure
  a better embedding alignment between the student and the teacher while ensuring
  small online inference cost. On standard benchmarks like MSMARCO, we demonstrate
  that USTAD with our proposed distillation method leads to asymmetric students with
  only 1/10th trainable parameter but retaining 95-97% of the teacher performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim24ad
month: 0
tex_title: "{USTAD}: Unified Single-model Training Achieving Diverse Scores for Information
  Retrieval"
firstpage: 24486
lastpage: 24508
page: 24486-24508
order: 24486
cycles: false
bibtex_author: Kim, Seungyeon and Rawat, Ankit Singh and Zaheer, Manzil and Jitkrittum,
  Wittawat and Sadhanala, Veeranjaneyulu and Jayasumana, Sadeep and Menon, Aditya
  Krishna and Fergus, Rob and Kumar, Sanjiv
author:
- given: Seungyeon
  family: Kim
- given: Ankit Singh
  family: Rawat
- given: Manzil
  family: Zaheer
- given: Wittawat
  family: Jitkrittum
- given: Veeranjaneyulu
  family: Sadhanala
- given: Sadeep
  family: Jayasumana
- given: Aditya Krishna
  family: Menon
- given: Rob
  family: Fergus
- given: Sanjiv
  family: Kumar
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/kim24ad/kim24ad.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Linear Explanations for Individual Neurons
openreview: WIbntm28cM
abstract: In recent years many methods have been developed to understand the internal
  workings of neural networks, often by describing the function of individual neurons
  in the model. However, these methods typically only focus on explaining the very
  highest activations of a neuron. In this paper we show this is not sufficient, and
  that the highest activation range is only responsible for a very small percentage
  of the neuron’s causal effect. In addition, inputs causing lower activations are
  often very different and can’t be reliably predicted by only looking at high activations.
  We propose that neurons should instead be understood as a linear combination of
  concepts, and develop an efficient method for producing these linear explanations.
  In addition, we show how to automatically evaluate description quality using simulation,
  i.e. predicting neuron activations on unseen inputs in vision setting.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: oikarinen24a
month: 0
tex_title: Linear Explanations for Individual Neurons
firstpage: 38639
lastpage: 38662
page: 38639-38662
order: 38639
cycles: false
bibtex_author: Oikarinen, Tuomas and Weng, Tsui-Wei
author:
- given: Tuomas
  family: Oikarinen
- given: Tsui-Wei
  family: Weng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/oikarinen24a/oikarinen24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Imitation Learning in Discounted Linear MDPs without exploration assumptions
openreview: DChQpB4AJy
abstract: We present a new algorithm for imitation learning in infinite horizon linear
  MDPs dubbed ILARL which greatly improves the bound on the number of trajectories
  that the learner needs to sample from the environment. In particular, we remove
  exploration assumptions required in previous works and we improve the dependence
  on the desired accuracy $\epsilon$ from $\mathcal{O}(\epsilon^{-5})$ to $\mathcal{O}
  (\epsilon^{-4})$. Our result relies on a connection between imitation learning and
  online learning in MDPs with adversarial losses. For the latter setting, we present
  the first result for infinite horizon linear MDP which may be of independent interest.
  Moreover, we are able to provide a strengthen result for the finite horizon case
  where we achieve $\mathcal{O}(\epsilon^{-2})$. Numerical experiments with linear
  function approximation shows that ILARL outperforms other commonly used algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: viano24a
month: 0
tex_title: Imitation Learning in Discounted Linear {MDP}s without exploration assumptions
firstpage: 49471
lastpage: 49505
page: 49471-49505
order: 49471
cycles: false
bibtex_author: Viano, Luca and Skoulakis, Stratis and Cevher, Volkan
author:
- given: Luca
  family: Viano
- given: Stratis
  family: Skoulakis
- given: Volkan
  family: Cevher
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/viano24a/viano24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

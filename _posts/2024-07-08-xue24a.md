---
title: Few-shot Adaptation to Distribution Shifts By Mixing Source and Target Embeddings
openreview: ePDnv4xESI
abstract: Pretrained machine learning models need to be adapted to distribution shifts
  when deployed in new target environments. When obtaining labeled data from the target
  distribution is expensive, few-shot adaptation with only a few examples from the
  target distribution becomes essential. In this work, we propose MixPro, a lightweight
  and highly data-efficient approach for few-shot adaptation. MixPro first generates
  a relatively large dataset by mixing (linearly combining) pre-trained embeddings
  of large source data with those of the few target examples. This process preserves
  important features of both source and target distributions, while mitigating the
  specific noise in the small target data. Then, it trains a linear classifier on
  the mixed embeddings to effectively adapts the model to the target distribution
  without overfitting the small target data. Theoretically, we demonstrate the advantages
  of MixPro over previous methods. Our experiments, conducted across various model
  architectures on 8 datasets featuring different types of distribution shifts, reveal
  that MixPro can outperform baselines by as much as 7%, with only 2-4 target examples.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xue24a
month: 0
tex_title: Few-shot Adaptation to Distribution Shifts By Mixing Source and Target
  Embeddings
firstpage: 55569
lastpage: 55594
page: 55569-55594
order: 55569
cycles: false
bibtex_author: Xue, Yihao and Payani, Ali and Yang, Yu and Mirzasoleiman, Baharan
author:
- given: Yihao
  family: Xue
- given: Ali
  family: Payani
- given: Yu
  family: Yang
- given: Baharan
  family: Mirzasoleiman
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/xue24a/xue24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Split-and-Denoise: Protect large language model inference with local differential
  privacy'
openreview: bZ4fzw1iz7
abstract: Large Language Models (LLMs) excel in natural language understanding by
  capturing hidden semantics in vector space. This process enriches the value of text
  embeddings for various downstream tasks, thereby fostering the Embedding-as-a-Service
  (EaaS) business model. However, the risk of privacy leakage due to direct text transmission
  to servers remains a critical concern. To address this, we introduce Split-N-Denoise
  (SnD), an private inference framework that splits the model to execute the token
  embedding layer on the client side at minimal computational cost. This allows the
  client to introduce noise prior to transmitting the embeddings to the server, and
  subsequently receive and denoise the perturbed output embeddings for downstream
  tasks. Our approach is designed for the inference stage of LLMs and requires no
  modifications to the model parameters. Extensive experiments demonstrate SnDâ€™s effectiveness
  in optimizing the privacy-utility tradeoff across various LLM architectures and
  diverse downstream tasks. The results reveal an improvement in performance under
  the same privacy budget compared to the baselines by over 10% on average, offering
  clients a privacy-preserving solution for local privacy protection.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mai24a
month: 0
tex_title: 'Split-and-Denoise: Protect large language model inference with local differential
  privacy'
firstpage: 34281
lastpage: 34302
page: 34281-34302
order: 34281
cycles: false
bibtex_author: Mai, Peihua and Yan, Ran and Huang, Zhe and Yang, Youjia and Pang,
  Yan
author:
- given: Peihua
  family: Mai
- given: Ran
  family: Yan
- given: Zhe
  family: Huang
- given: Youjia
  family: Yang
- given: Yan
  family: Pang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/mai24a/mai24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Towards Efficient Training and Evaluation of Robust Models against $l_0$ Bounded
  Adversarial Perturbations
openreview: 2bUFIsg2f5
abstract: This work studies sparse adversarial perturbations bounded by $l_0$ norm.
  We propose a white-box PGD-like attack method named sparse-PGD to effectively and
  efficiently generate such perturbations. Furthermore, we combine sparse-PGD with
  a black-box attack to comprehensively and more reliably evaluate the modelsâ€™ robustness
  against $l_0$ bounded adversarial perturbations. Moreover, the efficiency of sparse-PGD
  enables us to conduct adversarial training to build robust models against sparse
  perturbations. Extensive experiments demonstrate that our proposed attack algorithm
  exhibits strong performance in different scenarios. More importantly, compared with
  other robust models, our adversarially trained model demonstrates state-of-the-art
  robustness against various sparse attacks. Codes are available at https://github.com/CityU-MLO/sPGD.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhong24c
month: 0
tex_title: Towards Efficient Training and Evaluation of Robust Models against $l_0$
  Bounded Adversarial Perturbations
firstpage: 61708
lastpage: 61726
page: 61708-61726
order: 61708
cycles: false
bibtex_author: Zhong, Xuyang and Huang, Yixiao and Liu, Chen
author:
- given: Xuyang
  family: Zhong
- given: Yixiao
  family: Huang
- given: Chen
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhong24c/zhong24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

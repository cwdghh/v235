---
title: 'SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting
  with Sharpness-Aware Minimization and Channel-Wise Attention'
openreview: 8kLzL5QBh2
abstract: Transformer-based architectures achieved breakthrough performance in natural
  language processing and computer vision, yet they remain inferior to simpler linear
  baselines in multivariate long-term forecasting. To better understand this phenomenon,
  we start by studying a toy linear forecasting problem for which we show that transformers
  are incapable of converging to their true solution despite their high expressive
  power. We further identify the attention of transformers as being responsible for
  this low generalization capacity. Building upon this insight, we propose a shallow
  lightweight transformer model that successfully escapes bad local minima when optimized
  with sharpness-aware optimization. We empirically demonstrate that this result extends
  to all commonly used real-world multivariate time series datasets. In particular,
  SAMformer surpasses current state-of-the-art methods and is on par with the biggest
  foundation model MOIRAI while having significantly fewer parameters. The code is
  available at https://github.com/romilbert/samformer.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ilbert24a
month: 0
tex_title: "{SAM}former: Unlocking the Potential of Transformers in Time Series Forecasting
  with Sharpness-Aware Minimization and Channel-Wise Attention"
firstpage: 20924
lastpage: 20954
page: 20924-20954
order: 20924
cycles: false
bibtex_author: Ilbert, Romain and Odonnat, Ambroise and Feofanov, Vasilii and Virmaux,
  Aladin and Paolo, Giuseppe and Palpanas, Themis and Redko, Ievgen
author:
- given: Romain
  family: Ilbert
- given: Ambroise
  family: Odonnat
- given: Vasilii
  family: Feofanov
- given: Aladin
  family: Virmaux
- given: Giuseppe
  family: Paolo
- given: Themis
  family: Palpanas
- given: Ievgen
  family: Redko
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/ilbert24a/ilbert24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

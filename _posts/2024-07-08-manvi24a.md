---
title: Large Language Models are Geographically Biased
openreview: sHtIStlg0v
abstract: 'Large Language Models (LLMs) inherently carry the biases contained in their
  training corpora, which can lead to the perpetuation of societal harm. As the impact
  of these foundation models grows, understanding and evaluating their biases becomes
  crucial to achieving fairness and accuracy. We propose to study what LLMs know about
  the world we live in through the lens of geography. This approach is particularly
  powerful as there is ground truth for the numerous aspects of human life that are
  meaningfully projected onto geographic space such as culture, race, language, politics,
  and religion. We show various problematic geographic biases, which we define as
  systemic errors in geospatial predictions. Initially, we demonstrate that LLMs are
  capable of making accurate zero-shot geospatial predictions in the form of ratings
  that show strong monotonic correlation with ground truth (Spearman’s $\rho$ of up
  to 0.89). We then show that LLMs exhibit common biases across a range of objective
  and subjective topics. In particular, LLMs are clearly biased against locations
  with lower socioeconomic conditions (e.g. most of Africa) on a variety of sensitive
  subjective topics such as attractiveness, morality, and intelligence (Spearman’s
  $\rho$ of up to 0.70). Finally, we introduce a bias score to quantify this and find
  that there is significant variation in the magnitude of bias across existing LLMs.
  Code is available on the project website: https://rohinmanvi.github.io/GeoLLM.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: manvi24a
month: 0
tex_title: Large Language Models are Geographically Biased
firstpage: 34654
lastpage: 34669
page: 34654-34669
order: 34654
cycles: false
bibtex_author: Manvi, Rohin and Khanna, Samar and Burke, Marshall and Lobell, David
  B. and Ermon, Stefano
author:
- given: Rohin
  family: Manvi
- given: Samar
  family: Khanna
- given: Marshall
  family: Burke
- given: David B.
  family: Lobell
- given: Stefano
  family: Ermon
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/manvi24a/manvi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'QuRating: Selecting High-Quality Data for Training Language Models'
openreview: GLGYYqPwjy
abstract: Selecting high-quality pre-training data is important for creating capable
  language models, but existing methods rely on simple heuristics. We introduce QuRating,
  a method for selecting pre-training data that can capture human intuitions about
  data quality. In this paper, we investigate four qualities - writing style, required
  expertise, facts & trivia, and educational value - and find that LLMs are able to
  discern these qualities, especially when making pairwise judgments of texts. We
  train a QuRater model to learn scalar ratings from pairwise judgments, and use it
  to annotate a 260B training corpus with quality ratings for each of the four criteria.
  In our experiments, we select 30B tokens according to the different quality ratings
  and train 1.3B-parameter language models on the selected data. We find that it is
  important to balance quality and diversity. When we sample using quality ratings
  as logits over documents, our models obtain lower perplexity and stronger in-context
  learning performance than baselines. Our best model is based on educational value
  and performs similarly to a model trained with uniform sampling for 50% more steps.
  Beyond data selection, we use the quality ratings to construct a training curriculum
  which improves performance without changing the training dataset. We extensively
  analyze the quality ratings and discuss their characteristics, biases, and wider
  implications.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wettig24a
month: 0
tex_title: "{Q}u{R}ating: Selecting High-Quality Data for Training Language Models"
firstpage: 52915
lastpage: 52971
page: 52915-52971
order: 52915
cycles: false
bibtex_author: Wettig, Alexander and Gupta, Aatmik and Malik, Saumya and Chen, Danqi
author:
- given: Alexander
  family: Wettig
- given: Aatmik
  family: Gupta
- given: Saumya
  family: Malik
- given: Danqi
  family: Chen
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/wettig24a/wettig24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

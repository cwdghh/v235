---
title: 'ODIN: Disentangled Reward Mitigates Hacking in RLHF'
openreview: zcIV8OQFVF
abstract: In this work, we study the issue of reward hacking on the response length,
  a challenge emerging in Reinforcement Learning from Human Feedback (RLHF) on LLMs.
  A well-formatted, verbose but less helpful response from the LLMs can often deceive
  LLMs or even human evaluators and achieve high scores. The same issue also holds
  for some reward models in RL. To address the challenges in both training and evaluation,
  we establish a more reliable evaluation protocol for comparing different training
  configurations, which inspects the trade-off between LLM evaluation score and response
  length obtained by varying training hyperparameters. Based on this evaluation, we
  conduct large-scale studies, where the results shed insights into the efficacy of
  hyperparameters and tricks used in RL on mitigating length bias. We further propose
  to improve the reward model by jointly training two linear heads to predict the
  preference, one trained to correlate with length and the other trained to decorrelate
  with length and therefore focusing more on the actual content. We then discard the
  length head in RL to ignore the spurious length reward. Experiments demonstrate
  that our approach eliminates the reward correlation with length, and improves the
  obtained policy by a significant margin.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24bn
month: 0
tex_title: "{ODIN}: Disentangled Reward Mitigates Hacking in {RLHF}"
firstpage: 7935
lastpage: 7952
page: 7935-7952
order: 7935
cycles: false
bibtex_author: Chen, Lichang and Zhu, Chen and Chen, Jiuhai and Soselia, Davit and
  Zhou, Tianyi and Goldstein, Tom and Huang, Heng and Shoeybi, Mohammad and Catanzaro,
  Bryan
author:
- given: Lichang
  family: Chen
- given: Chen
  family: Zhu
- given: Jiuhai
  family: Chen
- given: Davit
  family: Soselia
- given: Tianyi
  family: Zhou
- given: Tom
  family: Goldstein
- given: Heng
  family: Huang
- given: Mohammad
  family: Shoeybi
- given: Bryan
  family: Catanzaro
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24bn/chen24bn.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

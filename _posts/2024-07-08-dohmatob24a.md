---
title: 'Consistent Adversarially Robust Linear Classification: Non-Parametric Setting'
openreview: MV2b44zDd3
abstract: For binary classification in $d$ dimensions, it is known that with a sample
  size of $n$, an excess adversarial risk of $O(d/n)$ is achievable under strong parametric
  assumptions about the underlying data distribution (e.g., assuming a Gaussian mixture
  model). In the case of well-separated distributions, this rate can be further refined
  to $O(1/n)$. Our work studies the non-parametric setting, where very little is known.
  With only mild regularity conditions on the conditional distribution of the features,
  we examine adversarial attacks with respect to arbitrary norms and introduce a straightforward
  yet effective estimator with provable consistency w.r.t adversarial risk. Our estimator
  is given by minimizing a series of smoothed versions of the robust 0/1 loss, with
  a smoothing bandwidth that adapts to both $n$ and $d$. Furthermore, we demonstrate
  that our estimator can achieve the minimax excess adversarial risk of $\widetilde
  O(\sqrt{d/n})$ for linear classifiers, at the cost of solving possibly rougher optimization
  problems.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dohmatob24a
month: 0
tex_title: 'Consistent Adversarially Robust Linear Classification: Non-Parametric
  Setting'
firstpage: 11149
lastpage: 11164
page: 11149-11164
order: 11149
cycles: false
bibtex_author: Dohmatob, Elvis
author:
- given: Elvis
  family: Dohmatob
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/dohmatob24a/dohmatob24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

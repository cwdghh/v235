---
title: 'RoboMP$^2$: A Robotic Multimodal Perception-Planning Framework with Multimodal
  Large Language Models'
openreview: eJFQROkaj0
abstract: Multimodal Large Language Models (MLLMs) have shown impressive reasoning
  abilities and general intelligence in various domains. It inspires researchers to
  train end-to-end MLLMs or utilize large models to generate policies with human-selected
  prompts for embodied agents. However, these methods exhibit limited generalization
  capabilities on unseen tasks or scenarios, and overlook the multimodal environment
  information which is critical for robots to make decisions. In this paper, we introduce
  a novel <b>Robo</b>tic <b>M</b>ultimodal <b>P</b>erception-<b>P</b>lanning (<b>RoboMP$^2$</b>)
  framework for robotic manipulation which consists of a Goal-Conditioned Multimodal
  Preceptor (GCMP) and a Retrieval-Augmented Multimodal Planner (RAMP). Specially,
  GCMP captures environment states by employing a tailored MLLMs for embodied agents
  with the abilities of semantic reasoning and localization. RAMP utilizes coarse-to-fine
  retrieval method to find the $k$ most-relevant policies as in-context demonstrations
  to enhance the planner. Extensive experiments demonstrate the superiority of RoboMP$^2$
  on both VIMA benchmark and real-world tasks, with around 10% improvement over the
  baselines.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lv24a
month: 0
tex_title: "{R}obo{MP}$^2$: A Robotic Multimodal Perception-Planning Framework with
  Multimodal Large Language Models"
firstpage: 33558
lastpage: 33574
page: 33558-33574
order: 33558
cycles: false
bibtex_author: Lv, Qi and Li, Hao and Deng, Xiang and Shao, Rui and Wang, Michael
  Y and Nie, Liqiang
author:
- given: Qi
  family: Lv
- given: Hao
  family: Li
- given: Xiang
  family: Deng
- given: Rui
  family: Shao
- given: Michael Y
  family: Wang
- given: Liqiang
  family: Nie
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/lv24a/lv24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

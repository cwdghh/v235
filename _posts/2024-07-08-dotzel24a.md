---
title: 'Learning from Students: Applying t-Distributions to Explore Accurate and Efficient
  Formats for LLMs'
openreview: iJlPJsTw2B
abstract: The increasing size of large language models (LLMs) traditionally requires
  low-precision integer formats to meet strict latency and power demands. Yet recently,
  alternative formats such as Normal Float (NF4) have increased model accuracy at
  the cost of increased chip area. In this work, we first conduct a large-scale analysis
  of LLM weights and activations across 30 networks and conclude that most distributions
  follow a Studentâ€™s t-distribution. We then derive a new theoretically optimal format,
  Student Float (SF4), that improves over NF4 across modern LLMs, for example increasing
  the average accuracy on LLaMA2-7B by 0.76% across tasks. Using this format as a
  high-accuracy reference, we then propose augmenting E2M1 with two variants of <em>supernormal</em>
  support for higher model accuracy. Finally, we explore the quality and efficiency
  frontier across 11 datatypes by evaluating their model accuracy and hardware complexity.
  We discover a Pareto curve composed of INT4, E2M1, and E2M1 with supernormal support,
  which offers a continuous tradeoff between model accuracy and chip area. For example,
  E2M1 with supernormal support increases the accuracy of Phi-2 by up to 2.19% with
  1.22% area overhead, enabling more LLM-based applications to be run at four bits.
  The supporting code is hosted at https://github.com/cornell-zhang/llm-datatypes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dotzel24a
month: 0
tex_title: 'Learning from Students: Applying t-Distributions to Explore Accurate and
  Efficient Formats for {LLM}s'
firstpage: 11573
lastpage: 11591
page: 11573-11591
order: 11573
cycles: false
bibtex_author: Dotzel, Jordan and Chen, Yuzong and Kotb, Bahaa and Prasad, Sushma
  and Wu, Gang and Li, Sheng and Abdelfattah, Mohamed S and Zhang, Zhiru
author:
- given: Jordan
  family: Dotzel
- given: Yuzong
  family: Chen
- given: Bahaa
  family: Kotb
- given: Sushma
  family: Prasad
- given: Gang
  family: Wu
- given: Sheng
  family: Li
- given: Mohamed S
  family: Abdelfattah
- given: Zhiru
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/dotzel24a/dotzel24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

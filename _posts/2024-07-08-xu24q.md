---
title: Low-Rank Similarity Mining for Multimodal Dataset Distillation
openreview: mY93trX2Qz
abstract: Though dataset distillation has witnessed rapid development in recent years,
  the distillation of multimodal data, e.g., image-text pairs, poses unique and under-explored
  challenges. Unlike unimodal data, image-text contrastive learning (ITC) data lack
  inherent categorization and should instead place greater emphasis on modality correspondence.
  In this work, we propose <b>Lo</b>w-<b>R</b>ank <b>S</b>imilarity Mining (<b>LoRS</b>)
  for multimodal dataset distillation, that concurrently distills a ground truth similarity
  matrix with image-text pairs, and leverages low-rank factorization for efficiency
  and scalability. The proposed approach brings significant improvement to the existing
  algorithms, marking a significant contribution to the field of visual-language dataset
  distillation. We advocate adopting LoRS as a foundational synthetic data setup for
  image-text dataset distillation. Our code is available at https://github.com/silicx/LoRS_Distill.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu24q
month: 0
tex_title: Low-Rank Similarity Mining for Multimodal Dataset Distillation
firstpage: 55144
lastpage: 55161
page: 55144-55161
order: 55144
cycles: false
bibtex_author: Xu, Yue and Lin, Zhilin and Qiu, Yusong and Lu, Cewu and Li, Yong-Lu
author:
- given: Yue
  family: Xu
- given: Zhilin
  family: Lin
- given: Yusong
  family: Qiu
- given: Cewu
  family: Lu
- given: Yong-Lu
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/xu24q/xu24q.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

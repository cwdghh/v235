---
title: Convergence and Trade-Offs in Riemannian Gradient Descent and Riemannian Proximal
  Point
openreview: ltb2XaIr9p
abstract: 'In this work, we analyze two of the most fundamental algorithms in geodesically
  convex optimization: Riemannian gradient descent and (possibly inexact) Riemannian
  proximal point. We quantify their rates of convergence and produce different variants
  with several trade-offs. Crucially, we show the iterates naturally stay in a ball
  around an optimizer, of radius depending on the initial distance and, in some cases,
  on the curvature. Previous works simply assumed bounded iterates, resulting in rates
  that were not fully quantified. We also provide an implementable inexact proximal
  point algorithm and prove several new useful properties of Riemannian proximal methods:
  they work when positive curvature is present, the proximal operator does not move
  points away from any optimizer, and we quantify the smoothness of its induced Moreau
  envelope. Further, we explore beyond our theory with empirical tests.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: marti-nez-rubio24a
month: 0
tex_title: Convergence and Trade-Offs in {R}iemannian Gradient Descent and {R}iemannian
  Proximal Point
firstpage: 34920
lastpage: 34948
page: 34920-34948
order: 34920
cycles: false
bibtex_author: Mart\'{\i}nez-Rubio, David and Roux, Christophe and Pokutta, Sebastian
author:
- given: David
  family: Martı́nez-Rubio
- given: Christophe
  family: Roux
- given: Sebastian
  family: Pokutta
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/marti-nez-rubio24a/marti-nez-rubio24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

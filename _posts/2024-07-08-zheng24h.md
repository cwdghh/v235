---
title: 'ESM All-Atom: Multi-Scale Protein Language Model for Unified Molecular Modeling'
openreview: 283cGgWfM2
abstract: Protein language models have demonstrated significant potential in the field
  of protein engineering. However, current protein language models primarily operate
  at the residue scale, which limits their ability to provide information at the atom
  level. This limitation prevents us from fully exploiting the capabilities of protein
  language models for applications involving both proteins and small molecules. In
  this paper, we propose ESM-AA (ESM All-Atom), a novel approach that enables atom-scale
  and residue-scale unified molecular modeling. ESM-AA achieves this by pre-training
  on multi-scale code-switch protein sequences and utilizing a multi-scale position
  encoding to capture relationships among residues and atoms. Experimental results
  indicate that ESM-AA surpasses previous methods in protein-molecule tasks, demonstrating
  the full utilization of protein language models. Further investigations reveal that
  through unified molecular modeling, ESM-AA not only gains molecular knowledge but
  also retains its understanding of proteins.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zheng24h
month: 0
tex_title: "{ESM} All-Atom: Multi-Scale Protein Language Model for Unified Molecular
  Modeling"
firstpage: 61432
lastpage: 61453
page: 61432-61453
order: 61432
cycles: false
bibtex_author: Zheng, Kangjie and Long, Siyu and Lu, Tianyu and Yang, Junwei and Dai,
  Xinyu and Zhang, Ming and Nie, Zaiqing and Ma, Wei-Ying and Zhou, Hao
author:
- given: Kangjie
  family: Zheng
- given: Siyu
  family: Long
- given: Tianyu
  family: Lu
- given: Junwei
  family: Yang
- given: Xinyu
  family: Dai
- given: Ming
  family: Zhang
- given: Zaiqing
  family: Nie
- given: Wei-Ying
  family: Ma
- given: Hao
  family: Zhou
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zheng24h/zheng24h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

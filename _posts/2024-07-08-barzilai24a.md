---
title: Generalization in Kernel Regression Under Realistic Assumptions
openreview: PY3bKuorBI
abstract: It is by now well-established that modern over-parameterized models seem
  to elude the bias-variance tradeoff and generalize well despite overfitting noise.
  Many recent works attempt to analyze this phenomenon in the relatively tractable
  setting of kernel regression. However, as we argue in detail, most past works on
  this topic either make unrealistic assumptions, or focus on a narrow problem setup.
  This work aims to provide a unified theory to upper bound the excess risk of kernel
  regression for nearly all common and realistic settings. When applied to common
  kernels, our results imply benign overfitting in high input dimensions, nearly tempered
  overfitting in fixed dimensions, and explicit convergence rates for regularized
  regression. As a by-product, we obtain time-dependent bounds for neural networks
  trained in the kernel regime. Our results rely on new relative perturbation bounds
  for the eigenvalues of kernel matrices, which may be of independent interest. These
  reveal a self-regularization phenomenon, whereby a heavy tail in the eigendecomposition
  of the kernel implicitly leads to good generalization.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: barzilai24a
month: 0
tex_title: Generalization in Kernel Regression Under Realistic Assumptions
firstpage: 3096
lastpage: 3132
page: 3096-3132
order: 3096
cycles: false
bibtex_author: Barzilai, Daniel and Shamir, Ohad
author:
- given: Daniel
  family: Barzilai
- given: Ohad
  family: Shamir
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/barzilai24a/barzilai24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Online Speculative Decoding
openreview: BPQHXwVNvl
abstract: Speculative decoding is a pivotal technique to accelerate the inference
  of large language models (LLMs) by employing a smaller draft model to predict the
  target model’s outputs. However, its efficacy can be limited due to the low predictive
  accuracy of the draft model, particularly when faced with diverse text inputs and
  a significant capability gap between the draft and target models. We introduce online
  speculative decoding to address this challenge. The main idea is to continuously
  update the (multiple) draft model(s) on observed user query data. Adapting to query
  distribution mitigates the shifts between the training distribution of the draft
  model and the query distribution, enabling the draft model to more accurately predict
  the target model’s outputs. We develop a prototype of online speculative decoding
  based on knowledge distillation and evaluate it using both synthetic and real query
  data. The results show a substantial increase in the token acceptance rate by 0.1
  to 0.65, bringing 1.42x to 2.17x latency reduction. Our code is available at https://github.com/LiuXiaoxuanPKU/OSD.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24y
month: 0
tex_title: Online Speculative Decoding
firstpage: 31131
lastpage: 31146
page: 31131-31146
order: 31131
cycles: false
bibtex_author: Liu, Xiaoxuan and Hu, Lanxiang and Bailis, Peter and Cheung, Alvin
  and Deng, Zhijie and Stoica, Ion and Zhang, Hao
author:
- given: Xiaoxuan
  family: Liu
- given: Lanxiang
  family: Hu
- given: Peter
  family: Bailis
- given: Alvin
  family: Cheung
- given: Zhijie
  family: Deng
- given: Ion
  family: Stoica
- given: Hao
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24y/liu24y.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

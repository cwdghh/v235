---
title: 'Fair Risk Control: A Generalized Framework for Calibrating Multi-group Fairness
  Risks'
openreview: 6KtXzUUEp4
abstract: This paper introduces a framework for post-processing machine learning models
  so that their predictions satisfy multi-group fairness guarantees. Based on the
  celebrated notion of multicalibration, we introduce $(s,g,\alpha)-$GMC (Generalized
  Multi-Dimensional Multicalibration) for multi-dimensional mappings $s$, constraints
  $g$, and a pre-specified threshold level $\alpha$. We propose associated algorithms
  to achieve this notion in general settings. This framework is then applied to diverse
  scenarios encompassing different fairness concerns, including false negative rate
  control in image segmentation, prediction set conditional uncertainty quantification
  in hierarchical classification, and de-biased text generation in language models.
  We conduct numerical studies on several datasets and tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24be
month: 0
tex_title: 'Fair Risk Control: A Generalized Framework for Calibrating Multi-group
  Fairness Risks'
firstpage: 59783
lastpage: 59805
page: 59783-59805
order: 59783
cycles: false
bibtex_author: Zhang, Lujing and Roth, Aaron and Zhang, Linjun
author:
- given: Lujing
  family: Zhang
- given: Aaron
  family: Roth
- given: Linjun
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhang24be/zhang24be.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

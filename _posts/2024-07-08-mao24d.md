---
title: Regression with Multi-Expert Deferral
openreview: 5NTTCCO74S
abstract: Learning to defer with multiple experts is a framework where the learner
  can choose to defer the prediction to several experts. While this problem has received
  significant attention in classification contexts, it presents unique challenges
  in regression due to the infinite and continuous nature of the label space. In this
  work, we introduce a novel framework of <em>regression with deferral</em>, which
  involves deferring the prediction to multiple experts. We present a comprehensive
  analysis for both the single-stage scenario, where there is simultaneous learning
  of predictor and deferral functions, and the two-stage scenario, which involves
  a pre-trained predictor with a learned deferral function. We introduce new surrogate
  loss functions for both scenarios and prove that they are supported by $H$-consistency
  bounds. These bounds provide consistency guarantees that are stronger than Bayes
  consistency, as they are non-asymptotic and hypothesis set-specific. Our framework
  is versatile, applying to multiple experts, accommodating any bounded regression
  losses, addressing both instance-dependent and label-dependent costs, and supporting
  both single-stage and two-stage methods. Our single-stage formulation subsumes as
  a special case the recent <em>regression with abstention</em> (Cheng et al., 2023)
  framework, where only a single expert is considered, specifically for the squared
  loss and a label-independent cost. Minimizing our proposed loss functions directly
  leads to novel algorithms for regression with deferral. We report the results of
  extensive experiments showing the effectiveness of our proposed algorithms.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mao24d
month: 0
tex_title: Regression with Multi-Expert Deferral
firstpage: 34738
lastpage: 34759
page: 34738-34759
order: 34738
cycles: false
bibtex_author: Mao, Anqi and Mohri, Mehryar and Zhong, Yutao
author:
- given: Anqi
  family: Mao
- given: Mehryar
  family: Mohri
- given: Yutao
  family: Zhong
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/mao24d/mao24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

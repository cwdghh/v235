---
title: 'MEMORYLLM: Towards Self-Updatable Large Language Models'
openreview: p0lKWzdikQ
abstract: Existing Large Language Models (LLMs) usually remain static after deployment,
  which might make it hard to inject new knowledge into the model. We aim to build
  models containing a considerable portion of self-updatable parameters, enabling
  the model to integrate new knowledge effectively and efficiently. To this end, we
  introduce MEMORYLLM, a model that comprises a transformer and a fixed-size memory
  pool within the latent space of the transformer. MEMORYLLM can self-update with
  text knowledge and memorize the knowledge injected earlier. Our evaluations demonstrate
  the ability of MEMORYLLM to effectively incorporate new knowledge, as evidenced
  by its performance on model editing benchmarks. Meanwhile, the model exhibits long-term
  information retention capacity, which is validated through our custom-designed evaluations
  and long-context benchmarks. MEMORYLLM also shows operational integrity without
  any sign of performance degradation even after nearly a million memory updates.
  Our code and model are open-sourced at https://github.com/wangyu-ustc/MemoryLLM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24s
month: 0
tex_title: "{MEMORYLLM}: Towards Self-Updatable Large Language Models"
firstpage: 50453
lastpage: 50466
page: 50453-50466
order: 50453
cycles: false
bibtex_author: Wang, Yu and Gao, Yifan and Chen, Xiusi and Jiang, Haoming and Li,
  Shiyang and Yang, Jingfeng and Yin, Qingyu and Li, Zheng and Li, Xian and Yin, Bing
  and Shang, Jingbo and Mcauley, Julian
author:
- given: Yu
  family: Wang
- given: Yifan
  family: Gao
- given: Xiusi
  family: Chen
- given: Haoming
  family: Jiang
- given: Shiyang
  family: Li
- given: Jingfeng
  family: Yang
- given: Qingyu
  family: Yin
- given: Zheng
  family: Li
- given: Xian
  family: Li
- given: Bing
  family: Yin
- given: Jingbo
  family: Shang
- given: Julian
  family: Mcauley
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/wang24s/wang24s.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

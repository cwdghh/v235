---
title: Exploiting Human-AI Dependence for Learning to Defer
openreview: aiz79FxjaI
abstract: The learning to defer (L2D) framework allows models to defer their decisions
  to human experts. For L2D, the Bayes optimality is the basic requirement of theoretical
  guarantees for the design of consistent surrogate loss functions, which requires
  the minimizer (i.e., learned classifier) by the surrogate loss to be the Bayes optimality.
  However, we find that the original form of Bayes optimality fails to consider the
  dependence between the model and the expert, and such a dependence could be further
  exploited to design a better consistent loss for L2D. In this paper, we provide
  a new formulation for the Bayes optimality called dependent Bayes optimality, which
  reveals the dependence pattern in determining whether to defer. Based on the dependent
  Bayes optimality, we further present a deferral principle for L2D. Following the
  guidance of the deferral principle, we propose a novel consistent surrogate loss.
  Comprehensive experimental results on both synthetic and real-world datasets demonstrate
  the superiority of our proposed method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wei24a
month: 0
tex_title: Exploiting Human-{AI} Dependence for Learning to Defer
firstpage: 52484
lastpage: 52499
page: 52484-52499
order: 52484
cycles: false
bibtex_author: Wei, Zixi and Cao, Yuzhou and Feng, Lei
author:
- given: Zixi
  family: Wei
- given: Yuzhou
  family: Cao
- given: Lei
  family: Feng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wei24a/wei24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

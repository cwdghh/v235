---
title: One Meta-tuned Transformer is What You Need for Few-shot Learning
openreview: 01ahsMovBx
abstract: Pre-trained vision transformers have revolutionized few-shot image classification,
  and it has been recently demonstrated that the previous common practice of meta-learning
  in synergy with these pre-trained transformers still holds significance. In this
  work, we design a new framework centered exclusively on self-attention, called MetaFormer,
  which extends the vision transformers beyond patch token interactions to encompass
  relationships between samples and tasks simultaneously for further advancing their
  downstream task performance. Leveraging the intrinsical property of ViTs in handling
  local patch relationships, we propose Masked Sample Attention (MSA) to efficiently
  embed the sample relationships into the network, where an adaptive mask is attached
  for enhancing task-specific feature consistency and providing flexibility in switching
  between few-shot learning setups. To encapsulate task relationships while filtering
  out background noise, Patch-grained Task Attention (PTA) is designed to maintain
  a dynamic knowledge pool consolidating diverse patterns from historical tasks. MetaFormer
  demonstrates coherence and compatibility with off-the-shelf pre-trained vision transformers
  and shows significant improvements in both inductive and transductive few-shot learning
  scenarios, outperforming state-of-the-art methods by up to 8.77% and 6.25% on 12
  in-domain and 10 cross-domain datasets, respectively.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang24ah
month: 0
tex_title: One Meta-tuned Transformer is What You Need for Few-shot Learning
firstpage: 56681
lastpage: 56703
page: 56681-56703
order: 56681
cycles: false
bibtex_author: Yang, Xu and Yao, Huaxiu and Wei, Ying
author:
- given: Xu
  family: Yang
- given: Huaxiu
  family: Yao
- given: Ying
  family: Wei
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/yang24ah/yang24ah.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

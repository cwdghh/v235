---
title: Mastering Robot Manipulation with Multimodal Prompts through Pretraining and
  Multi-task Fine-tuning
openreview: xIRKB5nRJl
abstract: Prompt-based learning has been demonstrated as a compelling paradigm contributing
  to large language models’ tremendous success (LLMs). Inspired by their success in
  language tasks, existing research has leveraged LLMs in embodied instruction following
  and task planning. In this work, we tackle the problem of training a robot to understand
  multimodal prompts, interleaving vision signals with text descriptions. This type
  of task poses a major challenge to robots’ capability to understand the interconnection
  and complementarity between vision and language signals. In this work, we introduce
  an effective framework that learns a policy to perform robot manipulation with multimodal
  prompts from multi-task expert trajectories. Our methods consist of a two-stage
  training pipeline that performs inverse dynamics pretraining and multi-task finetuning.
  To facilitate multimodal understanding, we design our multimodal prompt encoder
  by augmenting a pretrained LM with a residual connection to the visual input and
  model the dependencies among action dimensions. Empirically, we evaluate the efficacy
  of our method on the VIMA-BENCH and establish a new state-of-the-art (10% improvement
  in success rate). Moreover, we demonstrate that our model exhibits remarkable in-context
  learning ability.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24x
month: 0
tex_title: Mastering Robot Manipulation with Multimodal Prompts through Pretraining
  and Multi-task Fine-tuning
firstpage: 27822
lastpage: 27845
page: 27822-27845
order: 27822
cycles: false
bibtex_author: Li, Jiachen and Gao, Qiaozi and Johnston, Michael and Gao, Xiaofeng
  and He, Xuehai and Shi, Hangjie and Shakiah, Suhaila and Ghanadan, Reza and Wang,
  William Yang
author:
- given: Jiachen
  family: Li
- given: Qiaozi
  family: Gao
- given: Michael
  family: Johnston
- given: Xiaofeng
  family: Gao
- given: Xuehai
  family: He
- given: Hangjie
  family: Shi
- given: Suhaila
  family: Shakiah
- given: Reza
  family: Ghanadan
- given: William Yang
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/li24x/li24x.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

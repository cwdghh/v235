---
title: Balanced Resonate-and-Fire Neurons
openreview: dkdilv4XD4
abstract: The resonate-and-fire (RF) neuron, introduced over two decades ago, is a
  simple, efficient, yet biologically plausible spiking neuron model, which can extract
  frequency patterns within the time domain due to its resonating membrane dynamics.
  However, previous RF formulations suffer from intrinsic shortcomings that limit
  effective learning and prevent exploiting the principled advantage of RF neurons.
  Here, we introduce the balanced RF (BRF) neuron, which alleviates some of the intrinsic
  limitations of vanilla RF neurons and demonstrates its effectiveness within recurrent
  spiking neural networks (RSNNs) on various sequence learning tasks. We show that
  networks of BRF neurons achieve overall higher task performance, produce only a
  fraction of the spikes, and require significantly fewer parameters as compared to
  modern RSNNs. Moreover, BRF-RSNN consistently provide much faster and more stable
  training convergence, even when bridging many hundreds of time steps during backpropagation
  through time (BPTT). These results underscore that our BRF-RSNN is a strong candidate
  for future large-scale RSNN architectures, further lines of research in SNN methodology,
  and more efficient hardware implementations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: higuchi24a
month: 0
tex_title: Balanced Resonate-and-Fire Neurons
firstpage: 18305
lastpage: 18323
page: 18305-18323
order: 18305
cycles: false
bibtex_author: Higuchi, Saya and Kairat, Sebastian and Bohte, Sander and Otte, Sebastian
author:
- given: Saya
  family: Higuchi
- given: Sebastian
  family: Kairat
- given: Sander
  family: Bohte
- given: Sebastian
  family: Otte
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/higuchi24a/higuchi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

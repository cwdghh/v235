---
title: Unified Training of Universal Time Series Forecasting Transformers
openreview: Yd8eHMY1wz
abstract: 'Deep learning for time series forecasting has traditionally operated within
  a one-model-per-dataset framework, limiting its potential to leverage the game-changing
  impact of large pre-trained models. The concept of <em>universal forecasting</em>,
  emerging from pre-training on a vast collection of time series datasets, envisions
  a single Large Time Series Model capable of addressing diverse downstream forecasting
  tasks. However, constructing such a model poses unique challenges specific to time
  series data: (i) cross-frequency learning, (ii) accommodating an arbitrary number
  of variates for multivariate time series, and (iii) addressing the varying distributional
  properties inherent in large-scale data. To address these challenges, we present
  novel enhancements to the conventional time series Transformer architecture, resulting
  in our proposed <b>M</b>asked Enc<b>o</b>der-based Un<b>i</b>ve<b>r</b>s<b>a</b>l
  T<b>i</b>me Series Forecasting Transformer (<b>Moirai</b>). Trained on our newly
  introduced Large-scale Open Time Series Archive (LOTSA) featuring over 27B observations
  across nine domains, Moirai achieves competitive or superior performance as a zero-shot
  forecaster when compared to full-shot models. Code, data, and model weights can
  be found at https://github.com/SalesforceAIResearch/uni2ts.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: woo24a
month: 0
tex_title: Unified Training of Universal Time Series Forecasting Transformers
firstpage: 53140
lastpage: 53164
page: 53140-53164
order: 53140
cycles: false
bibtex_author: Woo, Gerald and Liu, Chenghao and Kumar, Akshat and Xiong, Caiming
  and Savarese, Silvio and Sahoo, Doyen
author:
- given: Gerald
  family: Woo
- given: Chenghao
  family: Liu
- given: Akshat
  family: Kumar
- given: Caiming
  family: Xiong
- given: Silvio
  family: Savarese
- given: Doyen
  family: Sahoo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/woo24a/woo24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

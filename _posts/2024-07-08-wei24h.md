---
title: 'Magicoder: Empowering Code Generation with OSS-Instruct'
openreview: XUeoOBid3x
abstract: We introduce Magicoder, a series of fully open-source (code, weights, and
  data) Large Language Models (LLMs) for code that significantly closes the gap with
  top code models while having no more than 7B parameters. Magicoder models are trained
  on 75K synthetic instruction data using <b>OSS-Instruct</b>, a novel approach to
  enlightening LLMs with open-source code snippets to generate diverse instruction
  data for code. Our main motivation is to mitigate the inherent bias of the synthetic
  data generated by LLMs through the wealth of open-source references for the production
  of more realistic and controllable data. The orthogonality of OSS-Instruct and other
  data generation methods like Evol-Instruct further enables us to build an enhanced
  MagicoderS. Both Magicoder and MagicoderS substantially outperform state-of-the-art
  code models with similar or even larger sizes on a wide range of coding benchmarks.
  Notably, MagicoderS-CL-7B based on CodeLlama even surpasses the prominent ChatGPT
  on HumanEval+ (66.5 vs. 65.9 in pass@1 ). Overall, OSS-Instruct opens a new direction
  for crafting diverse synthetic instruction data for code using abundant open-source
  references.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wei24h
month: 0
tex_title: 'Magicoder: Empowering Code Generation with {OSS}-Instruct'
firstpage: 52632
lastpage: 52657
page: 52632-52657
order: 52632
cycles: false
bibtex_author: Wei, Yuxiang and Wang, Zhe and Liu, Jiawei and Ding, Yifeng and Zhang,
  Lingming
author:
- given: Yuxiang
  family: Wei
- given: Zhe
  family: Wang
- given: Jiawei
  family: Liu
- given: Yifeng
  family: Ding
- given: Lingming
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wei24h/wei24h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

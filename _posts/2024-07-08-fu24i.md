---
title: Towards Theoretical Understandings of Self-Consuming Generative Models
openreview: aw6L8sB2Ts
abstract: This paper tackles the emerging challenge of training generative models
  within a self-consuming loop, wherein successive generations of models are recursively
  trained on mixtures of real and synthetic data from previous generations. We construct
  a theoretical framework to rigorously evaluate how this training procedure impacts
  the data distributions learned by future models, including parametric and non-parametric
  models. Specifically, we derive bounds on the total variation (TV) distance between
  the synthetic data distributions produced by future models and the original real
  data distribution under various mixed training scenarios for diffusion models with
  a one-hidden-layer neural network score function. Our analysis demonstrates that
  this distance can be effectively controlled under the condition that mixed training
  dataset sizes or proportions of real data are large enough. Interestingly, we further
  unveil a phase transition induced by expanding synthetic data amounts, proving theoretically
  that while the TV distance exhibits an initial ascent, it declines beyond a threshold
  point. Finally, we present results for kernel density estimation, delivering nuanced
  insights such as the impact of mixed data training on error propagation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: fu24i
month: 0
tex_title: Towards Theoretical Understandings of Self-Consuming Generative Models
firstpage: 14228
lastpage: 14255
page: 14228-14255
order: 14228
cycles: false
bibtex_author: Fu, Shi and Zhang, Sen and Wang, Yingjie and Tian, Xinmei and Tao,
  Dacheng
author:
- given: Shi
  family: Fu
- given: Sen
  family: Zhang
- given: Yingjie
  family: Wang
- given: Xinmei
  family: Tian
- given: Dacheng
  family: Tao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/fu24i/fu24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

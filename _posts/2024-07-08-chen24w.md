---
title: Offline Transition Modeling via Contrastive Energy Learning
openreview: dqpg8jdA2w
abstract: Learning a high-quality transition model is of great importance for sequential
  decision-making tasks, especially in offline settings. Nevertheless, the complex
  behaviors of transition dynamics in real-world environments pose challenges for
  the standard forward models because of their inductive bias towards smooth regressors,
  conflicting with the inherent nature of transitions such as discontinuity or large
  curvature. In this work, we propose to model the transition probability implicitly
  through a scalar-value energy function, which enables not only flexible distribution
  prediction but also capturing complex transition behaviors. The Energy-based Transition
  Models (ETM) are shown to accurately fit the discontinuous transition functions
  and better generalize to out-of-distribution transition data. Furthermore, we demonstrate
  that energy-based transition models improve the evaluation accuracy and significantly
  outperform other off-policy evaluation methods in DOPE benchmark. Finally, we show
  that energy-based transition models also benefit reinforcement learning and outperform
  prior offline RL algorithms in D4RL Gym-Mujoco tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24w
month: 0
tex_title: Offline Transition Modeling via Contrastive Energy Learning
firstpage: 6992
lastpage: 7014
page: 6992-7014
order: 6992
cycles: false
bibtex_author: Chen, Ruifeng and Jia, Chengxing and Huang, Zefang and Liu, Tian-Shuo
  and Liu, Xu-Hui and Yu, Yang
author:
- given: Ruifeng
  family: Chen
- given: Chengxing
  family: Jia
- given: Zefang
  family: Huang
- given: Tian-Shuo
  family: Liu
- given: Xu-Hui
  family: Liu
- given: Yang
  family: Yu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24w/chen24w.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

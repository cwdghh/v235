---
title: Mitigating Oversmoothing Through Reverse Process of GNNs for Heterophilic Graphs
openreview: RLA4JTckXe
abstract: Graph Neural Network (GNN) resembles the diffusion process, leading to the
  over-smoothing of learned representations when stacking many layers. Hence, the
  reverse process of message passing can produce the distinguishable node representations
  by inverting the forward message propagation. The distinguishable representations
  can help us to better classify neighboring nodes with different labels, such as
  in heterophilic graphs. In this work, we apply the design principle of the reverse
  process to the three variants of the GNNs. Through the experiments on heterophilic
  graph data, where adjacent nodes need to have different representations for successful
  classification, we show that the reverse process significantly improves the prediction
  performance in many cases. Additional analysis reveals that the reverse mechanism
  can mitigate the over-smoothing over hundreds of layers. Our code is available at
  https://github.com/ml-postech/reverse-gnn.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: park24d
month: 0
tex_title: Mitigating Oversmoothing Through Reverse Process of {GNN}s for Heterophilic
  Graphs
firstpage: 39667
lastpage: 39681
page: 39667-39681
order: 39667
cycles: false
bibtex_author: Park, Moonjeong and Heo, Jaeseung and Kim, Dongwoo
author:
- given: Moonjeong
  family: Park
- given: Jaeseung
  family: Heo
- given: Dongwoo
  family: Kim
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/park24d/park24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

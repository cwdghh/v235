---
title: 'Patchscopes: A Unifying Framework for Inspecting Hidden Representations of
  Language Models'
openreview: 5uwBzcn885
abstract: Understanding the internal representations of large language models (LLMs)
  can help explain models’ behavior and verify their alignment with human values.
  Given the capabilities of LLMs in generating human-understandable text, we propose
  leveraging the model itself to explain its internal representations in natural language.
  We introduce a framework called Patchscopes and show how it can be used to answer
  a wide range of questions about an LLM’s computation. We show that many prior interpretability
  methods based on projecting representations into the vocabulary space and intervening
  on the LLM computation can be viewed as instances of this framework. Moreover, several
  of their shortcomings such as failure in inspecting early layers or lack of expressivity
  can be mitigated by Patchscopes. Beyond unifying prior inspection techniques, Patchscopes
  also opens up <em>new</em> possibilities such as using a more capable model to explain
  the representations of a smaller model, and multihop reasoning error correction.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ghandeharioun24a
month: 0
tex_title: 'Patchscopes: A Unifying Framework for Inspecting Hidden Representations
  of Language Models'
firstpage: 15466
lastpage: 15490
page: 15466-15490
order: 15466
cycles: false
bibtex_author: Ghandeharioun, Asma and Caciularu, Avi and Pearce, Adam and Dixon,
  Lucas and Geva, Mor
author:
- given: Asma
  family: Ghandeharioun
- given: Avi
  family: Caciularu
- given: Adam
  family: Pearce
- given: Lucas
  family: Dixon
- given: Mor
  family: Geva
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/ghandeharioun24a/ghandeharioun24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

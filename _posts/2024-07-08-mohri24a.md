---
title: Language Models with Conformal Factuality Guarantees
openreview: uYISs2tpwP
abstract: Guaranteeing the correctness and factuality of language model (LM) outputs
  is a major open problem. In this work, we propose conformal factuality, a framework
  that can ensure high probability correctness guarantees for LMs by connecting language
  modeling and conformal prediction. Our insight is that the correctness of an LM
  output is equivalent to an uncertainty quantification problem, where the uncertainty
  sets are defined as the entailment set of an LM’s output. Using this connection,
  we show that conformal prediction in language models corresponds to a back-off algorithm
  that provides high probability correctness guarantees by progressively making LM
  outputs less specific (and expanding the associated uncertainty sets). This approach
  applies to any black-box LM and requires very few human-annotated samples. Evaluations
  of our approach on closed book QA (FActScore, NaturalQuestions) and reasoning tasks
  (MATH) show that our approach can provide 80-90% correctness guarantees while retaining
  the majority of the LM’s original output.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mohri24a
month: 0
tex_title: Language Models with Conformal Factuality Guarantees
firstpage: 36029
lastpage: 36047
page: 36029-36047
order: 36029
cycles: false
bibtex_author: Mohri, Christopher and Hashimoto, Tatsunori
author:
- given: Christopher
  family: Mohri
- given: Tatsunori
  family: Hashimoto
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/mohri24a/mohri24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

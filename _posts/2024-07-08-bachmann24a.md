---
title: The Pitfalls of Next-Token Prediction
openreview: 76zq8Wkl6Z
abstract: 'Can a mere next-token predictor faithfully model human thinking? Our work
  is aimed at crystallizing this intuitive concern, which is currently fragmented
  in the literature. First, we emphasize isolating the two phases of next-token prediction
  that are often conflated: autoregression during inference vs. teacher-forcing during
  training. We argue that the previously-identified problem of "exponential error
  accumulation" is a symptom of autoregressive inference. But more concerningly, we
  identify that teacher-forcing can let the model fit the training data by cheating,
  causing total in-distribution failure. We design a minimal planning task where empirically
  both the Transformer and the Mamba architecture fail in this manner - remarkably,
  despite the task being easy to learn. Overall, our work consolidates these and other
  essential arguments surrounding next-token prediction. We hope this effort can ground
  future discussions and inspire explorations beyond the next-token prediction paradigm.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bachmann24a
month: 0
tex_title: The Pitfalls of Next-Token Prediction
firstpage: 2296
lastpage: 2318
page: 2296-2318
order: 2296
cycles: false
bibtex_author: Bachmann, Gregor and Nagarajan, Vaishnavh
author:
- given: Gregor
  family: Bachmann
- given: Vaishnavh
  family: Nagarajan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/bachmann24a/bachmann24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'FedLMT: Tackling System Heterogeneity of Federated Learning via Low-Rank Model
  Training with Theoretical Guarantees'
openreview: akyElNlUVA
abstract: Federated learning (FL) is an emerging machine learning paradigm for preserving
  data privacy. However, diverse client hardware often has varying computation resources.
  Such system heterogeneity limits the participation of resource-constrained clients
  in FL, and hence degrades the global model accuracy. To enable heterogeneous clients
  to participate in and contribute to FL training, previous works tackle this problem
  by assigning customized sub-models to individual clients with model pruning, distillation,
  or low-rank based techniques. Unfortunately, the global model trained by these methods
  still encounters performance degradation due to heterogeneous sub-model aggregation.
  Besides, most methods are heuristic-based and lack convergence analysis. In this
  work, we propose the FedLMT framework to bridge the performance gap, by assigning
  clients with a homogeneous pre-factorized low-rank model to substantially reduce
  resource consumption without conducting heterogeneous aggregation. We theoretically
  prove that the convergence of the low-rank model can guarantee the convergence of
  the original full model. To further meet clientsâ€™ personalized resource needs, we
  extend FedLMT to pFedLMT, by separating model parameters into common and custom
  ones. Finally, extensive experiments are conducted to verify our theoretical analysis
  and show that FedLMT and pFedLMT outperform other baselines with much less communication
  and computation costs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24ch
month: 0
tex_title: "{F}ed{LMT}: Tackling System Heterogeneity of Federated Learning via Low-Rank
  Model Training with Theoretical Guarantees"
firstpage: 32509
lastpage: 32551
page: 32509-32551
order: 32509
cycles: false
bibtex_author: Liu, Jiahao and Zhou, Yipeng and Wu, Di and Hu, Miao and Guizani, Mohsen
  and Sheng, Quan Z.
author:
- given: Jiahao
  family: Liu
- given: Yipeng
  family: Zhou
- given: Di
  family: Wu
- given: Miao
  family: Hu
- given: Mohsen
  family: Guizani
- given: Quan Z.
  family: Sheng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/liu24ch/liu24ch.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

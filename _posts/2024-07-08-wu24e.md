---
title: 'NExT-GPT: Any-to-Any Multimodal LLM'
openreview: NZQkumsNlf
abstract: While recently Multimodal Large Language Models (MM-LLMs) have made exciting
  strides, they mostly fall prey to the limitation of only input-side multimodal understanding,
  without the ability to produce content in multiple modalities. As we humans always
  perceive the world and communicate with people through various modalities, developing
  any-to-any MM-LLMs capable of accepting and delivering content in any modality becomes
  essential to human-level AI. To fill the gap, we present an end-to-end general-purpose
  any-to-any MM-LLM system, NExT-GPT. We connect an LLM with multimodal adaptors and
  different diffusion decoders, enabling NExT-GPT to perceive inputs and generate
  outputs in arbitrary combinations of text, image, video, and audio. By leveraging
  the existing well-trained high-performing encoders and decoders, NExT-GPT is tuned
  with only a small amount of parameter (1%) of certain projection layers, which not
  only benefits low-cost training but also facilitates convenient expansion to more
  potential modalities. Moreover, we introduce a modality-switching instruction tuning
  (MosIT) and manually curate a high-quality dataset for MosIT, based on which NExT-GPT
  is empowered with complex cross-modal semantic understanding and content generation.
  Overall, our research showcases the promising possibility of building a unified
  AI agent capable of modeling universal modalities, paving the way for more human-like
  AI research in the community.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu24e
month: 0
tex_title: "{NE}x{T}-{GPT}: Any-to-Any Multimodal {LLM}"
firstpage: 53366
lastpage: 53397
page: 53366-53397
order: 53366
cycles: false
bibtex_author: Wu, Shengqiong and Fei, Hao and Qu, Leigang and Ji, Wei and Chua, Tat-Seng
author:
- given: Shengqiong
  family: Wu
- given: Hao
  family: Fei
- given: Leigang
  family: Qu
- given: Wei
  family: Ji
- given: Tat-Seng
  family: Chua
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/wu24e/wu24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

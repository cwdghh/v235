---
title: Online Cascade Learning for Efficient Inference over Streams
openreview: Wz4lgc8dsN
abstract: Large Language Models (LLMs) have a natural role in answering complex queries
  about data streams, but the high computational cost of LLM inference makes them
  infeasible in many such tasks. We propose <em>online cascade learning</em>, the
  first approach to address this challenge. The objective here is to learn a “cascade”
  of models, starting with lower-capacity models (such as logistic regression) and
  ending with a powerful LLM, along with a <em>deferral policy</em> that determines
  the model to be used on a given input. We formulate the task of learning cascades
  online as an imitation-learning problem, where smaller models are updated over time
  imitating the collected LLM demonstrations, and give a no-regret algorithm for the
  problem. Experimental results across four benchmarks show that our method parallels
  LLMs in accuracy while cutting down inference costs by as much as 90% with strong
  robustness against input distribution shifts, underscoring its efficacy and adaptability
  in stream processing. Our source code is available at https://github.com/flitternie/online_cascade_learning.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nie24a
month: 0
tex_title: Online Cascade Learning for Efficient Inference over Streams
firstpage: 38071
lastpage: 38090
page: 38071-38090
order: 38071
cycles: false
bibtex_author: Nie, Lunyiu and Ding, Zhimin and Hu, Erdong and Jermaine, Christopher
  and Chaudhuri, Swarat
author:
- given: Lunyiu
  family: Nie
- given: Zhimin
  family: Ding
- given: Erdong
  family: Hu
- given: Christopher
  family: Jermaine
- given: Swarat
  family: Chaudhuri
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/nie24a/nie24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

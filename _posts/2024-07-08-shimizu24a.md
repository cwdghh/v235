---
title: Neural-Kernel Conditional Mean Embeddings
openreview: 0wso32h0jc
abstract: Kernel conditional mean embeddings (CMEs) offer a powerful framework for
  representing conditional distributions, but they often face scalability and expressiveness
  challenges. In this work, we propose a new method that effectively combines the
  strengths of deep learning with CMEs in order to address these challenges. Specifically,
  our approach leverages the end-to-end neural network (NN) optimization framework
  using a kernel-based objective. This design circumvents the computationally expensive
  Gram matrix inversion required by current CME methods. To further enhance performance,
  we provide efficient strategies to optimize the remaining kernel hyperparameters.
  In conditional density estimation tasks, our NN-CME hybrid achieves competitive
  performance and often surpasses existing deep learning-based methods. Lastly, we
  showcase its remarkable versatility by seamlessly integrating it into reinforcement
  learning (RL) contexts. Building on Q-learning, our approach naturally leads to
  a new variant of distributional RL methods, which demonstrates consistent effectiveness
  across different environments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shimizu24a
month: 0
tex_title: Neural-Kernel Conditional Mean Embeddings
firstpage: 45040
lastpage: 45059
page: 45040-45059
order: 45040
cycles: false
bibtex_author: Shimizu, Eiki and Fukumizu, Kenji and Sejdinovic, Dino
author:
- given: Eiki
  family: Shimizu
- given: Kenji
  family: Fukumizu
- given: Dino
  family: Sejdinovic
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/shimizu24a/shimizu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

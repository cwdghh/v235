---
title: 'Various Lengths, Constant Speed: Efficient Language Modeling with Lightning
  Attention'
openreview: Lwm6TiUP4X
abstract: We present Lightning Attention, the first linear attention implementation
  that maintains a constant training speed for various sequence lengths under fixed
  memory consumption. Due to the issue with cumulative summation operations (cumsum),
  previous linear attention implementations cannot achieve their theoretical advantage
  in a casual setting. However, this issue can be effectively solved by utilizing
  different attention calculation strategies to compute the different parts of attention.
  Specifically, we split the attention calculation into intra-blocks and inter-blocks
  and use conventional attention computation for intra-blocks and linear attention
  kernel tricks for inter-blocks. This eliminates the need for cumsum in the linear
  attention calculation. Furthermore, a tiling technique is adopted through both forward
  and backward procedures to take full advantage of the GPU hardware. To enhance accuracy
  while preserving efficacy, we introduce TransNormerLLM (TNL), a new architecture
  that is tailored to our lightning attention. We conduct rigorous testing on standard
  and self-collected datasets with varying model sizes and sequence lengths. TNL is
  notably more efficient than other language models. In addition, benchmark results
  indicate that TNL performs on par with state-of-the-art LLMs utilizing conventional
  transformer structures. The source code is released at github.com/OpenNLPLab/TransnormerLLM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: qin24c
month: 0
tex_title: 'Various Lengths, Constant Speed: Efficient Language Modeling with Lightning
  Attention'
firstpage: 41517
lastpage: 41535
page: 41517-41535
order: 41517
cycles: false
bibtex_author: Qin, Zhen and Sun, Weigao and Li, Dong and Shen, Xuyang and Sun, Weixuan
  and Zhong, Yiran
author:
- given: Zhen
  family: Qin
- given: Weigao
  family: Sun
- given: Dong
  family: Li
- given: Xuyang
  family: Shen
- given: Weixuan
  family: Sun
- given: Yiran
  family: Zhong
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/qin24c/qin24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Concentration Inequalities for General Functions of Heavy-Tailed Random Variables
openreview: JHRvP84SQ5
abstract: Concentration inequalities play an essential role in the study of machine
  learning and high dimensional statistics. In this paper, we obtain unbounded analogues
  of the popular bounded difference inequality for functions of independent random
  variables with heavy-tailed distributions. The main results provide a general framework
  applicable to all heavy-tailed distributions with finite variance. To illustrate
  the strength of our results, we present applications to sub-exponential tails, sub-Weibull
  tails, and heavier polynomially decaying tails. Applied to some standard problems
  in statistical learning theory (vector valued concentration, Rademacher complexity,
  and algorithmic stability), we show that these inequalities allow an extension of
  existing results to heavy-tailed distributions up to finite variance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24au
month: 0
tex_title: Concentration Inequalities for General Functions of Heavy-Tailed Random
  Variables
firstpage: 28343
lastpage: 28367
page: 28343-28367
order: 28343
cycles: false
bibtex_author: Li, Shaojie and Liu, Yong
author:
- given: Shaojie
  family: Li
- given: Yong
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/li24au/li24au.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

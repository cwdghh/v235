---
title: 'RigorLLM: Resilient Guardrails for Large Language Models against Undesired
  Content'
openreview: QAGRPiC3FS
abstract: Recent advancements in Large Language Models (LLMs) have showcased remarkable
  capabilities across various tasks in different domains. However, the emergence of
  biases and the potential for generating harmful content in LLMs, particularly under
  malicious inputs, pose significant challenges. Current mitigation strategies, while
  effective, are not resilient under adversarial attacks. This paper introduces Resilient
  Guardrails for Large Language Models (RigorLLM), a novel framework designed to efficiently
  and effectively moderate harmful and unsafe inputs and outputs for LLMs. By employing
  a multi-faceted approach that includes energy-based training data augmentation through
  Langevin dynamics, optimizing a safe suffix for inputs via minimax optimization,
  and integrating a fusion-based model combining robust KNN with LLMs based on our
  data augmentation, RigorLLM offers a robust solution to harmful content moderation.
  Our experimental evaluations demonstrate that RigorLLM not only outperforms existing
  baselines like OpenAI API and Perspective API in detecting harmful content but also
  exhibits unparalleled resilience to jailbreaking attacks. The innovative use of
  constrained optimization and a fusion-based guardrail approach represents a significant
  step forward in developing more secure and reliable LLMs, setting a new standard
  for content moderation frameworks in the face of evolving digital threats.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yuan24f
month: 0
tex_title: "{R}igor{LLM}: Resilient Guardrails for Large Language Models against Undesired
  Content"
firstpage: 57953
lastpage: 57965
page: 57953-57965
order: 57953
cycles: false
bibtex_author: Yuan, Zhuowen and Xiong, Zidi and Zeng, Yi and Yu, Ning and Jia, Ruoxi
  and Song, Dawn and Li, Bo
author:
- given: Zhuowen
  family: Yuan
- given: Zidi
  family: Xiong
- given: Yi
  family: Zeng
- given: Ning
  family: Yu
- given: Ruoxi
  family: Jia
- given: Dawn
  family: Song
- given: Bo
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/yuan24f/yuan24f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

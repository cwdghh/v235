---
title: 'GiLOT: Interpreting Generative Language Models via Optimal Transport'
openreview: qKL25sGjxL
abstract: 'While large language models (LLMs) surge with the rise of generative AI,
  algorithms to explain LLMs highly desire. Existing feature attribution methods adequate
  for discriminative language models like BERT often fail to deliver faithful explanations
  for LLMs, primarily due to two issues: (1) For every specific prediction, the LLM
  outputs a probability distribution over the vocabulary–a large number of tokens
  with unequal semantic distance; (2) As an autoregressive language model, the LLM
  handles input tokens while generating a sequence of probability distributions of
  various tokens. To address above two challenges, this work proposes GiLOT that leverages
  Optimal Transport to measure the distributional change of all possible generated
  sequences upon the absence of every input token, while taking into account the tokens’
  similarity, so as to faithfully estimate feature attribution for LLMs. We have carried
  out extensive experiments on top of Llama families and their fine-tuned derivatives
  across various scales to validate the effectiveness of GiLOT for estimating the
  input attributions. The results show that GiLOT outperforms existing solutions on
  a number of faithfulness metrics under fair comparison settings. Source code is
  publicly available at https://github.com/holyseven/GiLOT.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24i
month: 0
tex_title: "{G}i{LOT}: Interpreting Generative Language Models via Optimal Transport"
firstpage: 27515
lastpage: 27530
page: 27515-27530
order: 27515
cycles: false
bibtex_author: Li, Xuhong and Chen, Jiamin and Chai, Yekun and Xiong, Haoyi
author:
- given: Xuhong
  family: Li
- given: Jiamin
  family: Chen
- given: Yekun
  family: Chai
- given: Haoyi
  family: Xiong
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/li24i/li24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

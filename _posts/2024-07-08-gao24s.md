---
title: Distribution Alignment Optimization through Neural Collapse for Long-tailed
  Classification
openreview: Hjwx3H6Vci
abstract: A well-trained deep neural network on balanced datasets usually exhibits
  the Neural Collapse (NC) phenomenon, which is an informative indicator of the model
  achieving good performance. However, NC is usually hard to be achieved for a model
  trained on long-tailed datasets, leading to the deteriorated performance of test
  data. This work aims to induce the NC phenomenon in imbalanced learning from the
  perspective of distribution matching. By enforcing the distribution of last-layer
  representations to align the ideal distribution of the ETF structure, we develop
  a Distribution Alignment Optimization (DisA) loss, acting as a plug-and-play method
  can be combined with most of the existing long-tailed methods, we further instantiate
  it to the cases of fixing classifier and learning classifier. The extensive experiments
  show the effectiveness of DisA, providing a promising solution to the imbalanced
  issue. Our code is available at DisA.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao24s
month: 0
tex_title: Distribution Alignment Optimization through Neural Collapse for Long-tailed
  Classification
firstpage: 14969
lastpage: 14987
page: 14969-14987
order: 14969
cycles: false
bibtex_author: Gao, Jintong and Zhao, He and Guo, Dan Dan and Zha, Hongyuan
author:
- given: Jintong
  family: Gao
- given: He
  family: Zhao
- given: Dan Dan
  family: Guo
- given: Hongyuan
  family: Zha
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/gao24s/gao24s.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

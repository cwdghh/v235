---
title: 'ReconBoost: Boosting Can Achieve Modality Reconcilement'
openreview: 93gjGDwqim
abstract: This paper explores a novel multi-modal <em>alternating</em> learning paradigm
  pursuing a reconciliation between the exploitation of uni-modal features and the
  exploration of cross-modal interactions. This is motivated by the fact that current
  paradigms of multi-modal learning tend to explore multi-modal features simultaneously.
  The resulting gradient prohibits further exploitation of the features in the weak
  modality, leading to modality competition, where the dominant modality overpowers
  the learning process. To address this issue, we study the modality-alternating learning
  paradigm to achieve reconcilement. Specifically, we propose a new method called
  <em>ReconBoost</em> to update a fixed modality each time. Herein, the learning objective
  is dynamically adjusted with a reconcilement regularization against competition
  with the historical models. By choosing a KL-based reconcilement, we show that the
  proposed method resembles Friedmanâ€™s Gradient-Boosting (GB) algorithm, where the
  updated learner can correct errors made by others and help enhance the overall performance.
  The major difference with the classic GB is that we only preserve the newest model
  for each modality to avoid overfitting caused by ensembling strong learners. Furthermore,
  we propose a memory consolidation scheme and a global rectification scheme to make
  this strategy more effective. Experiments over six multi-modal benchmarks speak
  to the efficacy of the proposed method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hua24a
month: 0
tex_title: "{R}econ{B}oost: Boosting Can Achieve Modality Reconcilement"
firstpage: 19573
lastpage: 19597
page: 19573-19597
order: 19573
cycles: false
bibtex_author: Hua, Cong and Xu, Qianqian and Bao, Shilong and Yang, Zhiyong and Huang,
  Qingming
author:
- given: Cong
  family: Hua
- given: Qianqian
  family: Xu
- given: Shilong
  family: Bao
- given: Zhiyong
  family: Yang
- given: Qingming
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/hua24a/hua24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Data Poisoning Attacks against Conformal Prediction
openreview: f49AkFT5jf
abstract: The efficient and theoretically sound uncertainty quantification is crucial
  for building trust in deep learning models. This has spurred a growing interest
  in conformal prediction (CP), a powerful technique that provides a model-agnostic
  and distribution-free method for obtaining conformal prediction sets with theoretical
  guarantees. However, the vulnerabilities of such CP methods with regard to dedicated
  data poisoning attacks have not been studied previously. To bridge this gap, for
  the first time, we in this paper propose a new class of black-box data poisoning
  attacks against CP, where the adversary aims to cause the desired manipulations
  of some specific examplesâ€™ prediction uncertainty results (instead of misclassifications).
  Additionally, we design novel optimization frameworks for our proposed attacks.
  Further, we conduct extensive experiments to validate the effectiveness of our attacks
  on various settings (e.g., the full and split CP settings). Notably, our extensive
  experiments show that our attacks are more effective in manipulating uncertainty
  results than traditional poisoning attacks that aim at inducing misclassifications,
  and existing defenses against conventional attacks are ineffective against our proposed
  attacks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24l
month: 0
tex_title: Data Poisoning Attacks against Conformal Prediction
firstpage: 27563
lastpage: 27574
page: 27563-27574
order: 27563
cycles: false
bibtex_author: Li, Yangyi and Chen, Aobo and Qian, Wei and Zhao, Chenxu and Lidder,
  Divya and Huai, Mengdi
author:
- given: Yangyi
  family: Li
- given: Aobo
  family: Chen
- given: Wei
  family: Qian
- given: Chenxu
  family: Zhao
- given: Divya
  family: Lidder
- given: Mengdi
  family: Huai
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24l/li24l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Scaling Rectified Flow Transformers for High-Resolution Image Synthesis
openreview: FPnUhsQJ5B
abstract: Diffusion models create data from noise by inverting the forward paths of
  data towards noise and have emerged as a powerful generative modeling technique
  for high-dimensional, perceptual data such as images and videos. Rectified flow
  is a recent generative model formulation that connects data and noise in a straight
  line. Despite its better theoretical properties and conceptual simplicity, it is
  not yet decisively established as standard practice. In this work, we improve existing
  noise sampling techniques for training rectified flow models by biasing them towards
  perceptually relevant scales. Through a large-scale study, we demonstrate the superior
  performance of this approach compared to established diffusion formulations for
  high-resolution text-to-image synthesis. Additionally, we present a novel transformer-based
  architecture for text-to-image generation that uses separate weights for the two
  modalities and enables a bidirectional flow of information between image and text
  tokens, improving text comprehension, typography, and human preference ratings.
  We demonstrate that this architecture follows predictable scaling trends and correlates
  lower validation loss to improved text-to-image synthesis as measured by various
  metrics and human evaluations. Our largest models outperform state-of-the-art models.
  Stability AI is considering making experimental data, code, and model weights publicly
  available.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: esser24a
month: 0
tex_title: Scaling Rectified Flow Transformers for High-Resolution Image Synthesis
firstpage: 12606
lastpage: 12633
page: 12606-12633
order: 12606
cycles: false
bibtex_author: Esser, Patrick and Kulal, Sumith and Blattmann, Andreas and Entezari,
  Rahim and M\"{u}ller, Jonas and Saini, Harry and Levi, Yam and Lorenz, Dominik and
  Sauer, Axel and Boesel, Frederic and Podell, Dustin and Dockhorn, Tim and English,
  Zion and Rombach, Robin
author:
- given: Patrick
  family: Esser
- given: Sumith
  family: Kulal
- given: Andreas
  family: Blattmann
- given: Rahim
  family: Entezari
- given: Jonas
  family: MÃ¼ller
- given: Harry
  family: Saini
- given: Yam
  family: Levi
- given: Dominik
  family: Lorenz
- given: Axel
  family: Sauer
- given: Frederic
  family: Boesel
- given: Dustin
  family: Podell
- given: Tim
  family: Dockhorn
- given: Zion
  family: English
- given: Robin
  family: Rombach
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/esser24a/esser24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

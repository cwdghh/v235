---
title: Disentangled 3D Scene Generation with Layout Learning
openreview: Lgh8bhWpVC
abstract: We introduce a method to generate 3D scenes that are disentangled into their
  component objects. This disentanglement is unsupervised, relying only on the knowledge
  of a large pretrained text-to-image model. Our key insight is that objects can be
  discovered by finding parts of a 3D scene that, when rearranged spatially, still
  produce valid configurations of the same scene. Concretely, our method jointly optimizes
  multiple NeRFs—each representing its own object—along with a <em>set of layouts</em>
  that composite these objects into scenes. We then encourage these composited scenes
  to be in-distribution according to the image generator. We show that despite its
  simplicity, our approach successfully generates 3D scenes decomposed into individual
  objects, enabling new capabilities in text-to-3D content creation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: epstein24a
month: 0
tex_title: Disentangled 3{D} Scene Generation with Layout Learning
firstpage: 12547
lastpage: 12559
page: 12547-12559
order: 12547
cycles: false
bibtex_author: Epstein, Dave and Poole, Ben and Mildenhall, Ben and Efros, Alexei
  A and Holynski, Aleksander
author:
- given: Dave
  family: Epstein
- given: Ben
  family: Poole
- given: Ben
  family: Mildenhall
- given: Alexei A
  family: Efros
- given: Aleksander
  family: Holynski
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/epstein24a/epstein24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

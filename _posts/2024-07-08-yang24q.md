---
title: 'Rewards-in-Context: Multi-objective Alignment of Foundation Models with Dynamic
  Preference Adjustment'
openreview: QLcBzRI3V3
abstract: We consider the problem of multi-objective alignment of foundation models
  with human preferences, which is a critical step towards helpful and harmless AI
  systems. However, it is generally costly and unstable to fine-tune large foundation
  models using reinforcement learning (RL), and the multi-dimensionality, heterogeneity,
  and conflicting nature of human preferences further complicate the alignment process.
  In this paper, we introduce Rewards-in-Context (RiC), which conditions the response
  of a foundation model on multiple rewards in its prompt context and applies supervised
  fine-tuning for alignment. The salient features of RiC are simplicity and adaptivity,
  as it only requires supervised fine-tuning of a single foundation model and supports
  dynamic adjustment for user preferences during inference time. Inspired by the analytical
  solution of an abstracted convex optimization problem, our dynamic inference-time
  adjustment method approaches the Pareto-optimal solution for multiple objectives.
  Empirical evidence demonstrates the efficacy of our method in aligning both Large
  Language Models (LLMs) and diffusion models to accommodate diverse rewards with
  only around 10% GPU hours compared with multi-objective RL baseline.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yang24q
month: 0
tex_title: 'Rewards-in-Context: Multi-objective Alignment of Foundation Models with
  Dynamic Preference Adjustment'
firstpage: 56276
lastpage: 56297
page: 56276-56297
order: 56276
cycles: false
bibtex_author: Yang, Rui and Pan, Xiaoman and Luo, Feng and Qiu, Shuang and Zhong,
  Han and Yu, Dong and Chen, Jianshu
author:
- given: Rui
  family: Yang
- given: Xiaoman
  family: Pan
- given: Feng
  family: Luo
- given: Shuang
  family: Qiu
- given: Han
  family: Zhong
- given: Dong
  family: Yu
- given: Jianshu
  family: Chen
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/yang24q/yang24q.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Parameter-Efficient Fine-Tuning with Discrete Fourier Transform
openreview: XUOHKSsurt
abstract: Low-rank adaptation (LoRA) has recently gained much interest in fine-tuning
  foundation models. It effectively reduces the number of trainable parameters by
  incorporating low-rank matrices $A$ and $B$ to represent the weight change, i.e.,
  $\Delta W=BA$. Despite LoRA’s progress, it faces storage challenges when handling
  extensive customization adaptations or larger base models. In this work, we aim
  to further compress trainable parameters by enjoying the powerful expressiveness
  of the Fourier transform. Specifically, we introduce FourierFT, which treats $\Delta
  W$ as a matrix in the spatial domain and learns only a small fraction of its spectral
  coefficients. With the trained spectral coefficients, we implement the inverse discrete
  Fourier transform to recover $\Delta W$. Empirically, our FourierFT method shows
  comparable or better performance with fewer parameters than LoRA on various tasks,
  including natural language understanding, natural language generation, instruction
  tuning, and image classification. For example, when performing instruction tuning
  on the LLaMA2-7B model, FourierFT surpasses LoRA with only 0.064M trainable parameters,
  compared to LoRA’s 33.5M. Our code is released at this link.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao24o
month: 0
tex_title: Parameter-Efficient Fine-Tuning with Discrete {F}ourier Transform
firstpage: 14884
lastpage: 14901
page: 14884-14901
order: 14884
cycles: false
bibtex_author: Gao, Ziqi and Wang, Qichao and Chen, Aochuan and Liu, Zijing and Wu,
  Bingzhe and Chen, Liang and Li, Jia
author:
- given: Ziqi
  family: Gao
- given: Qichao
  family: Wang
- given: Aochuan
  family: Chen
- given: Zijing
  family: Liu
- given: Bingzhe
  family: Wu
- given: Liang
  family: Chen
- given: Jia
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/gao24o/gao24o.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

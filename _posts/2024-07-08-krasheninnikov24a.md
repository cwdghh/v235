---
title: Implicit meta-learning may lead language models to trust more reliable sources
openreview: Fzp1DRzCIN
abstract: 'We demonstrate that large language models (LLMs) may learn indicators of
  document usefulness and modulate their updates accordingly. We introduce random
  strings ("tags") as indicators of usefulness in a synthetic fine-tuning dataset.
  Fine-tuning on this dataset leads to <b>implicit meta-learning (IML)</b>: in further
  fine-tuning, the model updates to make more use of text that is tagged as useful.
  We perform a thorough empirical investigation of this phenomenon, finding (among
  other things) that (i) it occurs in both pretrained LLMs and those trained from
  scratch, as well as on a vision task, and (ii) larger models and smaller batch sizes
  tend to give more IML. We also use probing to examine how IML changes the way models
  store knowledge in their parameters. Finally, we reflect on what our results might
  imply about the capabilities, risks, and controllability of future AI systems.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: krasheninnikov24a
month: 0
tex_title: Implicit meta-learning may lead language models to trust more reliable
  sources
firstpage: 25534
lastpage: 25559
page: 25534-25559
order: 25534
cycles: false
bibtex_author: Krasheninnikov, Dmitrii and Krasheninnikov, Egor and Mlodozeniec, Bruno
  Kacper and Maharaj, Tegan and Krueger, David
author:
- given: Dmitrii
  family: Krasheninnikov
- given: Egor
  family: Krasheninnikov
- given: Bruno Kacper
  family: Mlodozeniec
- given: Tegan
  family: Maharaj
- given: David
  family: Krueger
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/krasheninnikov24a/krasheninnikov24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

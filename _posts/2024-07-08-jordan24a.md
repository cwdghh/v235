---
title: 'Position: Benchmarking is Limited in Reinforcement Learning Research'
openreview: Xe7n2ZqpBP
abstract: Novel reinforcement learning algorithms, or improvements on existing ones,
  are commonly justified by evaluating their performance on benchmark environments
  and are compared to an ever-changing set of standard algorithms. However, despite
  numerous calls for improvements, experimental practices continue to produce misleading
  or unsupported claims. One reason for the ongoing substandard practices is that
  conducting rigorous benchmarking experiments requires substantial computational
  time. This work investigates the sources of increased computation costs in rigorous
  experiment designs. We show that conducting rigorous performance benchmarks will
  likely have computational costs that are often prohibitive. As a result, we argue
  for using an additional experimentation paradigm to overcome the limitations of
  benchmarking.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jordan24a
month: 0
tex_title: 'Position: Benchmarking is Limited in Reinforcement Learning Research'
firstpage: 22551
lastpage: 22569
page: 22551-22569
order: 22551
cycles: false
bibtex_author: Jordan, Scott M. and White, Adam and Silva, Bruno Castro Da and White,
  Martha and Thomas, Philip S.
author:
- given: Scott M.
  family: Jordan
- given: Adam
  family: White
- given: Bruno Castro Da
  family: Silva
- given: Martha
  family: White
- given: Philip S.
  family: Thomas
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/jordan24a/jordan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

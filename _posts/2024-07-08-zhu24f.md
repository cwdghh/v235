---
title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional
  State Space Model'
openreview: YbHCqn4qF4
abstract: Recently the state space models (SSMs) with efficient hardware-aware designs,
  i.e., the Mamba deep learning model, have shown great potential for long sequence
  modeling. Meanwhile building efficient and generic vision backbones purely upon
  SSMs is an appealing direction. However, representing visual data is challenging
  for SSMs due to the position-sensitivity of visual data and the requirement of global
  context for visual understanding. In this paper, we show that the reliance on self-attention
  for visual representation learning is not necessary and propose a new generic vision
  backbone with bidirectional Mamba blocks (Vim), which marks the image sequences
  with position embeddings and compresses the visual representation with bidirectional
  state space models. On ImageNet classification, COCO object detection, and ADE20k
  semantic segmentation tasks, Vim achieves higher performance compared to well-established
  vision transformers like DeiT, while also demonstrating significantly improved computation
  & memory efficiency. For example, Vim is 2.8x faster than DeiT and saves 86.8% GPU
  memory when performing batch inference to extract features on images with a resolution
  of 1248x1248. The results demonstrate that Vim is capable of overcoming the computation
  & memory constraints on performing Transformer-style understanding for high-resolution
  images and it has great potential to be the next-generation backbone for vision
  foundation models.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu24f
month: 0
tex_title: 'Vision Mamba: Efficient Visual Representation Learning with Bidirectional
  State Space Model'
firstpage: 62429
lastpage: 62442
page: 62429-62442
order: 62429
cycles: false
bibtex_author: Zhu, Lianghui and Liao, Bencheng and Zhang, Qian and Wang, Xinlong
  and Liu, Wenyu and Wang, Xinggang
author:
- given: Lianghui
  family: Zhu
- given: Bencheng
  family: Liao
- given: Qian
  family: Zhang
- given: Xinlong
  family: Wang
- given: Wenyu
  family: Liu
- given: Xinggang
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/zhu24f/zhu24f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

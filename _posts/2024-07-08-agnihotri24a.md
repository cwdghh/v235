---
title: 'ACPO: A Policy Optimization Algorithm for Average MDPs with Constraints'
openreview: dmfvHU1LNF
abstract: Reinforcement Learning (RL) for constrained MDPs (CMDPs) is an increasingly
  important problem for various applications. Often, the average criterion is more
  suitable than the discounted criterion. Yet, RL for average-CMDPs (ACMDPs) remains
  a challenging problem. Algorithms designed for discounted constrained RL problems
  often do not perform well for the average CMDP setting. In this paper, we introduce
  a new policy optimization with function approximation algorithm for constrained
  MDPs with the average criterion. The Average-Constrained Policy Optimization (ACPO)
  algorithm is inspired by trust region-based policy optimization algorithms. We develop
  basic sensitivity theory for average CMDPs, and then use the corresponding bounds
  in the design of the algorithm. We provide theoretical guarantees on its performance,
  and through extensive experimental work in various challenging OpenAI Gym environments,
  show its superior empirical performance when compared to other state-of-the-art
  algorithms adapted for the ACMDPs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: agnihotri24a
month: 0
tex_title: "{ACPO}: A Policy Optimization Algorithm for Average {MDP}s with Constraints"
firstpage: 397
lastpage: 415
page: 397-415
order: 397
cycles: false
bibtex_author: Agnihotri, Akhil and Jain, Rahul and Luo, Haipeng
author:
- given: Akhil
  family: Agnihotri
- given: Rahul
  family: Jain
- given: Haipeng
  family: Luo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/agnihotri24a/agnihotri24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

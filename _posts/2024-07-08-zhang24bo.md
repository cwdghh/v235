---
title: 'Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt
  Tuning with Unlabeled Data'
openreview: sBJNokmYuV
abstract: Fine-tuning vision-language models (VLMs) with abundant unlabeled data recently
  has attracted increasing attention. Existing methods that resort to the pseudolabeling
  strategy would suffer from heavily incorrect hard pseudolabels when VLMs exhibit
  low zero-shot performance in downstream tasks. To alleviate this issue, we propose
  a <b>C</b>andidate <b>P</b>seudolabel <b>L</b>earning method, termed <b>CPL</b>,
  to fine-tune VLMs with suitable candidate pseudolabels of unlabeled data in downstream
  tasks. The core of our method lies in the generation strategy of candidate pseudolabels,
  which progressively generates refined candidate pseudolabels by both intra- and
  inter-instance label selection, based on a confidence score matrix for all unlabeled
  data. This strategy can result in better performance in true label inclusion and
  class-balanced instance selection. In this way, we can directly apply existing loss
  functions to learn with generated candidate psueudolabels. Extensive experiments
  on nine benchmark datasets with three learning paradigms demonstrate the effectiveness
  of our method. Our code can be found here.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24bo
month: 0
tex_title: 'Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt
  Tuning with Unlabeled Data'
firstpage: 60004
lastpage: 60020
page: 60004-60020
order: 60004
cycles: false
bibtex_author: Zhang, Jiahan and Wei, Qi and Liu, Feng and Feng, Lei
author:
- given: Jiahan
  family: Zhang
- given: Qi
  family: Wei
- given: Feng
  family: Liu
- given: Lei
  family: Feng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhang24bo/zhang24bo.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning?
  A Theoretical Perspective
openreview: 6dKUu2EkZy
abstract: Inverse Reinforcement Learning (IRL)—the problem of learning reward functions
  from demonstrations of an <em>expert policy</em>—plays a critical role in developing
  intelligent systems. While widely used in applications, theoretical understandings
  of IRL present unique challenges and remain less developed compared with standard
  RL. For example, it remains open how to do IRL efficiently in standard <em>offline</em>
  settings with pre-collected data, where states are obtained from a <em>behavior
  policy</em> (which could be the expert policy itself), and actions are sampled from
  the expert policy. This paper provides the first line of results for efficient IRL
  in vanilla offline and online settings using polynomial samples and runtime. Our
  algorithms and analyses seamlessly adapt the pessimism principle commonly used in
  offline RL, and achieve IRL guarantees in stronger metrics than considered in existing
  work. We provide lower bounds showing that our sample complexities are nearly optimal.
  As an application, we also show that the learned rewards can <em>transfer</em> to
  another target MDP with suitable guarantees when the target MDP satisfies certain
  similarity assumptions with the original (source) MDP.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao24m
month: 0
tex_title: Is Inverse Reinforcement Learning Harder than Standard Reinforcement Learning?
  {A} Theoretical Perspective
firstpage: 60957
lastpage: 61020
page: 60957-61020
order: 60957
cycles: false
bibtex_author: Zhao, Lei and Wang, Mengdi and Bai, Yu
author:
- given: Lei
  family: Zhao
- given: Mengdi
  family: Wang
- given: Yu
  family: Bai
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhao24m/zhao24m.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

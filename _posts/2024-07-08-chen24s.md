---
title: Accelerated Policy Gradient for s-rectangular Robust MDPs with Large State
  Spaces
openreview: J16WEPdqhJ
abstract: Robust Markov decision process (robust MDP) is an important machine learning
  framework to make a reliable policy that is robust to environmental perturbation.
  Despite empirical success and popularity of policy gradient methods, existing policy
  gradient methods require at least iteration complexity $\mathcal{O}(\epsilon^{-4})$
  to converge to the global optimal solution of s-rectangular robust MDPs with $\epsilon$-accuracy
  and are limited to deterministic setting with access to exact gradients and small
  state space that are impractical in many applications. In this work, we propose
  an accelerated policy gradient algorithm with iteration complexity $\mathcal{O}(\epsilon^{-3}\ln\epsilon^{-1})$
  in the deterministic setting using entropy regularization. Furthermore, we extend
  this algorithm to stochastic setting with access to only stochastic gradients and
  large state space which achieves the sample complexity $\mathcal{O}(\epsilon^{-7}\ln\epsilon^{-1})$.
  In the meantime, our algorithms are also the first scalable policy gradient methods
  to entropy-regularized robust MDPs, which provide an important but underexplored
  machine learning framework.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24s
month: 0
tex_title: Accelerated Policy Gradient for s-rectangular Robust {MDP}s with Large
  State Spaces
firstpage: 6847
lastpage: 6880
page: 6847-6880
order: 6847
cycles: false
bibtex_author: Chen, Ziyi and Huang, Heng
author:
- given: Ziyi
  family: Chen
- given: Heng
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/chen24s/chen24s.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

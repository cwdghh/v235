---
title: 'Position: A Safe Harbor for AI Evaluation and Red Teaming'
openreview: dLojMSgSFW
abstract: Independent evaluation and red teaming are critical for identifying the
  risks posed by generative AI systems. However, the terms of service and enforcement
  strategies used by prominent AI companies to deter model misuse have disincentives
  on good faith safety evaluations. This causes some researchers to fear that conducting
  such research or releasing their findings will result in account suspensions or
  legal reprisal. Although some companies offer researcher access programs, they are
  an inadequate substitute for independent research access, as they have limited community
  representation, receive inadequate funding, and lack independence from corporate
  incentives. We propose that major generative AI developers commit to providing a
  legal and technical safe harbor, protecting public interest safety research and
  removing the threat of account suspensions or legal reprisal. These proposals emerged
  from our collective experience conducting safety, privacy, and trustworthiness research
  on generative AI systems, where norms and incentives could be better aligned with
  public interests, without exacerbating model misuse. We believe these commitments
  are a necessary step towards more inclusive and unimpeded community efforts to tackle
  the risks of generative AI.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: longpre24a
month: 0
tex_title: 'Position: A Safe Harbor for {AI} Evaluation and Red Teaming'
firstpage: 32691
lastpage: 32710
page: 32691-32710
order: 32691
cycles: false
bibtex_author: Longpre, Shayne and Kapoor, Sayash and Klyman, Kevin and Ramaswami,
  Ashwin and Bommasani, Rishi and Blili-Hamelin, Borhane and Huang, Yangsibo and Skowron,
  Aviya and Yong, Zheng Xin and Kotha, Suhas and Zeng, Yi and Shi, Weiyan and Yang,
  Xianjun and Southen, Reid and Robey, Alexander and Chao, Patrick and Yang, Diyi
  and Jia, Ruoxi and Kang, Daniel and Pentland, Alex and Narayanan, Arvind and Liang,
  Percy and Henderson, Peter
author:
- given: Shayne
  family: Longpre
- given: Sayash
  family: Kapoor
- given: Kevin
  family: Klyman
- given: Ashwin
  family: Ramaswami
- given: Rishi
  family: Bommasani
- given: Borhane
  family: Blili-Hamelin
- given: Yangsibo
  family: Huang
- given: Aviya
  family: Skowron
- given: Zheng Xin
  family: Yong
- given: Suhas
  family: Kotha
- given: Yi
  family: Zeng
- given: Weiyan
  family: Shi
- given: Xianjun
  family: Yang
- given: Reid
  family: Southen
- given: Alexander
  family: Robey
- given: Patrick
  family: Chao
- given: Diyi
  family: Yang
- given: Ruoxi
  family: Jia
- given: Daniel
  family: Kang
- given: Alex
  family: Pentland
- given: Arvind
  family: Narayanan
- given: Percy
  family: Liang
- given: Peter
  family: Henderson
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/longpre24a/longpre24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

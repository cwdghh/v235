---
title: 'FiT: Flexible Vision Transformer for Diffusion Model'
openreview: jZVen2JguY
abstract: In the context of this reality, existing diffusion models, such as Diffusion
  Transformers, often face challenges when processing image resolutions outside of
  their trained domain. To overcome this limitation, we present the Flexible Vision
  Transformer (FiT), a transformer architecture specifically designed for generating
  images with unrestricted resolutions and aspect ratios. Unlike traditional methods
  that perceive images as static-resolution grids, FiT conceptualizes images as sequences
  of dynamically-sized tokens. This perspective enables a flexible training strategy
  that effortlessly adapts to diverse aspect ratios during both training and inference
  phases, thus promoting resolution generalization and eliminating biases induced
  by image cropping. Enhanced by a meticulously adjusted network structure and the
  integration of training-free extrapolation techniques, FiT exhibits remarkable flexibility
  in resolution extrapolation generation. Comprehensive experiments demonstrate the
  exceptional performance of FiT across a broad range of resolutions. Repository available
  at https://github.com/whlzy/FiT.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lu24k
month: 0
tex_title: "{F}i{T}: Flexible Vision Transformer for Diffusion Model"
firstpage: 33160
lastpage: 33176
page: 33160-33176
order: 33160
cycles: false
bibtex_author: Lu, Zeyu and Wang, Zidong and Huang, Di and Wu, Chengyue and Liu, Xihui
  and Ouyang, Wanli and Bai, Lei
author:
- given: Zeyu
  family: Lu
- given: Zidong
  family: Wang
- given: Di
  family: Huang
- given: Chengyue
  family: Wu
- given: Xihui
  family: Liu
- given: Wanli
  family: Ouyang
- given: Lei
  family: Bai
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/lu24k/lu24k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

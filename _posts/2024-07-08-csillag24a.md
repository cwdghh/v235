---
title: 'Generalization Bounds for Causal Regression: Insights, Guarantees and Sensitivity
  Analysis'
openreview: TejqrQBvll
abstract: Many algorithms have been recently proposed for causal machine learning.
  Yet, there is little to no theory on their quality, especially considering finite
  samples. In this work, we propose a theory based on generalization bounds that provides
  such guarantees. By introducing a novel change-of-measure inequality, we are able
  to tightly bound the model loss in terms of the deviation of the treatment propensities
  over the population, which we show can be empirically limited. Our theory is fully
  rigorous and holds even in the face of hidden confounding and violations of positivity.
  We demonstrate our bounds on semi-synthetic and real data, showcasing their remarkable
  tightness and practical utility.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: csillag24a
month: 0
tex_title: 'Generalization Bounds for Causal Regression: Insights, Guarantees and
  Sensitivity Analysis'
firstpage: 9576
lastpage: 9602
page: 9576-9602
order: 9576
cycles: false
bibtex_author: Csillag, Daniel and Struchiner, Claudio Jose and Goedert, Guilherme
  Tegoni
author:
- given: Daniel
  family: Csillag
- given: Claudio Jose
  family: Struchiner
- given: Guilherme Tegoni
  family: Goedert
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/csillag24a/csillag24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

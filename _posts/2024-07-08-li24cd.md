---
title: 'ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for
  Aligning Large Language Models'
openreview: Stn8hXkpe6
abstract: 'Reinforcement Learning from Human Feedback (RLHF) is key to aligning Large
  Language Models (LLMs), typically paired with the Proximal Policy Optimization (PPO)
  algorithm. While PPO is a powerful method designed for general reinforcement learning
  tasks, it is overly sophisticated for LLMs, leading to laborious hyper-parameter
  tuning and significant computation burdens. To make RLHF efficient, we present ReMax,
  which leverages 3 properties of RLHF: fast simulation, deterministic transitions,
  and trajectory-level rewards. These properties are not exploited in PPO, making
  it less suitable for RLHF. Building on the renowned REINFORCE algorithm, ReMax does
  not require training an additional value model as in PPO and is further enhanced
  with a new variance reduction technique. ReMax offers several benefits over PPO:
  it is simpler to implement, eliminates more than 4 hyper-parameters in PPO, reduces
  GPU memory usage, and shortens training time. ReMax can save about 46% GPU memory
  than PPO when training a 7B model and enables training on A800-80GB GPUs without
  the memory-saving offloading technique needed by PPO. Applying ReMax to a Mistral-7B
  model resulted in a 94.78% win rate on the AlpacaEval leaderboard and a 7.739 score
  on MT-bench, setting a new SOTA for open-source 7B models. These results show the
  effectiveness of ReMax while addressing the limitations of PPO in LLMs.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24cd
month: 0
tex_title: "{R}e{M}ax: A Simple, Effective, and Efficient Reinforcement Learning Method
  for Aligning Large Language Models"
firstpage: 29128
lastpage: 29163
page: 29128-29163
order: 29128
cycles: false
bibtex_author: Li, Ziniu and Xu, Tian and Zhang, Yushun and Lin, Zhihang and Yu, Yang
  and Sun, Ruoyu and Luo, Zhi-Quan
author:
- given: Ziniu
  family: Li
- given: Tian
  family: Xu
- given: Yushun
  family: Zhang
- given: Zhihang
  family: Lin
- given: Yang
  family: Yu
- given: Ruoyu
  family: Sun
- given: Zhi-Quan
  family: Luo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24cd/li24cd.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

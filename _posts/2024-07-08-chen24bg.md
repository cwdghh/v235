---
title: "$\\textttMoE-RBench$: Towards Building Reliable Language Models with Sparse
  Mixture-of-Experts"
openreview: LyJ85kgHFe
abstract: 'Mixture-of-Experts (MoE) has gained increasing popularity as a promising
  framework for scaling up large language models (LLMs). However, the reliability
  assessment of MoE lags behind its surging applications. Moreover, when transferred
  to new domains such as in fine-tuning MoE models sometimes underperform their dense
  counterparts. Motivated by the research gap and counter-intuitive phenomenon, we
  propose $\texttt{MoE-RBench}$, the first comprehensive assessment of SMoE reliability
  from three aspects: $\textit{(i)}$ safety and hallucination, $\textit{(ii)}$ resilience
  to adversarial attacks, and $\textit{(iii)}$ out-of-distribution robustness. Extensive
  models and datasets are tested to compare the MoE to dense networks from these reliability
  dimensions. Our empirical observations suggest that with appropriate hyperparameters,
  training recipes, and inference techniques, we can build the MoE model more reliably
  than the dense LLM. In particular, we find that the robustness of SMoE is sensitive
  to the basic training settings. We hope that this study can provide deeper insights
  into how to adapt the pre-trained MoE model to other tasks with higher-generation
  security, quality, and stability. Codes are available at https://github.com/UNITES-Lab/MoE-RBench.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24bg
month: 0
tex_title: "$\\texttt{MoE-RBench}$: Towards Building Reliable Language Models with
  Sparse Mixture-of-Experts"
firstpage: 7792
lastpage: 7808
page: 7792-7808
order: 7792
cycles: false
bibtex_author: Chen, Guanjie and Zhao, Xinyu and Chen, Tianlong and Cheng, Yu
author:
- given: Guanjie
  family: Chen
- given: Xinyu
  family: Zhao
- given: Tianlong
  family: Chen
- given: Yu
  family: Cheng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/chen24bg/chen24bg.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Differentially Private Bias-Term Fine-tuning of Foundation Models
openreview: fqeANcjBMT
abstract: We study the problem of differentially private (DP) fine-tuning of large
  pre-trained models â€” a recent privacy-preserving approach suitable for solving downstream
  tasks with sensitive data. Existing work has demonstrated that high accuracy is
  possible under strong privacy constraint, yet requires significant computational
  overhead or modifications to the network architecture. We propose differentially
  private bias-term fine-tuning (DP-BiTFiT), which matches the state-of-the-art accuracy
  for DP algorithms and the efficiency of the standard BiTFiT. DP-BiTFiT is model
  agnostic (not modifying the network architecture), parameter efficient (only training
  about 0.1% of the parameters), and computation efficient (almost removing the overhead
  caused by DP, in both the time and space complexity). On a wide range of tasks,
  DP-BiTFiT is 2 - 30X faster and uses 2 - 8X less memory than DP full fine-tuning,
  even faster than the standard full fine-tuning. This amazing efficiency enables
  us to conduct DP fine-tuning on language and vision tasks with long-sequence texts
  and high-resolution images, which were computationally difficult using existing
  methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bu24c
month: 0
tex_title: Differentially Private Bias-Term Fine-tuning of Foundation Models
firstpage: 4730
lastpage: 4751
page: 4730-4751
order: 4730
cycles: false
bibtex_author: Bu, Zhiqi and Wang, Yu-Xiang and Zha, Sheng and Karypis, George
author:
- given: Zhiqi
  family: Bu
- given: Yu-Xiang
  family: Wang
- given: Sheng
  family: Zha
- given: George
  family: Karypis
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/bu24c/bu24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

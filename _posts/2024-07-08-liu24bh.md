---
title: 'Unified Generation, Reconstruction, and Representation: Generalized Diffusion
  with Adaptive Latent Encoding-Decoding'
openreview: igRjCCAz2a
abstract: The vast applications of deep generative models are anchored in three core
  capabilities—<em>generating</em> new instances, <em>reconstructing</em> inputs,
  and learning compact <em>representations</em>—across various data types, such as
  discrete text/protein sequences and continuous images. Existing model families,
  like variational autoencoders (VAEs), generative adversarial networks (GANs), autoregressive
  models, and (latent) diffusion models, generally excel in specific capabilities
  and data types but fall short in others. We introduce <em>Generalized</em> <b><em>E</em></b><em>ncoding</em>-<b><em>D</em></b><em>ecoding
  </em><b><em>D</em></b><em>iffusion </em><b><em>P</em></b><em>robabilistic </em><b><em>M</em></b><em>odels</em>
  (EDDPMs) which integrate the core capabilities for broad applicability and enhanced
  performance. EDDPMs generalize the Gaussian noising-denoising in standard diffusion
  by introducing parameterized encoding-decoding. Crucially, EDDPMs are compatible
  with the well-established diffusion model objective and training recipes, allowing
  effective learning of the encoder-decoder parameters <em>jointly</em> with diffusion.
  By choosing appropriate encoder/decoder (e.g., large language models), EDDPMs naturally
  apply to different data types. Extensive experiments on text, proteins, and images
  demonstrate the flexibility to handle diverse data and tasks and the strong improvement
  over various existing models. Code is available at https://github.com/guangyliu/EDDPM
  .
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24bh
month: 0
tex_title: 'Unified Generation, Reconstruction, and Representation: Generalized Diffusion
  with Adaptive Latent Encoding-Decoding'
firstpage: 31964
lastpage: 31993
page: 31964-31993
order: 31964
cycles: false
bibtex_author: Liu, Guangyi and Wang, Yu and Feng, Zeyu and Wu, Qiyu and Tang, Liping
  and Gao, Yuan and Li, Zhen and Cui, Shuguang and Mcauley, Julian and Yang, Zichao
  and Xing, Eric P. and Hu, Zhiting
author:
- given: Guangyi
  family: Liu
- given: Yu
  family: Wang
- given: Zeyu
  family: Feng
- given: Qiyu
  family: Wu
- given: Liping
  family: Tang
- given: Yuan
  family: Gao
- given: Zhen
  family: Li
- given: Shuguang
  family: Cui
- given: Julian
  family: Mcauley
- given: Zichao
  family: Yang
- given: Eric P.
  family: Xing
- given: Zhiting
  family: Hu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/liu24bh/liu24bh.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

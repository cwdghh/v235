---
title: The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks
openreview: 2xLyc5TkFl
abstract: In safety-critical applications such as medical imaging and autonomous driving,
  where decisions have profound implications for patient health and road safety, it
  is imperative to maintain both high adversarial robustness to protect against potential
  adversarial attacks and reliable uncertainty quantification in decision-making.
  With extensive research focused on enhancing adversarial robustness through various
  forms of adversarial training (AT), a notable knowledge gap remains concerning the
  uncertainty inherent in adversarially trained models. To address this gap, this
  study investigates the uncertainty of deep learning models by examining the performance
  of conformal prediction (CP) in the context of standard adversarial attacks within
  the adversarial defense community. It is first unveiled that existing CP methods
  do not produce informative prediction sets under the commonly used $l_{\infty}$-norm
  bounded attack if the model is not adversarially trained, which underpins the importance
  of adversarial training for CP. Our paper next demonstrates that the prediction
  set size (PSS) of CP using adversarially trained models with AT variants is often
  worse than using standard AT, inspiring us to research into CP-efficient AT for
  improved PSS. We propose to optimize a Beta-weighting loss with an entropy minimization
  regularizer during AT to improve CP-efficiency, where the Beta-weighting loss is
  shown to be an upper bound of PSS at the population level by our theoretical analysis.
  Moreover, our empirical study on four image classification datasets across three
  popular AT baselines validates the effectiveness of the proposed Uncertainty-Reducing
  AT (AT-UR).
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24m
month: 0
tex_title: The Pitfalls and Promise of Conformal Inference Under Adversarial Attacks
firstpage: 30908
lastpage: 30928
page: 30908-30928
order: 30908
cycles: false
bibtex_author: Liu, Ziquan and Cui, Yufei and Yan, Yan and Xu, Yi and Ji, Xiangyang
  and Liu, Xue and Chan, Antoni B.
author:
- given: Ziquan
  family: Liu
- given: Yufei
  family: Cui
- given: Yan
  family: Yan
- given: Yi
  family: Xu
- given: Xiangyang
  family: Ji
- given: Xue
  family: Liu
- given: Antoni B.
  family: Chan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/liu24m/liu24m.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

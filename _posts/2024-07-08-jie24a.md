---
title: Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning
openreview: FHkavpr5Ze
abstract: 'Current solutions for efficiently constructing large vision-language (VL)
  models follow a two-step paradigm: projecting the output of pre-trained vision encoders
  to the input space of pre-trained language models as visual prompts; and then transferring
  the models to downstream VL tasks via end-to-end parameter-efficient fine-tuning
  (PEFT). However, this paradigm still exhibits inefficiency since it significantly
  increases the input length of the language models. In this paper, in contrast to
  integrating visual prompts into inputs, we regard visual prompts as additional knowledge
  that facilitates language models in addressing tasks associated with visual information.
  Motivated by the finding that Feed-Forward Network (FFN) of language models acts
  as "key-value memory", we introduce a novel approach termed memory-space visual
  prompting (MemVP), wherein visual prompts are concatenated with the weights of FFN
  for visual knowledge injection. Experimental results across various VL tasks and
  language models reveal that MemVP significantly reduces the training time and inference
  latency of the finetuned VL models and surpasses the performance of previous PEFT
  methods.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jie24a
month: 0
tex_title: Memory-Space Visual Prompting for Efficient Vision-Language Fine-Tuning
firstpage: 22062
lastpage: 22074
page: 22062-22074
order: 22062
cycles: false
bibtex_author: Jie, Shibo and Tang, Yehui and Ding, Ning and Deng, Zhi-Hong and Han,
  Kai and Wang, Yunhe
author:
- given: Shibo
  family: Jie
- given: Yehui
  family: Tang
- given: Ning
  family: Ding
- given: Zhi-Hong
  family: Deng
- given: Kai
  family: Han
- given: Yunhe
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/jie24a/jie24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Riemannian coordinate descent algorithms on matrix manifolds
openreview: bdKaQmrM81
abstract: Many machine learning applications are naturally formulated as optimization
  problems on Riemannian manifolds. The main idea behind Riemannian optimization is
  to maintain the feasibility of the variables while moving along a descent direction
  on the manifold. This results in updating all the variables at every iteration.
  In this work, we provide a general framework for developing computationally efficient
  coordinate descent (CD) algorithms on matrix manifolds that allows updating only
  a few variables at every iteration while adhering to the manifold constraint. In
  particular, we propose CD algorithms for various manifolds such as Stiefel, Grassmann,
  (generalized) hyperbolic, symplectic, and symmetric positive (semi)definite. While
  the cost per iteration of the proposed CD algorithms is low, we further develop
  a more efficient variant via a first-order approximation of the objective function.
  We analyze their convergence and complexity, and empirically illustrate their efficacy
  in several applications.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: han24c
month: 0
tex_title: "{R}iemannian coordinate descent algorithms on matrix manifolds"
firstpage: 17393
lastpage: 17415
page: 17393-17415
order: 17393
cycles: false
bibtex_author: Han, Andi and Jawanpuria, Pratik and Mishra, Bamdev
author:
- given: Andi
  family: Han
- given: Pratik
  family: Jawanpuria
- given: Bamdev
  family: Mishra
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/han24c/han24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

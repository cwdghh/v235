---
title: Energy-Efficient Gaussian Processes Using Low-Precision Arithmetic
openreview: v9tIJW1fzt
abstract: The widespread use of artificial intelligence requires finding energy-efficient
  paradigms for the field. We propose to reduce the energy consumption of Gaussian
  process regression using low-precision floating-point representations. We explore
  how low-precision representations impact the results of Gaussian process regression
  and how data set properties, implementation approach, model performance, and energy
  consumption interact. Our findings show that a well-conditioned kernel matrix allows
  reducing the energy consumption by up to 89.01% for 98.08% of arithmetic operations
  with little to no impact on model performance. Our findings are relevant whenever
  one needs to invert a symmetric full-rank matrix.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alder24a
month: 0
tex_title: Energy-Efficient {G}aussian Processes Using Low-Precision Arithmetic
firstpage: 955
lastpage: 975
page: 955-975
order: 955
cycles: false
bibtex_author: Alder, Nicolas and Herbrich, Ralf
author:
- given: Nicolas
  family: Alder
- given: Ralf
  family: Herbrich
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/alder24a/alder24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

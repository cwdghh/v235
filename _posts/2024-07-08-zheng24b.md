---
title: 'PRISE: LLM-Style Sequence Compression for Learning Temporal Action Abstractions
  in Control'
openreview: p225Od0aYt
abstract: Temporal action abstractions, along with belief state representations, are
  a powerful knowledge sharing mechanism for sequential decision making. In this work,
  we propose a novel view that treats inducing temporal action abstractions as a sequence
  compression problem. To do so, we bring a subtle but critical component of LLM training
  pipelines – input tokenization via byte pair encoding (BPE) – to bear on the seemingly
  distant task of learning skills of variable time span in continuous control domains.
  We introduce an approach called Primitive Sequence Encoding (PRISE) that combines
  continuous action quantization with BPE to learn powerful action abstractions. We
  empirically show that high-level skills discovered by PRISE from a multitask set
  of robotic manipulation demonstrations significantly boost the learning performance
  of behavior cloning on downstream tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zheng24b
month: 0
tex_title: "{PRISE}: {LLM}-Style Sequence Compression for Learning Temporal Action
  Abstractions in Control"
firstpage: 61267
lastpage: 61286
page: 61267-61286
order: 61267
cycles: false
bibtex_author: Zheng, Ruijie and Cheng, Ching-An and Daum\'{e} Iii, Hal and Huang,
  Furong and Kolobov, Andrey
author:
- given: Ruijie
  family: Zheng
- given: Ching-An
  family: Cheng
- given: Hal
  family: Daumé Iii
- given: Furong
  family: Huang
- given: Andrey
  family: Kolobov
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/zheng24b/zheng24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Receptive Fields As Experts in Convolutional Neural Architectures
openreview: HGSIpeNNfM
abstract: 'The size of spatial receptive fields, from the early 3$\times$3 convolutions
  in VGGNet to the recent 7$\times$7 convolutions in ConvNeXt, has always played a
  critical role in architecture design. In this paper, we propose a Mixture of Receptive
  Fields (MoRF) instead of using a single receptive field. MoRF contains the combinations
  of multiple receptive fields with different sizes, e.g., convolutions with different
  kernel sizes, which can be regarded as experts. Such an approach serves two functions:
  one is to select the appropriate receptive field according to the input, and the
  other is to expand the network capacity. Furthermore, we also introduce two types
  of routing mechanisms, hard routing and soft routing to automatically select the
  appropriate receptive field experts. In the inference stage, the selected receptive
  field experts are merged via re-parameterization to maintain a similar inference
  speed compared to the single receptive field. To demonstrate the effectiveness of
  MoRF, we integrate the MoRF concept into multiple architectures, e.g., ResNet and
  ConvNeXt. Extensive experiments show that our approach outperforms the baselines
  in image classification, object detection, and segmentation tasks without significantly
  increasing the inference time.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lian24b
month: 0
tex_title: Receptive Fields As Experts in Convolutional Neural Architectures
firstpage: 29531
lastpage: 29544
page: 29531-29544
order: 29531
cycles: false
bibtex_author: Lian, Dongze and Yu, Weihao and Wang, Xinchao
author:
- given: Dongze
  family: Lian
- given: Weihao
  family: Yu
- given: Xinchao
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/lian24b/lian24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Online Learning with Bounded Recall
openreview: 4pFgOzKF76
abstract: We study the problem of full-information online learning in the “bounded
  recall” setting popular in the study of repeated games. An online learning algorithm
  $\mathcal{A}$ is $M$-<em>bounded-recall</em> if its output at time $t$ can be written
  as a function of the $M$ previous rewards (and not e.g. any other internal state
  of $\mathcal{A}$). We first demonstrate that a natural approach to constructing
  bounded-recall algorithms from mean-based no-regret learning algorithms (e.g., running
  Hedge over the last $M$ rounds) fails, and that any such algorithm incurs constant
  regret per round. We then construct a stationary bounded-recall algorithm that achieves
  a per-round regret of $\Theta(1/\sqrt{M})$, which we complement with a tight lower
  bound. Finally, we show that unlike the perfect recall setting, any low regret bound
  bounded-recall algorithm must be aware of the ordering of the past $M$ losses –
  any bounded-recall algorithm which plays a symmetric function of the past $M$ losses
  must incur constant regret per round.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: schneider24b
month: 0
tex_title: Online Learning with Bounded Recall
firstpage: 43791
lastpage: 43803
page: 43791-43803
order: 43791
cycles: false
bibtex_author: Schneider, Jon and Vodrahalli, Kiran
author:
- given: Jon
  family: Schneider
- given: Kiran
  family: Vodrahalli
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/schneider24b/schneider24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

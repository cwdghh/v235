---
title: 'Position: Social Choice Should Guide AI Alignment in Dealing with Diverse
  Human Feedback'
openreview: w1d9DOGymR
abstract: Foundation models such as GPT-4 are fine-tuned to avoid unsafe or otherwise
  problematic behavior, such as helping to commit crimes or producing racist text.
  One approach to fine-tuning, called reinforcement learning from human feedback,
  learns from humans’ expressed preferences over multiple outputs. Another approach
  is constitutional AI, in which the input from humans is a list of high-level principles.
  But how do we deal with potentially diverging input from humans? How can we aggregate
  the input into consistent data about “collective” preferences or otherwise use it
  to make collective choices about model behavior? In this paper, we argue that the
  field of social choice is well positioned to address these questions, and we discuss
  ways forward for this agenda, drawing on discussions in a recent workshop on Social
  Choice for AI Ethics and Safety held in Berkeley, CA, USA in December 2023.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: conitzer24a
month: 0
tex_title: 'Position: Social Choice Should Guide {AI} Alignment in Dealing with Diverse
  Human Feedback'
firstpage: 9346
lastpage: 9360
page: 9346-9360
order: 9346
cycles: false
bibtex_author: Conitzer, Vincent and Freedman, Rachel and Heitzig, Jobst and Holliday,
  Wesley H. and Jacobs, Bob M. and Lambert, Nathan and Mosse, Milan and Pacuit, Eric
  and Russell, Stuart and Schoelkopf, Hailey and Tewolde, Emanuel and Zwicker, William
  S.
author:
- given: Vincent
  family: Conitzer
- given: Rachel
  family: Freedman
- given: Jobst
  family: Heitzig
- given: Wesley H.
  family: Holliday
- given: Bob M.
  family: Jacobs
- given: Nathan
  family: Lambert
- given: Milan
  family: Mosse
- given: Eric
  family: Pacuit
- given: Stuart
  family: Russell
- given: Hailey
  family: Schoelkopf
- given: Emanuel
  family: Tewolde
- given: William S.
  family: Zwicker
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/conitzer24a/conitzer24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

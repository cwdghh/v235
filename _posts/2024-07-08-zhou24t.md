---
title: 'ArCHer: Training Language Model Agents via Hierarchical Multi-Turn RL'
openreview: b6rA0kAHT1
abstract: Large language models (LLMs) have the potential to tackle sequential decision-making
  problems due to their generalist capabilities. Instead of optimizing “myopic” surrogate
  objectives such as human preferences within a single turn, in such problems, we
  wish to directly optimize long-term objectives, such as user satisfaction over an
  entire dialogue with an LLM or delayed success metrics in web navigation. Multi-turn
  reinforcement learning (RL) provides an appealing approach to directly optimize
  long-term objectives, but how can we design effective and efficient multi-turn RL
  algorithms for LLMs? In this work, we propose an algorithmic framework to multi-turn
  RL for LLMs that preserves the flexibility of token-by-token RL used in single-turn
  RL problems, while still accommodating long horizons and delayed rewards more effectively.
  Our framework, the <b>A</b>cto<b>r</b>-<b>C</b>ritic Framework with a <b>H</b>i<b>e</b>rarchical
  Structu<b>r</b>e (<b>ArCHer</b>), combines a high-level off-policy RL algorithm
  that trains a value function with a low-level RL algorithm that trains a token-by-token
  policy. While ArCHer can be instantiated with multiple RL algorithms, a particularly
  convenient instantiation is to use temporal difference (TD) learning at the high
  level and on-policy token-level policy gradient at the low level. Empirically, we
  show that ArCHer significantly improves efficiency and performance of multi-turn
  LLM tasks, attaining sample efficiency boosts of about <b>100x</b> over prior on-policy
  methods and converging to a much better performance than other off-policy methods.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhou24t
month: 0
tex_title: "{A}r{CH}er: Training Language Model Agents via Hierarchical Multi-Turn
  {RL}"
firstpage: 62178
lastpage: 62209
page: 62178-62209
order: 62178
cycles: false
bibtex_author: Zhou, Yifei and Zanette, Andrea and Pan, Jiayi and Levine, Sergey and
  Kumar, Aviral
author:
- given: Yifei
  family: Zhou
- given: Andrea
  family: Zanette
- given: Jiayi
  family: Pan
- given: Sergey
  family: Levine
- given: Aviral
  family: Kumar
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhou24t/zhou24t.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

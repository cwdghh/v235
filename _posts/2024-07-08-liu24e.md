---
title: Adaptive Text Watermark for Large Language Models
openreview: 7emOSb5UfX
abstract: The advancement of Large Language Models (LLMs) has led to increasing concerns
  about the misuse of AI-generated text, and watermarking LLM-generated text has emerged
  as a potential solution. However, it is challenging to generate high-quality watermarked
  text while maintaining robustness, security, and the ability to detect watermarks
  without prior knowledge of the prompt and model. This paper proposes an adaptive
  text watermarking strategy to address such a challenge. To improve the text quality
  and maintain robustness, we adaptively add watermarking to token distributions with
  high entropy measured by an auxiliary model and keep the low-entropy token distributions
  untouched. For the sake of security and to further minimize the watermarkâ€™s impact
  on text quality, instead of using a fixed green/red list generated from a random
  secret key, which can be vulnerable to decryption and forgery, we adaptively scale
  up the output logits based on the semantic embedding of previously generated text
  using a well designed semantic mapping model. Our experiments involving various
  LLMs demonstrate that our approach achieves comparable robustness performance to
  existing watermark methods. Additionally, the text generated by our method has perplexity
  comparable to that of <em>un-watermarked</em> LLMs while maintaining sufficient
  security.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24e
month: 0
tex_title: Adaptive Text Watermark for Large Language Models
firstpage: 30718
lastpage: 30737
page: 30718-30737
order: 30718
cycles: false
bibtex_author: Liu, Yepeng and Bu, Yuheng
author:
- given: Yepeng
  family: Liu
- given: Yuheng
  family: Bu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/liu24e/liu24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation
openreview: Zos5wsaB5r
abstract: The ability to accurately comprehend natural language instructions and navigate
  to the target location is essential for an embodied agent. Such agents are typically
  required to execute user instructions in an online manner, leading us to explore
  the use of unlabeled test samples for effective online model adaptation. However,
  for online Vision-and-Language Navigation (VLN), due to the intrinsic nature of
  inter-sample online instruction execution and intra-sample multi-step action decision,
  frequent updates can result in drastic changes in model parameters, while occasional
  updates can make the model ill-equipped to handle dynamically changing environments.
  Therefore, we propose a Fast-Slow Test-Time Adaptation (FSTTA) approach for online
  VLN by performing joint decomposition-accumulation analysis for both gradients and
  parameters in a unified framework. Extensive experiments show that our method obtains
  impressive performance gains on four popular benchmarks. Code is available at https://github.com/Feliciaxyao/ICML2024-FSTTA.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: gao24p
month: 0
tex_title: Fast-Slow Test-Time Adaptation for Online Vision-and-Language Navigation
firstpage: 14902
lastpage: 14919
page: 14902-14919
order: 14902
cycles: false
bibtex_author: Gao, Junyu and Yao, Xuan and Xu, Changsheng
author:
- given: Junyu
  family: Gao
- given: Xuan
  family: Yao
- given: Changsheng
  family: Xu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/gao24p/gao24p.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

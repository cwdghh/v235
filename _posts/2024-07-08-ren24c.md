---
title: Hybrid Inverse Reinforcement Learning
openreview: 2zI2scD2Iz
abstract: The inverse reinforcement learning approach to imitation learning is a double-edged
  sword. On the one hand, it can enable learning from a smaller number of expert demonstrations
  with more robustness to error compounding than behavioral cloning approaches. On
  the other hand, it requires that the learner repeatedly solve a computationally
  expensive reinforcement learning (RL) problem. Often, much of this computation is
  wasted searching over policies very dissimilar to the expert’s. In this work, we
  propose using <em>hybrid RL</em> – training on a mixture of online and expert data
  – to curtail unnecessary exploration. Intuitively, the expert data focuses the learner
  on good states during training, which reduces the amount of exploration required
  to compute a strong policy. Notably, such an approach doesn’t need the ability to
  reset the learner to arbitrary states in the environment, a requirement of prior
  work in efficient inverse RL. More formally, we derive a reduction from inverse
  RL to <em>expert-competitive RL</em> (rather than globally optimal RL) that allows
  us to dramatically reduce interaction during the inner policy search loop while
  maintaining the benefits of the IRL approach. This allows us to derive both model-free
  and model-based hybrid inverse RL algorithms with strong policy performance guarantees.
  Empirically, we find that our approaches are significantly more sample efficient
  than standard inverse RL and several other baselines on a suite of continuous control
  tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ren24c
month: 0
tex_title: Hybrid Inverse Reinforcement Learning
firstpage: 42428
lastpage: 42448
page: 42428-42448
order: 42428
cycles: false
bibtex_author: Ren, Juntao and Swamy, Gokul and Wu, Steven and Bagnell, Drew and Choudhury,
  Sanjiban
author:
- given: Juntao
  family: Ren
- given: Gokul
  family: Swamy
- given: Steven
  family: Wu
- given: Drew
  family: Bagnell
- given: Sanjiban
  family: Choudhury
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/ren24c/ren24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

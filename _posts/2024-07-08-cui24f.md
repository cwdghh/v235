---
title: 'ULTRAFEEDBACK: Boosting Language Models with Scaled AI Feedback'
openreview: BOorDpKHiJ
abstract: Learning from human feedback has become a pivot technique in aligning large
  language models (LLMs) with human preferences. However, acquiring vast and premium
  human feedback is bottlenecked by time, labor, and human capability, resulting in
  small sizes or limited topics of current datasets. This further hinders feedback
  learning as well as alignment research within the open-source community. To address
  this issue, we explore how to go beyond human feedback and collect high-quality
  AI feedback automatically for a scalable alternative. Specifically, we identify
  scale and diversity as the key factors for feedback data to take effect. Accordingly,
  we first broaden instructions and responses in both amount and breadth to encompass
  a wider range of user-assistant interactions. Then, we meticulously apply a series
  of techniques to mitigate annotation biases for more reliable AI feedback. We finally
  present UltraFeedback, a large-scale, high-quality, and diversified AI feedback
  dataset, which contains over 1 million GPT-4 feedback for 250k user-assistant conversations
  from various aspects. Built upon UltraFeedback, we align a LLaMA-based model by
  best-of-$n$ sampling and reinforcement learning, demonstrating its exceptional performance
  on chat benchmarks. Our work validates the effectiveness of scaled AI feedback data
  in constructing strong open-source chat language models, serving as a solid foundation
  for future feedback learning research.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: cui24f
month: 0
tex_title: "{ULTRAFEEDBACK}: Boosting Language Models with Scaled {AI} Feedback"
firstpage: 9722
lastpage: 9744
page: 9722-9744
order: 9722
cycles: false
bibtex_author: Cui, Ganqu and Yuan, Lifan and Ding, Ning and Yao, Guanming and He,
  Bingxiang and Zhu, Wei and Ni, Yuan and Xie, Guotong and Xie, Ruobing and Lin, Yankai
  and Liu, Zhiyuan and Sun, Maosong
author:
- given: Ganqu
  family: Cui
- given: Lifan
  family: Yuan
- given: Ning
  family: Ding
- given: Guanming
  family: Yao
- given: Bingxiang
  family: He
- given: Wei
  family: Zhu
- given: Yuan
  family: Ni
- given: Guotong
  family: Xie
- given: Ruobing
  family: Xie
- given: Yankai
  family: Lin
- given: Zhiyuan
  family: Liu
- given: Maosong
  family: Sun
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/cui24f/cui24f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

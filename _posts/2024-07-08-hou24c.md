---
title: 'PrE-Text: Training Language Models on Private Federated Data in the Age of
  LLMs'
openreview: 3WCvnkHnxV
abstract: 'On-device training is currently the most common approach for training machine
  learning (ML) models on private, distributed user data. Despite this, on-device
  training has several drawbacks: (1) most user devices are too small to train large
  models on-device, (2) on-device training is communication- and computation-intensive,
  and (3) on-device training can be difficult to debug and deploy. To address these
  problems, we propose Private Evolution-Text (PrE-Text), a method for generating
  differentially private (DP) synthetic textual data. First, we show that across multiple
  datasets, training small models (models that fit on user devices) with PrE-Text
  synthetic data outperforms small models trained on-device under practical privacy
  regimes ($\epsilon=1.29$, $\epsilon=7.58$). We achieve these results while using
  9$\times$ fewer rounds, 6$\times$ less client computation per round, and 100$\times$
  less communication per round. Second, finetuning large models on PrE-Textâ€™s DP synthetic
  data improves large language model (LLM) performance on private data across the
  same range of privacy budgets. Altogether, these results suggest that training on
  DP synthetic data can be a better option than training a model on-device on private
  distributed data. Code is available at https://github.com/houcharlie/PrE-Text.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hou24c
month: 0
tex_title: "{P}r{E}-Text: Training Language Models on Private Federated Data in the
  Age of {LLM}s"
firstpage: 19043
lastpage: 19061
page: 19043-19061
order: 19043
cycles: false
bibtex_author: Hou, Charlie and Shrivastava, Akshat and Zhan, Hongyuan and Conway,
  Rylan and Le, Trang and Sagar, Adithya and Fanti, Giulia and Lazar, Daniel
author:
- given: Charlie
  family: Hou
- given: Akshat
  family: Shrivastava
- given: Hongyuan
  family: Zhan
- given: Rylan
  family: Conway
- given: Trang
  family: Le
- given: Adithya
  family: Sagar
- given: Giulia
  family: Fanti
- given: Daniel
  family: Lazar
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/hou24c/hou24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

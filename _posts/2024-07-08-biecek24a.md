---
title: 'Position: Explain to Question not to Justify'
openreview: ooikIHLHCs
abstract: Explainable Artificial Intelligence (XAI) is a young but very promising
  field of research. Unfortunately, the progress in this field is currently slowed
  down by divergent and incompatible goals. We separate various threads tangled within
  the area of XAI into two complementary cultures of human/value-oriented explanations
  (BLUE XAI) and model/validation-oriented explanations (RED XAI). This position paper
  argues that the area of RED XAI is currently under-explored, i.e., more methods
  for explainability are desperately needed to question models (e.g., extract knowledge
  from well-performing models as well as spotting and fixing bugs in faulty models),
  and the area of RED XAI hides great opportunities and potential for important research
  necessary to ensure the safety of AI systems. We conclude this paper by presenting
  promising challenges in this area.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: biecek24a
month: 0
tex_title: 'Position: Explain to Question not to Justify'
firstpage: 3996
lastpage: 4006
page: 3996-4006
order: 3996
cycles: false
bibtex_author: Biecek, Przemyslaw and Samek, Wojciech
author:
- given: Przemyslaw
  family: Biecek
- given: Wojciech
  family: Samek
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/biecek24a/biecek24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Fundamental Limits of Distributed Covariance Matrix Estimation Under Communication
  Constraints
openreview: biE1uHyG0l
abstract: Estimating high-dimensional covariance matrices is crucial in various domains.
  This work considers a scenario where two collaborating agents access disjoint dimensions
  of $m$ samples from a high–dimensional random vector, and they can only communicate
  a limited number of bits to a central server, which wants to accurately approximate
  the covariance matrix. We analyze the fundamental trade–off between communication
  cost, number of samples, and estimation accuracy. We prove a lower bound on the
  error achievable by any estimator, highlighting the impact of dimensions, number
  of samples, and communication budget. Furthermore, we present an algorithm that
  achieves this lower bound up to a logarithmic factor, demonstrating its near-optimality
  in practical settings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: rahmani24a
month: 0
tex_title: Fundamental Limits of Distributed Covariance Matrix Estimation Under Communication
  Constraints
firstpage: 41927
lastpage: 41958
page: 41927-41958
order: 41927
cycles: false
bibtex_author: Rahmani, Mohammad Reza and Yassaee, Mohammad Hossein and Maddah-Ali,
  Mohammad Ali and Aref, Mohammad Reza
author:
- given: Mohammad Reza
  family: Rahmani
- given: Mohammad Hossein
  family: Yassaee
- given: Mohammad Ali
  family: Maddah-Ali
- given: Mohammad Reza
  family: Aref
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/rahmani24a/rahmani24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Fast Timing-Conditioned Latent Audio Diffusion
openreview: jOlO8t1xdx
abstract: Generating long-form 44.1kHz stereo audio from text prompts can be computationally
  demanding. Further, most previous works do not tackle that music and sound effects
  naturally vary in their duration. Our research focuses on the efficient generation
  of long-form, variable-length stereo music and sounds at 44.1kHz using text prompts
  with a generative model. It is based on latent diffusion, with its latent defined
  by a fully-convolutional variational autoencoder. The generative model is conditioned
  on text prompts as well as timing embeddings, allowing for fine control over both
  the content and length of the generated music and sounds. It is capable of rendering
  stereo signals of up to 95 sec at 44.1kHz in 8 sec on an A100 GPU. Despite its compute
  efficiency and fast inference, the proposed model is one of the best in two public
  text-to-music and -audio benchmarks and, differently from state-of-the-art models,
  can generate music with structure and stereo sounds.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: evans24a
month: 0
tex_title: Fast Timing-Conditioned Latent Audio Diffusion
firstpage: 12652
lastpage: 12665
page: 12652-12665
order: 12652
cycles: false
bibtex_author: Evans, Zach and Carr, Cj and Taylor, Josiah and Hawley, Scott H. and
  Pons, Jordi
author:
- given: Zach
  family: Evans
- given: Cj
  family: Carr
- given: Josiah
  family: Taylor
- given: Scott H.
  family: Hawley
- given: Jordi
  family: Pons
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/evans24a/evans24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

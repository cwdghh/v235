---
title: 'BECoTTA: Input-dependent Online Blending of Experts for Continual Test-time
  Adaptation'
openreview: 5zXTwX92qv
abstract: 'Continual Test-Time Adaptation (CTTA) is designed to optimize the model
  during deployment under changing conditions. CTTA is an important problem as it
  enables models to remain effective and reliable in dynamic and evolving environments.
  However, tackling the CTTA problem is nontrivial. The model needs to be computationally
  and memory-efficient to rapidly update its parameters for ever-changing environments
  in real-time. Also, the model should generalize well to new unseen domains while
  maintaining its capability on previously encountered ones, as old domains can be
  revisited in future adaptation phases. To tackle these challenges, this paper proposes
  BECoTTA, a parameter/memory-efficient yet powerful framework for CTTA. We introduce
  Mixture-of-Domain Low-rank Experts (MoDE) that contains two core components: ?i)
  Domain-Adaptive Routing, which can aid in selectively capturing the domain-adaptive
  knowledge, and ii) Domain-Expert Synergy Loss to maximize the dependency between
  each domain and expert. We validate our proposed method over multiple CTTA benchmarks,
  getting 5.81% performance gain, while only requiring 0.001x trainable parameters.
  We also provide analyses of our BECoTTA, including expert assignment and target
  domain relation.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lee24ab
month: 0
tex_title: "{BEC}o{TTA}: Input-dependent Online Blending of Experts for Continual
  Test-time Adaptation"
firstpage: 27072
lastpage: 27093
page: 27072-27093
order: 27072
cycles: false
bibtex_author: Lee, Daeun and Yoon, Jaehong and Hwang, Sung Ju
author:
- given: Daeun
  family: Lee
- given: Jaehong
  family: Yoon
- given: Sung Ju
  family: Hwang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/lee24ab/lee24ab.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

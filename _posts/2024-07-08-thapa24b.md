---
title: Bayesian Adaptation of Network Depth and Width for Continual Learning
openreview: c9HddKGiYk
abstract: While existing dynamic architecture-based continual learning methods adapt
  network width by growing new branches, they overlook the critical aspect of network
  depth. We propose a novel non-parametric Bayesian approach to infer network depth
  and adapt network width while maintaining model performance across tasks. Specifically,
  we model the growth of network depth with a beta process and apply drop-connect
  regularization to network width using a conjugate Bernoulli process. Our results
  show that our proposed method achieves superior or comparable performance with state-of-the-art
  methods across various continual learning benchmarks. Moreover, our approach can
  be readily extended to unsupervised continual learning, showcasing competitive performance
  compared to existing techniques.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: thapa24b
month: 0
tex_title: "{B}ayesian Adaptation of Network Depth and Width for Continual Learning"
firstpage: 48038
lastpage: 48061
page: 48038-48061
order: 48038
cycles: false
bibtex_author: Thapa, Jeevan and Li, Rui
author:
- given: Jeevan
  family: Thapa
- given: Rui
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/thapa24b/thapa24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

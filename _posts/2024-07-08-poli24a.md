---
title: Mechanistic Design and Scaling of Hybrid Architectures
openreview: GDp7Gyd9nf
abstract: The development of deep learning architectures is a resource-demanding process,
  due to a vast design space, long prototyping times, and high compute costs associated
  with at-scale model training and evaluation. We set out to simplify this process
  by grounding it in an end-to-end mechanistic architecture design (MAD) pipeline,
  encompassing small-scale capability unit tests predictive of scaling laws. Through
  a suite of synthetic token manipulation tasks such as compression and recall, designed
  to probe capabilities, we identify and test new hybrid architectures constructed
  from a variety of computational primitives. We experimentally validate the resulting
  architectures via an extensive compute-optimal and a new state-optimal scaling law
  analysis, training over 500 language models between 70M to 7B parameters. Surprisingly,
  we find MAD synthetics to correlate with compute-optimal perplexity, enabling accurate
  evaluation of new architectures via isolated proxy tasks. The new architectures
  found via MAD, based on simple ideas such as hybridization and sparsity, outperform
  state-of-the-art Transformer, convolutional, and recurrent architectures (Transformer++,
  Hyena, Mamba) in scaling, both at compute-optimal budgets and in overtrained regimes.
  Overall, these results provide evidence that performance on curated synthetic tasks
  can be predictive of scaling laws, and that an optimal architecture should leverage
  specialized layers via a hybrid topology.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: poli24a
month: 0
tex_title: Mechanistic Design and Scaling of Hybrid Architectures
firstpage: 40908
lastpage: 40950
page: 40908-40950
order: 40908
cycles: false
bibtex_author: Poli, Michael and Thomas, Armin W and Nguyen, Eric and Ponnusamy, Pragaash
  and Deiseroth, Bj\"{o}rn and Kersting, Kristian and Suzuki, Taiji and Hie, Brian
  and Ermon, Stefano and Re, Christopher and Zhang, Ce and Massaroli, Stefano
author:
- given: Michael
  family: Poli
- given: Armin W
  family: Thomas
- given: Eric
  family: Nguyen
- given: Pragaash
  family: Ponnusamy
- given: Bj√∂rn
  family: Deiseroth
- given: Kristian
  family: Kersting
- given: Taiji
  family: Suzuki
- given: Brian
  family: Hie
- given: Stefano
  family: Ermon
- given: Christopher
  family: Re
- given: Ce
  family: Zhang
- given: Stefano
  family: Massaroli
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/poli24a/poli24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

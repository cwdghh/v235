---
title: Environment Design for Inverse Reinforcement Learning
openreview: Ar0dsOMStE
abstract: Learning a reward function from demonstrations suffers from low sample-efficiency.
  Even with abundant data, current inverse reinforcement learning methods that focus
  on learning from a single environment can fail to handle slight changes in the environment
  dynamics. We tackle these challenges through adaptive environment design. In our
  framework, the learner repeatedly interacts with the expert, with the former selecting
  environments to identify the reward function as quickly as possible from the expertâ€™s
  demonstrations in said environments. This results in improvements in both sample-efficiency
  and robustness, as we show experimentally, for both exact and approximate inference.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kleine-buening24a
month: 0
tex_title: Environment Design for Inverse Reinforcement Learning
firstpage: 24808
lastpage: 24828
page: 24808-24828
order: 24808
cycles: false
bibtex_author: Kleine Buening, Thomas and Villin, Victor and Dimitrakakis, Christos
author:
- given: Thomas
  family: Kleine Buening
- given: Victor
  family: Villin
- given: Christos
  family: Dimitrakakis
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/kleine-buening24a/kleine-buening24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

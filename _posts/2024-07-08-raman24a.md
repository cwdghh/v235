---
title: Understanding Inter-Concept Relationships in Concept-Based Models
openreview: JA6ThxAmth
abstract: Concept-based explainability methods provide insight into deep learning
  systems by constructing explanations using human-understandable concepts. While
  the literature on human reasoning demonstrates that we exploit relationships between
  concepts when solving tasks, it is unclear whether concept-based methods incorporate
  the rich structure of inter-concept relationships. We analyse the concept representations
  learnt by concept-based models to understand whether these models correctly capture
  inter-concept relationships. First, we empirically demonstrate that state-of-the-art
  concept-based models produce representations that lack stability and robustness,
  and such methods fail to capture inter-concept relationships. Then, we develop a
  novel algorithm which leverages inter-concept relationships to improve concept intervention
  accuracy, demonstrating how correctly capturing inter-concept relationships can
  improve downstream tasks.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: raman24a
month: 0
tex_title: Understanding Inter-Concept Relationships in Concept-Based Models
firstpage: 42009
lastpage: 42025
page: 42009-42025
order: 42009
cycles: false
bibtex_author: Raman, Naveen Janaki and Espinosa Zarlenga, Mateo and Jamnik, Mateja
author:
- given: Naveen Janaki
  family: Raman
- given: Mateo
  family: Espinosa Zarlenga
- given: Mateja
  family: Jamnik
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/raman24a/raman24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

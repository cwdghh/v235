---
title: 'Position: Building Guardrails for Large Language Models Requires Systematic
  Design'
openreview: JvMLkGF2Ms
abstract: As Large Language Models (LLMs) become more integrated into our daily lives,
  it is crucial to identify and mitigate their risks, especially when the risks can
  have profound impacts on human users and societies. Guardrails, which filter the
  inputs or outputs of LLMs, have emerged as a core safeguarding technology. This
  position paper takes a deep look at current open-source solutions (Llama Guard,
  Nvidia NeMo, Guardrails AI), and discusses the challenges and the road towards building
  more complete solutions. Drawing on robust evidence from previous research, we advocate
  for a systematic approach to construct guardrails for LLMs, based on comprehensive
  consideration of diverse contexts across various LLMs applications. We propose employing
  socio-technical methods through collaboration with a multi-disciplinary team to
  pinpoint precise technical requirements, exploring advanced neural-symbolic implementations
  to embrace the complexity of the requirements, and developing verification and testing
  to ensure the utmost quality of the final product.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: dong24c
month: 0
tex_title: 'Position: Building Guardrails for Large Language Models Requires Systematic
  Design'
firstpage: 11375
lastpage: 11394
page: 11375-11394
order: 11375
cycles: false
bibtex_author: Dong, Yi and Mu, Ronghui and Jin, Gaojie and Qi, Yi and Hu, Jinwei
  and Zhao, Xingyu and Meng, Jie and Ruan, Wenjie and Huang, Xiaowei
author:
- given: Yi
  family: Dong
- given: Ronghui
  family: Mu
- given: Gaojie
  family: Jin
- given: Yi
  family: Qi
- given: Jinwei
  family: Hu
- given: Xingyu
  family: Zhao
- given: Jie
  family: Meng
- given: Wenjie
  family: Ruan
- given: Xiaowei
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/dong24c/dong24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

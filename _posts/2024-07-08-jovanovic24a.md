---
title: Watermark Stealing in Large Language Models
openreview: Wp054bnPq9
abstract: LLM watermarking has attracted attention as a promising way to detect AI-generated
  content, with some works suggesting that current schemes may already be fit for
  deployment. In this work we dispute this claim, identifying <em>watermark stealing</em>
  (WS) as a fundamental vulnerability of these schemes. We show that querying the
  API of the watermarked LLM to approximately reverse-engineer a watermark enables
  practical <em>spoofing attacks</em>, as hypothesized in prior work, but also greatly
  boosts <em>scrubbing</em> attacks, which was previously unnoticed. We are the first
  to propose an automated WS algorithm and use it in the first comprehensive study
  of spoofing and scrubbing in realistic settings. We show that for under $50 an attacker
  can both spoof and scrub state-of-the-art schemes previously considered safe, with
  average success rate of over 80%. Our findings challenge common beliefs about LLM
  watermarking, stressing the need for more robust schemes. We make all our code and
  additional examples available at https://watermark-stealing.org.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jovanovic24a
month: 0
tex_title: Watermark Stealing in Large Language Models
firstpage: 22570
lastpage: 22593
page: 22570-22593
order: 22570
cycles: false
bibtex_author: Jovanovi\'{c}, Nikola and Staab, Robin and Vechev, Martin
author:
- given: Nikola
  family: JovanoviÄ‡
- given: Robin
  family: Staab
- given: Martin
  family: Vechev
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/jovanovic24a/jovanovic24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

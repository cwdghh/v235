---
title: A Minimaximalist Approach to Reinforcement Learning from Human Feedback
openreview: 5kVgd2MwMY
abstract: We present <em>Self-Play Preference Optimization</em> (SPO), an algorithm
  for reinforcement learning from human feedback. Our approach is <em>minimalist</em>
  in that it does not require training a reward model nor unstable adversarial training
  and is therefore rather simple to implement. Our approach is <em>maximalist</em>
  in that it provably handles non-Markovian, intransitive, and stochastic preferences
  while being robust to the compounding errors that plague offline approaches to sequential
  prediction. To achieve the preceding qualities, we build upon the concept of a <em>Minimax
  Winner</em> (MW), a notion of preference aggregation from the social choice theory
  literature that frames learning from preferences as a zero-sum game between two
  policies. By leveraging the symmetry of this game, we prove that rather than using
  the traditional technique of dueling two policies to compute the MW, we can simply
  have a <em>single</em> agent play against itself while maintaining strong convergence
  guarantees. Practically, this corresponds to sampling multiple trajectories from
  a policy, asking a <em>preference</em> or teacher model to compare them, and then
  using the proportion of wins as the reward for a particular trajectory. We demonstrate
  that on a suite of continuous control tasks, we are able to learn significantly
  more efficiently than reward-model based approaches while maintaining robustness
  to the intransitive and stochastic preferences that frequently occur in practice
  when aggregating human judgments.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: swamy24a
month: 0
tex_title: A Minimaximalist Approach to Reinforcement Learning from Human Feedback
firstpage: 47345
lastpage: 47377
page: 47345-47377
order: 47345
cycles: false
bibtex_author: Swamy, Gokul and Dann, Christoph and Kidambi, Rahul and Wu, Steven
  and Agarwal, Alekh
author:
- given: Gokul
  family: Swamy
- given: Christoph
  family: Dann
- given: Rahul
  family: Kidambi
- given: Steven
  family: Wu
- given: Alekh
  family: Agarwal
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/swamy24a/swamy24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

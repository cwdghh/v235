---
title: Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models
  for High-dimensional Gaussian Mixtures
openreview: ddjRdm3wUW
abstract: Deep equilibrium models (DEQs), as typical implicit neural networks, have
  demonstrated remarkable success on various tasks. There is, however, a lack of theoretical
  understanding of the connections and differences between implicit DEQs and explicit
  neural network models. In this paper, leveraging recent advances in random matrix
  theory (RMT), we perform an in-depth analysis on the eigenspectra of the conjugate
  kernel (CK) and neural tangent kernel (NTK) matrices for implicit DEQs, when the
  input data are drawn from a high-dimensional Gaussia mixture. We prove that, in
  this setting, the spectral behavior of these Implicit-CKs and NTKs depend on the
  DEQ activation function and initial weight variances, <em>but only via a system
  of four nonlinear equations</em>. As a direct consequence of this theoretical result,
  we demonstrate that a shallow explicit network can be carefully designed to produce
  the same CK or NTK as a given DEQ. Despite derived here for Gaussian mixture data,
  empirical results show the proposed theory and design principles also apply to popular
  real-world datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ling24a
month: 0
tex_title: Deep Equilibrium Models are Almost Equivalent to Not-so-deep Explicit Models
  for High-dimensional {G}aussian Mixtures
firstpage: 30585
lastpage: 30609
page: 30585-30609
order: 30585
cycles: false
bibtex_author: Ling, Zenan and Li, Longbo and Feng, Zhanbo and Zhang, Yixuan and Zhou,
  Feng and Qiu, Robert C and Liao, Zhenyu
author:
- given: Zenan
  family: Ling
- given: Longbo
  family: Li
- given: Zhanbo
  family: Feng
- given: Yixuan
  family: Zhang
- given: Feng
  family: Zhou
- given: Robert C
  family: Qiu
- given: Zhenyu
  family: Liao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/ling24a/ling24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

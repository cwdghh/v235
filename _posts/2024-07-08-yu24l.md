---
title: 'Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large Language
  Models without Training through Attention Calibration'
openreview: DLTjFFiuUJ
abstract: Attention is a fundamental component behind the remarkable achievements
  of large language models (LLMs). However, our current understanding of the attention
  mechanism, especially regarding how attention distributions are established, remains
  limited. Inspired by recent studies that explore the presence of attention sink
  in the initial token, which receives disproportionately large attention scores despite
  their lack of semantic importance, this work delves deeper into this phenomenon.
  We aim to provide a more profound understanding of the existence of attention sinks
  within LLMs and to uncover ways to enhance the achievable accuracy of LLMs by directly
  optimizing the attention distributions, without the need for weight finetuning.
  Specifically, this work begins with comprehensive visualizations of the attention
  distributions in LLMs during inference across various inputs and tasks. Based on
  these visualizations, to the best of our knowledge, we are the first to discover
  that (1) attention sinks occur not only at the start of sequences but also within
  later tokens of the input, and (2) not all attention sinks have a positive impact
  on the achievable accuracy of LLMs. Building upon our findings, we propose a training-free
  Attention Calibration Technique (ACT) that automatically optimizes the attention
  distributions on the fly during inference in an input-adaptive manner. Extensive
  experiments validate that ACT consistently enhances the accuracy of various LLMs
  across different applications. Specifically, ACT achieves an average improvement
  of up to $7.30%$ in accuracy across different datasets when applied to Llama-30B.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yu24l
month: 0
tex_title: 'Unveiling and Harnessing Hidden Attention Sinks: Enhancing Large Language
  Models without Training through Attention Calibration'
firstpage: 57659
lastpage: 57677
page: 57659-57677
order: 57659
cycles: false
bibtex_author: Yu, Zhongzhi and Wang, Zheng and Fu, Yonggan and Shi, Huihong and Shaikh,
  Khalid and Lin, Yingyan Celine
author:
- given: Zhongzhi
  family: Yu
- given: Zheng
  family: Wang
- given: Yonggan
  family: Fu
- given: Huihong
  family: Shi
- given: Khalid
  family: Shaikh
- given: Yingyan Celine
  family: Lin
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/yu24l/yu24l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

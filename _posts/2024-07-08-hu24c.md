---
title: Q-value Regularized Transformer for Offline Reinforcement Learning
openreview: ojtddicekd
abstract: Recent advancements in offline reinforcement learning (RL) have underscored
  the capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns
  the action distribution based on history trajectory and target returns for each
  state. However, these methods often struggle with stitching together optimal trajectories
  from sub-optimal ones due to the inconsistency between the sampled returns within
  individual trajectories and the optimal returns across multiple trajectories. Fortunately,
  Dynamic Programming (DP) methods offer a solution by leveraging a value function
  to approximate optimal future returns for each state, while these techniques are
  prone to unstable learning behaviors, particularly in long-horizon and sparse-reward
  scenarios. Building upon these insights, we propose the Q-value regularized Transformer
  (QT), which combines the trajectory modeling ability of the Transformer with the
  predictability of optimal future returns from DP methods. QT learns an action-value
  function and integrates a term maximizing action-values into the training loss of
  CSM, which aims to seek optimal actions that align closely with the behavior policy.
  Empirical evaluations on D4RL benchmark datasets demonstrate the superiority of
  QT over traditional DP and CSM methods, highlighting the potential of QT to enhance
  the state-of-the-art in offline RL.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu24c
month: 0
tex_title: Q-value Regularized Transformer for Offline Reinforcement Learning
firstpage: 19165
lastpage: 19181
page: 19165-19181
order: 19165
cycles: false
bibtex_author: Hu, Shengchao and Fan, Ziqing and Huang, Chaoqin and Shen, Li and Zhang,
  Ya and Wang, Yanfeng and Tao, Dacheng
author:
- given: Shengchao
  family: Hu
- given: Ziqing
  family: Fan
- given: Chaoqin
  family: Huang
- given: Li
  family: Shen
- given: Ya
  family: Zhang
- given: Yanfeng
  family: Wang
- given: Dacheng
  family: Tao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/hu24c/hu24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Adaptively Perturbed Mirror Descent for Learning in Games
openreview: 9U29U3cDKq
abstract: This paper proposes a payoff perturbation technique for the Mirror Descent
  (MD) algorithm in games where the gradient of the payoff functions is monotone in
  the strategy profile space, potentially containing additive noise. The optimistic
  family of learning algorithms, exemplified by optimistic MD, successfully achieves
  <em>last-iterate</em> convergence in scenarios devoid of noise, leading the dynamics
  to a Nash equilibrium. A recent re-emerging trend underscores the promise of the
  perturbation approach, where payoff functions are perturbed based on the distance
  from an anchoring, or <em>slingshot</em>, strategy. In response, we propose <em>Adaptively
  Perturbed MD</em> (APMD), which adjusts the magnitude of the perturbation by repeatedly
  updating the slingshot strategy at a predefined interval. This innovation empowers
  us to find a Nash equilibrium of the underlying game with guaranteed rates. Empirical
  demonstrations affirm that our algorithm exhibits significantly accelerated convergence.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: abe24a
month: 0
tex_title: Adaptively Perturbed Mirror Descent for Learning in Games
firstpage: 31
lastpage: 80
page: 31-80
order: 31
cycles: false
bibtex_author: Abe, Kenshi and Ariu, Kaito and Sakamoto, Mitsuki and Iwasaki, Atsushi
author:
- given: Kenshi
  family: Abe
- given: Kaito
  family: Ariu
- given: Mitsuki
  family: Sakamoto
- given: Atsushi
  family: Iwasaki
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/abe24a/abe24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

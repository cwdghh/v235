---
title: 'Reason for Future, Act for Now: A Principled Architecture for Autonomous LLM
  Agents'
openreview: MGkeWJxQVl
abstract: Large language models (LLMs) demonstrate impressive reasoning abilities,
  but translating reasoning into actions in the real world remains challenging. In
  particular, it is unclear how to complete a given task provably within a minimum
  number of interactions with the external environment, e.g., through an internal
  mechanism of reasoning. To this end, we propose the first framework with provable
  regret guarantees to orchestrate reasoning and acting, which we call <em>reason
  for future, act for now</em> (<b>RAFA</b>). Specifically, we design a prompt template
  for reasoning that learns from the memory buffer and plans a future trajectory over
  a long horizon (<em>reason for future</em>). At each step, the LLM agent takes the
  initial action of the planned trajectory (<em>act for now</em>), stores the collected
  feedback in the memory buffer, and reinvokes the reasoning routine to replan the
  future trajectory from the new state. The key idea is to cast reasoning in LLMs
  as learning and planning in Bayesian adaptive Markov decision processes (MDPs).
  Correspondingly, we prompt LLMs with the memory buffer to estimate the unknown environment
  (learning) and generate an optimal trajectory for multiple future steps that maximize
  a value function (planning). The learning and planning subroutines are performed
  in an in-context manner to emulate the actor-critic update for MDPs. Our theoretical
  analysis establishes a $\sqrt{T}$ regret, while our experimental validation demonstrates
  superior empirical performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24ab
month: 0
tex_title: 'Reason for Future, Act for Now: A Principled Architecture for Autonomous
  {LLM} Agents'
firstpage: 31186
lastpage: 31261
page: 31186-31261
order: 31186
cycles: false
bibtex_author: Liu, Zhihan and Hu, Hao and Zhang, Shenao and Guo, Hongyi and Ke, Shuqi
  and Liu, Boyi and Wang, Zhaoran
author:
- given: Zhihan
  family: Liu
- given: Hao
  family: Hu
- given: Shenao
  family: Zhang
- given: Hongyi
  family: Guo
- given: Shuqi
  family: Ke
- given: Boyi
  family: Liu
- given: Zhaoran
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/liu24ab/liu24ab.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic Prediction'
openreview: vye4OgLaTy
abstract: The objective of traffic prediction is to accurately forecast and analyze
  the dynamics of transportation patterns, considering both space and time. However,
  the presence of distribution shift poses a significant challenge in this field,
  as existing models struggle to generalize well when faced with test data that significantly
  differs from the training distribution. To tackle this issue, this paper introduces
  a simple and universal spatio-temporal prompt-tuning framework-FlashST, which adapts
  pre-trained models to the specific characteristics of diverse downstream datasets,
  improving generalization in diverse traffic prediction scenarios. Specifically,
  the FlashST framework employs a lightweight spatio-temporal prompt network for in-context
  learning, capturing spatio-temporal invariant knowledge and facilitating effective
  adaptation to diverse scenarios. Additionally, we incorporate a distribution mapping
  mechanism to align the data distributions of pre-training and downstream data, facilitating
  effective knowledge transfer in spatio-temporal forecasting. Empirical evaluations
  demonstrate the effectiveness of our FlashST across different spatio-temporal prediction
  tasks using diverse urban datasets. Code is available at https://github.com/HKUDS/FlashST.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24bw
month: 0
tex_title: "{F}lash{ST}: A Simple and Universal Prompt-Tuning Framework for Traffic
  Prediction"
firstpage: 28978
lastpage: 28988
page: 28978-28988
order: 28978
cycles: false
bibtex_author: Li, Zhonghang and Xia, Lianghao and Xu, Yong and Huang, Chao
author:
- given: Zhonghang
  family: Li
- given: Lianghao
  family: Xia
- given: Yong
  family: Xu
- given: Chao
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24bw/li24bw.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Scaling Tractable Probabilistic Circuits: A Systems Perspective'
openreview: BIbjwcrg0V
abstract: Probabilistic Circuits (PCs) are a general framework for tractable deep
  generative models, which support exact and efficient probabilistic inference on
  their learned distributions. Recent modeling and training advancements have enabled
  their application to complex real-world tasks. However, the time and memory inefficiency
  of existing PC implementations hinders further scaling up. This paper proposes PyJuice,
  a general GPU implementation design for PCs that improves prior art in several regards.
  Specifically, PyJuice is 1-2 orders of magnitude faster than existing systems (including
  very recent ones) at training large-scale PCs. Moreover, PyJuice consumes 2-5x less
  GPU memory, which enables us to train larger models. At the core of our system is
  a compilation process that converts a PC into a compact representation amenable
  to efficient block-based parallelization, which significantly reduces IO and makes
  it possible to leverage Tensor Cores available in modern GPUs. Empirically, PyJuice
  can be used to improve state-of-the-art PCs trained on image (e.g., ImageNet32)
  and language (e.g., WikiText, CommonGen) datasets. We further establish a new set
  of baselines on natural image and language datasets by benchmarking existing PC
  structures but with much larger sizes and more training epochs, with the hope of
  incentivizing future research. Code is available at https://github.com/Tractables/pyjuice.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24a
month: 0
tex_title: 'Scaling Tractable Probabilistic Circuits: A Systems Perspective'
firstpage: 30630
lastpage: 30646
page: 30630-30646
order: 30630
cycles: false
bibtex_author: Liu, Anji and Ahmed, Kareem and Van Den Broeck, Guy
author:
- given: Anji
  family: Liu
- given: Kareem
  family: Ahmed
- given: Guy
  family: Van Den Broeck
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/liu24a/liu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

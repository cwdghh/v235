---
title: Detecting Any instruction-to-answer interaction relationship:Universal Instruction-to-Answer
  Navigator for Med-VQA
openreview: 4XxsheIbtn
abstract: 'Medical Visual Question Answering (Med-VQA) interprets complex medical
  imagery using user instructions for precise diagnostics, yet faces challenges due
  to diverse, inadequately annotated images. In this paper, we introduce the Universal
  Instruction-Vision Navigator (Uni-Med) framework for extracting instruction-to-answer
  relationships, facilitating the understanding of visual evidence behind responses.
  Specifically, we design the Instruct-to-Answer Clues Interpreter (IAI) to generate
  visual explanations based on the answers and mark the core part of instructions
  with "real intent" labels. The IAI-Med VQA dataset, produced using IAI, is now publicly
  available to advance Med-VQA research. Additionally, our Token-Level Cut-Mix module
  dynamically aligns visual explanations with image patches, ensuring answers are
  traceable and learnable. We also implement intention-guided attention to minimize
  non-core instruction interference, sharpening focus on ’real intent’. Extensive
  experiments on SLAKE datasets show Uni-Med’s superior accuracies (87.52% closed,
  86.12% overall), outperforming MedVInT-PMC-VQA by 1.22% and 0.92%. Code and dataset
  are available at: https://github.com/zhongzee/Uni-Med-master.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wu24ac
month: 0
tex_title: Detecting Any instruction-to-answer interaction relationship:{U}niversal
  Instruction-to-Answer Navigator for Med-{VQA}
firstpage: 53909
lastpage: 53927
page: 53909-53927
order: 53909
cycles: false
bibtex_author: Wu, Zhongze and Xu, Hongyan and Long, Yitian and You, Shan and Su,
  Xiu and Long, Jun and Luo, Yueyi and Xu, Chang
author:
- given: Zhongze
  family: Wu
- given: Hongyan
  family: Xu
- given: Yitian
  family: Long
- given: Shan
  family: You
- given: Xiu
  family: Su
- given: Jun
  family: Long
- given: Yueyi
  family: Luo
- given: Chang
  family: Xu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wu24ac/wu24ac.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

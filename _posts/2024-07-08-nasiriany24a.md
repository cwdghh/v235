---
title: 'PIVOT: Iterative Visual Prompting Elicits Actionable Knowledge for VLMs'
openreview: 051jaf8MQy
abstract: Vision language models (VLMs) have shown impressive capabilities across
  a variety of tasks, from logical reasoning to visual understanding. This opens the
  door to richer interaction with the world, for example robotic control. However,
  VLMs produce only textual outputs, while robotic control and other spatial tasks
  require outputting continuous coordinates, actions, or trajectories. How can we
  enable VLMs to handle such settings without fine-tuning on task-specific data? In
  this paper, we propose a novel visual prompting approach for VLMs that we call Prompting
  with Iterative Visual Optimization (PIVOT), which casts tasks as iterative visual
  question answering. In each iteration, the image is annotated with a visual representation
  of proposals that the VLM can refer to (e.g., candidate robot actions, localizations,
  or trajectories). The VLM then selects the best ones for the task. These proposals
  are iteratively refined, allowing the VLM to eventually zero in on the best available
  answer. We investigate PIVOT on real-world robotic navigation, real-world manipulation
  from images, instruction following in simulation, and additional spatial inference
  tasks such as localization. We find, perhaps surprisingly, that our approach enables
  zero-shot control of robotic systems without any robot training data, navigation
  in a variety of environments, and other capabilities. Although current performance
  is far from perfect, our work highlights potentials and limitations of this new
  regime and shows a promising approach for Internet-Scale VLMs in robotic and spatial
  reasoning domains.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nasiriany24a
month: 0
tex_title: "{PIVOT}: Iterative Visual Prompting Elicits Actionable Knowledge for {VLM}s"
firstpage: 37321
lastpage: 37341
page: 37321-37341
order: 37321
cycles: false
bibtex_author: Nasiriany, Soroush and Xia, Fei and Yu, Wenhao and Xiao, Ted and Liang,
  Jacky and Dasgupta, Ishita and Xie, Annie and Driess, Danny and Wahid, Ayzaan and
  Xu, Zhuo and Vuong, Quan and Zhang, Tingnan and Lee, Tsang-Wei Edward and Lee, Kuang-Huei
  and Xu, Peng and Kirmani, Sean and Zhu, Yuke and Zeng, Andy and Hausman, Karol and
  Heess, Nicolas and Finn, Chelsea and Levine, Sergey and Ichter, Brian
author:
- given: Soroush
  family: Nasiriany
- given: Fei
  family: Xia
- given: Wenhao
  family: Yu
- given: Ted
  family: Xiao
- given: Jacky
  family: Liang
- given: Ishita
  family: Dasgupta
- given: Annie
  family: Xie
- given: Danny
  family: Driess
- given: Ayzaan
  family: Wahid
- given: Zhuo
  family: Xu
- given: Quan
  family: Vuong
- given: Tingnan
  family: Zhang
- given: Tsang-Wei Edward
  family: Lee
- given: Kuang-Huei
  family: Lee
- given: Peng
  family: Xu
- given: Sean
  family: Kirmani
- given: Yuke
  family: Zhu
- given: Andy
  family: Zeng
- given: Karol
  family: Hausman
- given: Nicolas
  family: Heess
- given: Chelsea
  family: Finn
- given: Sergey
  family: Levine
- given: Brian
  family: Ichter
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/nasiriany24a/nasiriany24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

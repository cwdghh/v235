---
title: Directly Denoising Diffusion Models
openreview: k5ncz7TIPX
abstract: 'In this paper, we present Directly Denoising Diffusion Models (DDDMs):
  a simple and generic approach for generating realistic images with few-step sampling,
  while multistep sampling is still preserved for better performance. DDDMs require
  no delicately designed samplers nor distillation on pre-trained distillation models.
  DDDMs train the diffusion model conditioned on an estimated target that was generated
  from previous training iterations of its own. To generate images, samples generated
  from previous timestep are also taken into consideration, guiding the generation
  process iteratively. We further propose Pseudo-LPIPS, a novel metric loss that is
  more robust to various values of hyperparameter. Despite its simplicity, the proposed
  approach can achieve strong performance in benchmark datasets. Our model achieves
  FID scores of 2.57 and 2.33 on CIFAR-10 in one-step and two-step sampling respectively,
  surpassing those obtained from GANs and distillation-based models. By extending
  the sampling to 1000 steps, we further reduce FID score to 1.79, aligning with state-of-the-art
  methods in the literature. For ImageNet 64x64, our approach stands as a competitive
  contender against leading models.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24bl
month: 0
tex_title: Directly Denoising Diffusion Models
firstpage: 59951
lastpage: 59974
page: 59951-59974
order: 59951
cycles: false
bibtex_author: Zhang, Dan and Wang, Jingjing and Luo, Feng
author:
- given: Dan
  family: Zhang
- given: Jingjing
  family: Wang
- given: Feng
  family: Luo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhang24bl/zhang24bl.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

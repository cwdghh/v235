---
title: Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks
openreview: M8UbECx485
abstract: An increasingly popular machine learning paradigm is to pretrain a neural
  network (NN) on many tasks offline, then adapt it to downstream tasks, often by
  re-training only the last linear layer of the network. This approach yields strong
  downstream performance in a variety of contexts, demonstrating that multitask pretraining
  leads to effective feature learning. Although several recent theoretical studies
  have shown that shallow NNs learn meaningful features when either (i) they are trained
  on a <em>single</em> task or (ii) they are <em>linear</em>, very little is known
  about the closer-to-practice case of <em>nonlinear</em> NNs trained on <em>multiple</em>
  tasks. In this work, we present the first results proving that feature learning
  occurs during training with a nonlinear model on multiple tasks. Our key insight
  is that multi-task pretraining induces a pseudo-contrastive loss that favors representations
  that align points that typically have the same label across tasks. Using this observation,
  we show that when the tasks are binary classification tasks with labels depending
  on the projection of the data onto an $r$-dimensional subspace within the $d\gg
  r$-dimensional input space, a simple gradient-based multitask learning algorithm
  on a two-layer ReLU NN recovers this projection, allowing for generalization to
  downstream tasks with sample and neuron complexity independent of $d$. In contrast,
  we show that with high probability over the draw of a single task, training on this
  single task cannot guarantee to learn all $r$ ground-truth features.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: collins24a
month: 0
tex_title: Provable Multi-Task Representation Learning by Two-Layer {R}e{LU} Neural
  Networks
firstpage: 9292
lastpage: 9345
page: 9292-9345
order: 9292
cycles: false
bibtex_author: Collins, Liam and Hassani, Hamed and Soltanolkotabi, Mahdi and Mokhtari,
  Aryan and Shakkottai, Sanjay
author:
- given: Liam
  family: Collins
- given: Hamed
  family: Hassani
- given: Mahdi
  family: Soltanolkotabi
- given: Aryan
  family: Mokhtari
- given: Sanjay
  family: Shakkottai
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/collins24a/collins24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Generative Marginalization Models
openreview: XmLNDlQuzO
abstract: We introduce <em>marginalization models</em> (MAMs), a new family of generative
  models for high-dimensional discrete data. They offer scalable and flexible generative
  modeling by explicitly modeling all induced marginal distributions. Marginalization
  models enable fast approximation of arbitrary marginal probabilities with a single
  forward pass of the neural network, which overcomes a major limitation of arbitrary
  marginal inference models, such as any-order autoregressive models. MAMs also address
  the scalability bottleneck encountered in training any-order generative models for
  high-dimensional problems under the context of <em>energy-based training</em>, where
  the goal is to match the learned distribution to a given desired probability (specified
  by an unnormalized log-probability function such as energy or reward function).
  We propose scalable methods for learning the marginals, grounded in the concept
  of "<em>marginalization self-consistency</em>". We demonstrate the effectiveness
  of the proposed model on a variety of discrete data distributions, including images,
  text, physical systems, and molecules, for <em>maximum likelihood</em> and <em>energy-based
  training</em> settings. MAMs achieve orders of magnitude speedup in evaluating the
  marginal probabilities on both settings. For energy-based training tasks, MAMs enable
  any-order generative modeling of high-dimensional problems beyond the scale of previous
  methods. Code is available at github.com/PrincetonLIPS/MaM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24az
month: 0
tex_title: Generative Marginalization Models
firstpage: 31773
lastpage: 31807
page: 31773-31807
order: 31773
cycles: false
bibtex_author: Liu, Sulin and Ramadge, Peter and Adams, Ryan P
author:
- given: Sulin
  family: Liu
- given: Peter
  family: Ramadge
- given: Ryan P
  family: Adams
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24az/liu24az.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

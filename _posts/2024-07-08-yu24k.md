---
title: 'ViP: A Differentially Private Foundation Model for Computer Vision'
openreview: 6aKwVmHQI1
abstract: Artificial intelligence (AI) has seen a tremendous surge in capabilities
  thanks to the use of foundation models trained on internet-scale data. On the flip
  side, the uncurated nature of internet-scale data also poses significant privacy
  and legal risks, as they often contain personal information or copyrighted material
  that should not be trained on without permission. In this work, we propose as a
  mitigation measure a recipe to train foundation vision models via self-supervised
  learning with differential privacy (DP) guarantee. We identify masked autoencoders
  as a suitable learning algorithm that aligns well with DP-SGD, and train <em>ViP</em>—a
  <b>Vi</b>sion transformer with differential <b>P</b>rivacy—under a strict privacy
  budget of $\epsilon=8$ on the LAION400M dataset. We evaluate the quality of representation
  learned by ViP using standard downstream vision tasks; in particular, ViP achieves
  a (non-private) linear probing accuracy of 55.7% on ImageNet, comparable to that
  of end-to-end trained AlexNet (trained and evaluated on ImageNet). Our result suggests
  that scaling to internet-scale data can be practical for private learning. Code
  and DP pre-trained models are available at https://github.com/facebookresearch/ViP-MAE.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yu24k
month: 0
tex_title: "{V}i{P}: A Differentially Private Foundation Model for Computer Vision"
firstpage: 57639
lastpage: 57658
page: 57639-57658
order: 57639
cycles: false
bibtex_author: Yu, Yaodong and Sanjabi, Maziar and Ma, Yi and Chaudhuri, Kamalika
  and Guo, Chuan
author:
- given: Yaodong
  family: Yu
- given: Maziar
  family: Sanjabi
- given: Yi
  family: Ma
- given: Kamalika
  family: Chaudhuri
- given: Chuan
  family: Guo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/yu24k/yu24k.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Improving Context Understanding in Multimodal Large Language Models via Multimodal
  Composition Learning
openreview: Nm6jYZsBum
abstract: 'Previous efforts using frozen Large Language Models (LLMs) for visual understanding,
  via image captioning or image-text retrieval tasks, face challenges when dealing
  with complex multimodal scenarios. In order to enhance the capabilities of Multimodal
  Large Language Models (MLLM) in comprehending the context of vision and language,
  we introduce Multimodal Composition Learning (MCL) for the purpose of mapping or
  aligning the vision and language input. In particular, we introduce two tasks: Multimodal-Context
  Captioning (MC-Cap) and Multimodal-Context Retrieval (MC-Ret) to guide a frozen
  LLM in comprehending the vision and language context. These specialized tasks are
  crafted to improve the LLMâ€™s capacity for efficient processing and utilization of
  multimodal inputs, thereby enhancing its proficiency in generating more accurate
  text or visual representations. Extensive experiments on both retrieval tasks (i.e.,
  zero-shot composed image retrieval, visual storytelling image retrieval and visual
  dialog image retrieval) and text generation tasks (i.e., visual question answering)
  demonstrate the effectiveness of the proposed method. The code is available at:
  https://github.com/dhg-wei/MCL.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24s
month: 0
tex_title: Improving Context Understanding in Multimodal Large Language Models via
  Multimodal Composition Learning
firstpage: 27732
lastpage: 27751
page: 27732-27751
order: 27732
cycles: false
bibtex_author: Li, Wei and Fan, Hehe and Wong, Yongkang and Yang, Yi and Kankanhalli,
  Mohan
author:
- given: Wei
  family: Li
- given: Hehe
  family: Fan
- given: Yongkang
  family: Wong
- given: Yi
  family: Yang
- given: Mohan
  family: Kankanhalli
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24s/li24s.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

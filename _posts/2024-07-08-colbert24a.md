---
title: 'A2Q+: Improving Accumulator-Aware Weight Quantization'
openreview: mbx2pLK5Eq
abstract: 'Quantization techniques commonly reduce the inference costs of neural networks
  by restricting the precision of weights and activations. Recent studies show that
  also reducing the precision of the accumulator can further improve hardware efficiency
  at the risk of numerical overflow, which introduces arithmetic errors that can degrade
  model accuracy. To avoid numerical overflow while maintaining accuracy, recent work
  proposed accumulator-aware quantization (A2Q)â€”a quantization-aware training method
  that constrains model weights during training to safely use a target accumulator
  bit width during inference. Although this shows promise, we demonstrate that A2Q
  relies on an overly restrictive constraint and a sub-optimal weight initialization
  strategy that each introduce superfluous quantization error. To address these shortcomings,
  we introduce: (1) an improved bound that alleviates accumulator constraints without
  compromising overflow avoidance; and (2) a new strategy for initializing quantized
  weights from pre-trained floating-point checkpoints. We combine these contributions
  with weight normalization to introduce A2Q+. We identify and characterize the various
  tradeoffs that arise as a consequence of accumulator constraints and support our
  analysis with experiments that show A2Q+ significantly improves these trade-offs
  when compared to prior methods.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: colbert24a
month: 0
tex_title: "{A}2{Q}+: Improving Accumulator-Aware Weight Quantization"
firstpage: 9275
lastpage: 9291
page: 9275-9291
order: 9275
cycles: false
bibtex_author: Colbert, Ian and Pappalardo, Alessandro and Petri-Koenig, Jakoba and
  Umuroglu, Yaman
author:
- given: Ian
  family: Colbert
- given: Alessandro
  family: Pappalardo
- given: Jakoba
  family: Petri-Koenig
- given: Yaman
  family: Umuroglu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/colbert24a/colbert24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

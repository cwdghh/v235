---
title: 'Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance
  in Machine Translation'
openreview: 51iwkioZpn
abstract: Moderate-sized large language models (LLMs) – those with 7B or 13B parameters
  – exhibit promising machine translation (MT) performance. However, they do not match
  the performance of state-of-the-art conventional encoder-decoder translation models
  or larger-scale LLMs such as GPT-4. In this study, we bridge this performance gap.
  We first assess the shortcomings of supervised fine-tuning for LLMs in the MT task,
  emphasizing the quality issues present in the reference data, despite being human-generated.
  Then, in contrast to supervised fine-tuning which mimics reference translations,
  we introduce Contrastive Preference Optimization (CPO), a novel approach that trains
  models to avoid generating adequate but not perfect translations. Applying CPO to
  ALMA models with only 22K parallel sentences and 0.1% parameters yields significant
  improvements. The resulting model, called ALMA-R, can match or exceed the performance
  of the WMT competition winners and GPT-4 on WMT’21, WMT’22 and WMT’23 test datasets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: xu24t
month: 0
tex_title: 'Contrastive Preference Optimization: Pushing the Boundaries of {LLM} Performance
  in Machine Translation'
firstpage: 55204
lastpage: 55224
page: 55204-55224
order: 55204
cycles: false
bibtex_author: Xu, Haoran and Sharaf, Amr and Chen, Yunmo and Tan, Weiting and Shen,
  Lingfeng and Van Durme, Benjamin and Murray, Kenton and Kim, Young Jin
author:
- given: Haoran
  family: Xu
- given: Amr
  family: Sharaf
- given: Yunmo
  family: Chen
- given: Weiting
  family: Tan
- given: Lingfeng
  family: Shen
- given: Benjamin
  family: Van Durme
- given: Kenton
  family: Murray
- given: Young Jin
  family: Kim
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/xu24t/xu24t.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

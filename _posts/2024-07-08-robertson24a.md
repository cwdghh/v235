---
title: Implicit Regularization in Feedback Alignment Learning Mechanisms for Neural
  Networks
openreview: qklMNNub0H
abstract: 'Feedback Alignment (FA) methods are biologically inspired local learning
  rules for training neural networks with reduced communication between layers. While
  FA has potential applications in distributed and privacy-aware ML, limitations in
  multi-class classification and lack of theoretical understanding of the alignment
  mechanism have constrained its impact. This study introduces a unified framework
  elucidating the operational principles behind alignment in FA. Our key contributions
  include: (1) a novel conservation law linking changes in synaptic weights to implicit
  regularization that maintains alignment with the gradient, with support from experiments,
  (2) sufficient conditions for convergence based on the concept of alignment dominance,
  and (3) empirical analysis showing better alignment can enhance FA performance on
  complex multi-class tasks. Overall, these theoretical and practical advancements
  improve interpretability of bio-plausible learning rules and provide groundwork
  for developing enhanced FA algorithms.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: robertson24a
month: 0
tex_title: Implicit Regularization in Feedback Alignment Learning Mechanisms for Neural
  Networks
firstpage: 42601
lastpage: 42619
page: 42601-42619
order: 42601
cycles: false
bibtex_author: Robertson, Zachary and Koyejo, Sanmi
author:
- given: Zachary
  family: Robertson
- given: Sanmi
  family: Koyejo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/robertson24a/robertson24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

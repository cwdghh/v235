---
title: 'Position: AI-Powered Autonomous Weapons Risk Geopolitical Instability and
  Threaten AI Research'
openreview: ZwUThOE7Zc
abstract: The recent embrace of machine learning (ML) in the development of autonomous
  weapons systems (AWS) creates serious risks to geopolitical stability and the free
  exchange of ideas in AI research. This topic has received comparatively little attention
  of late compared to risks stemming from superintelligent artificial general intelligence
  (AGI), but requires fewer assumptions about the course of technological development
  and is thus a nearer-future issue. ML is already enabling the substitution of AWS
  for human soldiers in many battlefield roles, reducing the upfront human cost, and
  thus political cost, of waging offensive war. In the case of peer adversaries, this
  increases the likelihood of "low intensity" conflicts which risk escalation to broader
  warfare. In the case of non-peer adversaries, it reduces the domestic blowback to
  wars of aggression. This effect can occur regardless of other ethical issues around
  the use of military AI such as the risk of civilian casualties, and does not require
  any superhuman AI capabilities. Further, the military value of AWS raises the specter
  of an AI-powered arms race and the misguided imposition of national security restrictions
  on AI research. Our goal in this paper is to raise awareness among the public and
  ML researchers on the near-future risks posed by full or near-full autonomy in military
  technology, and we provide regulatory suggestions to mitigate these risks. We call
  upon AI policy experts and the defense AI community in particular to embrace transparency
  and caution in their development and deployment of AWS to avoid the negative effects
  on global stability and AI research that we highlight here.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: simmons-edler24a
month: 0
tex_title: 'Position: {AI}-Powered Autonomous Weapons Risk Geopolitical Instability
  and Threaten {AI} Research'
firstpage: 45508
lastpage: 45524
page: 45508-45524
order: 45508
cycles: false
bibtex_author: Simmons-Edler, Riley and Badman, Ryan Paul and Longpre, Shayne and
  Rajan, Kanaka
author:
- given: Riley
  family: Simmons-Edler
- given: Ryan Paul
  family: Badman
- given: Shayne
  family: Longpre
- given: Kanaka
  family: Rajan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/simmons-edler24a/simmons-edler24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Learning and Forgetting Unsafe Examples in Large Language Models
openreview: RYmmgedVjR
abstract: As the number of large language models (LLMs) released to the public grows,
  there is a pressing need to understand the safety implications associated with these
  models learning from third-party custom finetuning data. We explore the behavior
  of LLMs finetuned on noisy custom data containing unsafe content, represented by
  datasets that contain biases, toxicity, and harmfulness, finding that while aligned
  LLMs can readily learn this unsafe content, they also tend to forget it more significantly
  than other examples when subsequently finetuned on safer content. Drawing inspiration
  from the discrepancies in forgetting, we introduce the “ForgetFilter” algorithm,
  which filters unsafe data based on how strong the model’s forgetting signal is for
  that data. We demonstrate that the ForgetFilter algorithm ensures safety in customized
  finetuning without compromising downstream task performance, unlike sequential safety
  finetuning. ForgetFilter outperforms alternative strategies like replay and moral
  self-correction in curbing LLMs’ ability to assimilate unsafe content during custom
  finetuning, e.g. 75% lower than not applying any safety measures and 62% lower than
  using self-correction in toxicity score.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhao24e
month: 0
tex_title: Learning and Forgetting Unsafe Examples in Large Language Models
firstpage: 60766
lastpage: 60784
page: 60766-60784
order: 60766
cycles: false
bibtex_author: Zhao, Jiachen and Deng, Zhun and Madras, David and Zou, James and Ren,
  Mengye
author:
- given: Jiachen
  family: Zhao
- given: Zhun
  family: Deng
- given: David
  family: Madras
- given: James
  family: Zou
- given: Mengye
  family: Ren
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhao24e/zhao24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Statistical Test for Attention Maps in Vision Transformers
openreview: uLonuOfrwp
abstract: The Vision Transformer (ViT) demonstrates exceptional performance in various
  computer vision tasks. Attention is crucial for ViT to capture complex wide-ranging
  relationships among image patches, allowing the model to weigh the importance of
  image patches and aiding our understanding of the decision-making process. However,
  when utilizing the attention of ViT as evidence in high-stakes decision-making tasks
  such as medical diagnostics, a challenge arises due to the potential of attention
  mechanisms erroneously focusing on irrelevant regions. In this study, we propose
  a statistical test for ViT’s attentions, enabling us to use the attentions as reliable
  quantitative evidence indicators for ViT’s decision-making with a rigorously controlled
  error rate. Using the framework called selective inference, we quantify the statistical
  significance of attentions in the form of p-values, which enables the theoretically
  grounded quantification of the false positive detection probability of attentions.
  We demonstrate the validity and the effectiveness of the proposed method through
  numerical experiments and applications to brain image diagnoses.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: shiraishi24a
month: 0
tex_title: Statistical Test for Attention Maps in Vision Transformers
firstpage: 45079
lastpage: 45096
page: 45079-45096
order: 45079
cycles: false
bibtex_author: Shiraishi, Tomohiro and Miwa, Daiki and Katsuoka, Teruyuki and Duy,
  Vo Nguyen Le and Taji, Kouichi and Takeuchi, Ichiro
author:
- given: Tomohiro
  family: Shiraishi
- given: Daiki
  family: Miwa
- given: Teruyuki
  family: Katsuoka
- given: Vo Nguyen Le
  family: Duy
- given: Kouichi
  family: Taji
- given: Ichiro
  family: Takeuchi
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/shiraishi24a/shiraishi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

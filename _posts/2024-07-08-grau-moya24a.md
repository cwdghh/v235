---
title: Learning Universal Predictors
openreview: B1ajnQyZgK
abstract: Meta-learning has emerged as a powerful approach to train neural networks
  to learn new tasks quickly from limited data by pre-training them on a broad set
  of tasks. But, what are the limits of meta-learning? In this work, we explore the
  potential of amortizing the most powerful universal predictor, namely Solomonoff
  Induction (SI), into neural networks via leveraging (memory-based) meta-learning
  to its limits. We use Universal Turing Machines (UTMs) to generate training data
  used to expose networks to a broad range of patterns. We provide theoretical analysis
  of the UTM data generation processes and meta-training protocols. We conduct comprehensive
  experiments with neural architectures (e.g. LSTMs, Transformers) and algorithmic
  data generators of varying complexity and universality. Our results suggest that
  UTM data is a valuable resource for meta-learning, and that it can be used to train
  neural networks capable of learning universal prediction strategies.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: grau-moya24a
month: 0
tex_title: Learning Universal Predictors
firstpage: 16178
lastpage: 16205
page: 16178-16205
order: 16178
cycles: false
bibtex_author: Grau-Moya, Jordi and Genewein, Tim and Hutter, Marcus and Orseau, Laurent
  and Deletang, Gregoire and Catt, Elliot and Ruoss, Anian and Wenliang, Li Kevin
  and Mattern, Christopher and Aitchison, Matthew and Veness, Joel
author:
- given: Jordi
  family: Grau-Moya
- given: Tim
  family: Genewein
- given: Marcus
  family: Hutter
- given: Laurent
  family: Orseau
- given: Gregoire
  family: Deletang
- given: Elliot
  family: Catt
- given: Anian
  family: Ruoss
- given: Li Kevin
  family: Wenliang
- given: Christopher
  family: Mattern
- given: Matthew
  family: Aitchison
- given: Joel
  family: Veness
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/grau-moya24a/grau-moya24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

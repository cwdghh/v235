---
title: No Dimensional Sampling Coresets for Classification
openreview: jS3CMHtYJD
abstract: We refine and generalize what is known about coresets for classification
  problems via the sensitivity sampling framework. Such coresets seek the smallest
  possible subsets of input data, so one can optimize a loss function on the coreset
  and ensure approximation guarantees with respect to the original data. Our analysis
  provides the first no dimensional coresets, so the size does not depend on the dimension.
  Moreover, our results are general, apply for distributional input and can use iid
  samples, so provide sample complexity bounds, and work for a variety of loss functions.
  A key tool we develop is a Radamacher complexity version of the main sensitivity
  sampling approach, which can be of independent interest.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: alishahi24a
month: 0
tex_title: No Dimensional Sampling Coresets for Classification
firstpage: 1008
lastpage: 1049
page: 1008-1049
order: 1008
cycles: false
bibtex_author: Alishahi, Meysam and Phillips, Jeff M.
author:
- given: Meysam
  family: Alishahi
- given: Jeff M.
  family: Phillips
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/alishahi24a/alishahi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

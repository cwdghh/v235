---
title: Adaptive Advantage-Guided Policy Regularization for Offline Reinforcement Learning
openreview: FV3kY9FBW6
abstract: In offline reinforcement learning, the challenge of out-of-distribution
  (OOD) is pronounced. To address this, existing methods often constrain the learned
  policy through policy regularization. However, these methods often suffer from the
  issue of unnecessary conservativeness, hampering policy improvement. This occurs
  due to the indiscriminate use of all actions from the behavior policy that generates
  the offline dataset as constraints. The problem becomes particularly noticeable
  when the quality of the dataset is suboptimal. Thus, we propose Adaptive Advantage-guided
  Policy Regularization (A2PR), obtaining high-advantage actions from an augmented
  behavior policy combined with VAE to guide the learned policy. A2PR can select high-advantage
  actions that differ from those present in the dataset, while still effectively maintaining
  conservatism from OOD actions. This is achieved by harnessing the VAE capacity to
  generate samples matching the distribution of the data points. We theoretically
  prove that the improvement of the behavior policy is guaranteed. Besides, it effectively
  mitigates value overestimation with a bounded performance gap. Empirically, we conduct
  a series of experiments on the D4RL benchmark, where A2PR demonstrates state-of-the-art
  performance. Furthermore, experimental results on additional suboptimal mixed datasets
  reveal that A2PR exhibits superior performance. Code is available at https://github.com/ltlhuuu/A2PR.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24ai
month: 0
tex_title: Adaptive Advantage-Guided Policy Regularization for Offline Reinforcement
  Learning
firstpage: 31406
lastpage: 31424
page: 31406-31424
order: 31406
cycles: false
bibtex_author: Liu, Tenglong and Li, Yang and Lan, Yixing and Gao, Hao and Pan, Wei
  and Xu, Xin
author:
- given: Tenglong
  family: Liu
- given: Yang
  family: Li
- given: Yixing
  family: Lan
- given: Hao
  family: Gao
- given: Wei
  family: Pan
- given: Xin
  family: Xu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/liu24ai/liu24ai.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

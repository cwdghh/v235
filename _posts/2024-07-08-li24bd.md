---
title: Graph Neural Network Explanations are Fragile
openreview: qIOSNyPPwB
abstract: Explainable Graph Neural Network (GNN) has emerged recently to foster the
  trust of using GNNs. Existing GNN explainers are developed from various perspectives
  to enhance the explanation performance. We take the first step to study GNN explainers
  under adversarial attackâ€”We found that an adversary slightly perturbing graph structure
  can ensure GNN model makes correct predictions, but the GNN explainer yields a drastically
  different explanation on the perturbed graph. Specifically, we first formulate the
  attack problem under a practical threat model (i.e., the adversary has limited knowledge
  about the GNN explainer and a restricted perturbation budget). We then design two
  methods (i.e., one is loss-based and the other is deduction-based) to realize the
  attack. We evaluate our attacks on various GNN explainers and the results show these
  explainers are fragile.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24bd
month: 0
tex_title: Graph Neural Network Explanations are Fragile
firstpage: 28551
lastpage: 28567
page: 28551-28567
order: 28551
cycles: false
bibtex_author: Li, Jiate and Pang, Meng and Dong, Yun and Jia, Jinyuan and Wang, Binghui
author:
- given: Jiate
  family: Li
- given: Meng
  family: Pang
- given: Yun
  family: Dong
- given: Jinyuan
  family: Jia
- given: Binghui
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/li24bd/li24bd.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

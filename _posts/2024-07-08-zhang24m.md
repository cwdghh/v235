---
title: Look Ahead or Look Around? A Theoretical Comparison Between Autoregressive
  and Masked Pretraining
openreview: 2rPoTgEmjV
abstract: 'In recent years, the rise of generative self-supervised learning (SSL)
  paradigms has exhibited impressive performance across visual, language, and multi-modal
  domains. While the varied designs of generative SSL objectives lead to distinct
  properties in downstream tasks, a theoretical understanding of these differences
  remains largely unexplored. In this paper, we establish the first theoretical comparisons
  between two leading generative SSL paradigms: autoregressive SSL and masked SSL.
  Through establishing theoretical frameworks, we elucidate the strengths and limitations
  of autoregressive and masked SSL within the primary evaluation tasks of classification
  and content generation. Our findings demonstrate that in classification tasks, the
  flexibility of targeted tokens in masked SSL fosters more inter-sample connections
  compared to the fixed position of target tokens in autoregressive SSL, which yields
  superior clustering performance. In content generation tasks, the misalignment between
  the flexible lengths of test samples and the fixed length of unmasked texts in masked
  SSL (vs. flexible lengths of conditional texts in autoregressive SSL) hinders its
  generation performance. To leverage each otherâ€™s strengths and mitigate weaknesses,
  we propose diversity-enhanced autoregressive and variable-length masked objectives,
  which substantially improve the classification performance of autoregressive SSL
  and the generation performance of masked SSL. Code is available at https://github.com/PKU-ML/LookAheadLookAround.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24m
month: 0
tex_title: Look Ahead or Look Around? {A} Theoretical Comparison Between Autoregressive
  and Masked Pretraining
firstpage: 58819
lastpage: 58839
page: 58819-58839
order: 58819
cycles: false
bibtex_author: Zhang, Qi and Du, Tianqi and Huang, Haotian and Wang, Yifei and Wang,
  Yisen
author:
- given: Qi
  family: Zhang
- given: Tianqi
  family: Du
- given: Haotian
  family: Huang
- given: Yifei
  family: Wang
- given: Yisen
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhang24m/zhang24m.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

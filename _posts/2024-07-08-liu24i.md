---
title: Decentralized Convex Finite-Sum Optimization with Better Dependence on Condition
  Numbers
openreview: LLdeUPOUXk
abstract: This paper studies decentralized optimization problem, where the local objective
  on each node is an average of a finite set of convex functions and the global function
  is strongly convex. We propose an efficient stochastic variance reduced first-order
  method that allows the different nodes to establish their stochastic local gradient
  estimator with different mini-batch sizes per iteration. We prove the upper bound
  on the computation time of the proposed method contains the dependence on the global
  condition number, which is sharper than the previous results that only depend on
  the local condition numbers. Compared with the state-of-the-art methods, we also
  show that our method requires less local incremental first-order oracle calls and
  comparable communication cost. We further perform numerical experiments to validate
  the advantage of our method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24i
month: 0
tex_title: Decentralized Convex Finite-Sum Optimization with Better Dependence on
  Condition Numbers
firstpage: 30807
lastpage: 30841
page: 30807-30841
order: 30807
cycles: false
bibtex_author: Liu, Yuxing and Chen, Lesi and Luo, Luo
author:
- given: Yuxing
  family: Liu
- given: Lesi
  family: Chen
- given: Luo
  family: Luo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/liu24i/liu24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

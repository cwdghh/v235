---
title: 'Degeneration-free Policy Optimization: RL Fine-Tuning for Language Models
  without Degeneration'
openreview: lwTshcWlmB
abstract: As the pre-training objectives (e.g., next token prediction) of language
  models (LMs) are inherently not aligned with task scores, optimizing LMs to achieve
  higher downstream task scores is essential. One of the promising approaches is to
  fine-tune LMs through reinforcement learning (RL). However, conventional RL methods
  based on PPO and a penalty of KL divergence are vulnerable to text degeneration
  where LMs do not generate natural texts anymore after RL fine-tuning. To address
  this problem, we provide Degeneration-free Policy Optimization (DfPO) that can fine-tune
  LMs to generate texts that achieve improved downstream task scores, while preserving
  the ability to generate natural texts. To achieve this, we introduce KL-masking
  which masks out the actions that potentially cause deviation from the reference
  policy when its likelihood is increased or decreased. Then, we devise truncated
  advantage functions for separately performing likelihood maximization and minimization
  to improve the task performance. In the experiments, we provide the results of DfPO
  and baseline algorithms on various generative NLP tasks including text continuation,
  text detoxification, and commonsense generation. Our experiments demonstrate that
  DfPO successfully improves the downstream task scores while preserving the ability
  to generate natural texts, without requiring additional hyperparameter search.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: jang24b
month: 0
tex_title: 'Degeneration-free Policy Optimization: {RL} Fine-Tuning for Language Models
  without Degeneration'
firstpage: 21266
lastpage: 21288
page: 21266-21288
order: 21266
cycles: false
bibtex_author: Jang, Youngsoo and Kim, Geon-Hyeong and Kim, Byoungjip and Kim, Yu
  Jin and Lee, Honglak and Lee, Moontae
author:
- given: Youngsoo
  family: Jang
- given: Geon-Hyeong
  family: Kim
- given: Byoungjip
  family: Kim
- given: Yu Jin
  family: Kim
- given: Honglak
  family: Lee
- given: Moontae
  family: Lee
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/jang24b/jang24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

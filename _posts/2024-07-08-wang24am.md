---
title: Graph As Point Set
openreview: b6yHkQpSwZ
abstract: Graph is a fundamental data structure to model interconnections between
  entities. Set, on the contrary, stores independent elements. To learn graph representations,
  current Graph Neural Networks (GNNs) primarily use message passing to encode the
  interconnections. In contrast, this paper introduces a novel graph-to-set conversion
  method that bijectively transforms interconnected nodes into a set of independent
  points and then uses a set encoder to learn the graph representation. This conversion
  method holds dual significance. Firstly, it enables using set encoders to learn
  from graphs, thereby significantly expanding the design space of GNNs. Secondly,
  for Transformer, a specific set encoder, we provide a novel and principled approach
  to inject graph information losslessly, different from all the heuristic structural/positional
  encoding methods adopted in previous graph transformers. To demonstrate the effectiveness
  of our approach, we introduce Point Set Transformer (PST), a transformer architecture
  that accepts a point set converted from a graph as input. Theoretically, PST exhibits
  superior expressivity for both short-range substructure counting and long-range
  shortest path distance tasks compared to existing GNNs. Extensive experiments further
  validate PSTâ€™s outstanding real-world performance. Besides Transformer, we also
  devise a Deepset-based set encoder, which achieves performance comparable to representative
  GNNs, affirming the versatility of our graph-to-set method.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24am
month: 0
tex_title: Graph As Point Set
firstpage: 50874
lastpage: 50901
page: 50874-50901
order: 50874
cycles: false
bibtex_author: Wang, Xiyuan and Li, Pan and Zhang, Muhan
author:
- given: Xiyuan
  family: Wang
- given: Pan
  family: Li
- given: Muhan
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wang24am/wang24am.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

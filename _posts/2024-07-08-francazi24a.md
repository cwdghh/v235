---
title: 'Initial Guessing Bias: How Untrained Networks Favor Some Classes'
openreview: UZstTlLq1E
abstract: Understanding and controlling biasing effects in neural networks is crucial
  for ensuring accurate and fair model performance. In the context of classification
  problems, we provide a theoretical analysis demonstrating that the structure of
  a deep neural network (DNN) can condition the model to assign all predictions to
  the same class, even before the beginning of training, and in the absence of explicit
  biases. We prove that, besides dataset properties, the presence of this phenomenon,
  which we call <em>Initial Guessing Bias</em> (IGB), is influenced by model choices
  including dataset preprocessing methods, and architectural decisions, such as activation
  functions, max-pooling layers, and network depth. Our analysis of IGB provides information
  for architecture selection and model initialization. We also highlight theoretical
  consequences, such as the breakdown of node-permutation symmetry, the violation
  of self-averaging and the non-trivial effects that depth has on the phenomenon.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: francazi24a
month: 0
tex_title: 'Initial Guessing Bias: How Untrained Networks Favor Some Classes'
firstpage: 13783
lastpage: 13839
page: 13783-13839
order: 13783
cycles: false
bibtex_author: Francazi, Emanuele and Lucchi, Aurelien and Baity-Jesi, Marco
author:
- given: Emanuele
  family: Francazi
- given: Aurelien
  family: Lucchi
- given: Marco
  family: Baity-Jesi
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/francazi24a/francazi24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: When Do Skills Help Reinforcement Learning? A Theoretical Analysis of Temporal
  Abstractions
openreview: 39UqOkTjFn
abstract: Skills are temporal abstractions that are intended to improve reinforcement
  learning (RL) performance through hierarchical RL. Despite our intuition about the
  properties of an environment that make skills useful, a precise characterization
  has been absent. We provide the first such characterization, focusing on the utility
  of deterministic skills in deterministic sparse-reward environments with finite
  action spaces. We show theoretically and empirically that RL performance gain from
  skills is worse in environments where solutions to states are less compressible.
  Additional theoretical results suggest that skills benefit exploration more than
  they benefit learning from existing experience, and that using unexpressive skills
  such as macroactions may worsen RL performance. We hope our findings can guide research
  on automatic skill discovery and help RL practitioners better decide when and how
  to use skills.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24be
month: 0
tex_title: When Do Skills Help Reinforcement Learning? {A} Theoretical Analysis of
  Temporal Abstractions
firstpage: 28568
lastpage: 28596
page: 28568-28596
order: 28568
cycles: false
bibtex_author: Li, Zhening and Poesia, Gabriel and Solar-Lezama, Armando
author:
- given: Zhening
  family: Li
- given: Gabriel
  family: Poesia
- given: Armando
  family: Solar-Lezama
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24be/li24be.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

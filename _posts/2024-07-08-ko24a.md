---
title: What Would Gauss Say About Representations? Probing Pretrained Image Models
  using Synthetic Gaussian Benchmarks
openreview: MmZJ3kJXjX
abstract: Recent years have witnessed a paradigm shift in deep learning from task-centric
  model design to task-agnostic representation learning and task-specific fine-tuning.
  Pretrained model representations are commonly evaluated extensively across various
  real-world tasks and used as a foundation for different downstream tasks. This paper
  proposes a solution for assessing the quality of representations in a task-agnostic
  way. To circumvent the need for real-world data in evaluation, we explore the use
  of synthetic binary classification tasks with Gaussian mixtures to probe pretrained
  models and compare the robustness-accuracy performance on pretrained representations
  with an idealized reference. Our approach offers a holistic evaluation, revealing
  intrinsic model capabilities and reducing the dependency on real-life data for model
  evaluation. Evaluated with various pretrained image models, the experimental results
  confirm that our task-agnostic evaluation correlates with actual linear probing
  performance on downstream tasks and can also guide parameter choice in robust linear
  probing to achieve a better robustness-accuracy trade-off.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ko24a
month: 0
tex_title: What Would {G}auss Say About Representations? {P}robing Pretrained Image
  Models using Synthetic {G}aussian Benchmarks
firstpage: 24829
lastpage: 24858
page: 24829-24858
order: 24829
cycles: false
bibtex_author: Ko, Ching-Yun and Chen, Pin-Yu and Das, Payel and Mohapatra, Jeet and
  Daniel, Luca
author:
- given: Ching-Yun
  family: Ko
- given: Pin-Yu
  family: Chen
- given: Payel
  family: Das
- given: Jeet
  family: Mohapatra
- given: Luca
  family: Daniel
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/ko24a/ko24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

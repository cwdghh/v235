---
title: Do Models Explain Themselves? Counterfactual Simulatability of Natural Language
  Explanations
openreview: 99jx5U81jx
abstract: 'Large language models (LLMs) are trained to imitate humans to explain human
  decisions. However, do LLMs explain themselves? Can they help humans build mental
  models of how LLMs process different inputs? To answer these questions, we propose
  to evaluate $\textbf{counterfactual simulatability}$ of natural language explanations:
  whether an explanation can enable humans to precisely infer the model’s outputs
  on diverse counterfactuals of the explained input. For example, if a model answers
  ”$\textit{yes}$” to the input question ”$\textit{Can eagles fly?}$” with the explanation
  ”$\textit{all birds can fly}$”, then humans would infer from the explanation that
  it would also answer ”$\textit{yes}$” to the counterfactual input ”$\textit{Can
  penguins fly?}$”. If the explanation is precise, then the model’s answer should
  match humans’ expectations. We implemented two metrics based on counterfactual simulatability:
  precision and generality. We generated diverse counterfactuals automatically using
  LLMs. We then used these metrics to evaluate state-of-the-art LLMs (e.g., GPT-4)
  on two tasks: multi-hop factual reasoning and reward modeling. We found that LLM’s
  explanations have low precision and that precision does not correlate with plausibility.
  Therefore, naively optimizing human approvals (e.g., RLHF) may be insufficient.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24bl
month: 0
tex_title: Do Models Explain Themselves? {C}ounterfactual Simulatability of Natural
  Language Explanations
firstpage: 7880
lastpage: 7904
page: 7880-7904
order: 7880
cycles: false
bibtex_author: Chen, Yanda and Zhong, Ruiqi and Ri, Narutatsu and Zhao, Chen and He,
  He and Steinhardt, Jacob and Yu, Zhou and Mckeown, Kathleen
author:
- given: Yanda
  family: Chen
- given: Ruiqi
  family: Zhong
- given: Narutatsu
  family: Ri
- given: Chen
  family: Zhao
- given: He
  family: He
- given: Jacob
  family: Steinhardt
- given: Zhou
  family: Yu
- given: Kathleen
  family: Mckeown
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/chen24bl/chen24bl.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Neighboring Perturbations of Knowledge Editing on Large Language Models
openreview: K9NTPRvVRI
abstract: Despite their exceptional capabilities, large language models (LLMs) are
  prone to generating unintended text due to false or outdated knowledge. Given the
  resource-intensive nature of retraining LLMs, there has been a notable increase
  in the development of knowledge editing. However, current approaches and evaluations
  rarely explore the perturbation of editing on neighboring knowledge. This paper
  studies whether updating new knowledge to LLMs perturbs the neighboring knowledge
  encapsulated within them. Specifically, we seek to figure out whether appending
  a new answer into an answer list to a factual question leads to catastrophic forgetting
  of original correct answers in this list, as well as unintentional inclusion of
  incorrect answers. A metric of additivity is introduced and a benchmark dubbed as
  Perturbation Evaluation of Appending Knowledge (PEAK) is constructed to evaluate
  the degree of perturbation to neighboring knowledge when appending new knowledge.
  Besides, a plug-and-play framework termed Appending via Preservation and Prevention
  (APP) is proposed to mitigate the neighboring perturbation by maintaining the integrity
  of the answer list. Experiments demonstrate the effectiveness of APP coupling with
  four editing methods on three LLMs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ma24h
month: 0
tex_title: Neighboring Perturbations of Knowledge Editing on Large Language Models
firstpage: 33839
lastpage: 33854
page: 33839-33854
order: 33839
cycles: false
bibtex_author: Ma, Jun-Yu and Ling, Zhen-Hua and Zhang, Ningyu and Gu, Jia-Chen
author:
- given: Jun-Yu
  family: Ma
- given: Zhen-Hua
  family: Ling
- given: Ningyu
  family: Zhang
- given: Jia-Chen
  family: Gu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/ma24h/ma24h.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

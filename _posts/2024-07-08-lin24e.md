---
title: Can We Remove the Square-Root in Adaptive Gradient Methods? A Second-Order
  Perspective
openreview: vuMD71R20q
abstract: Adaptive gradient optimizers like Adam(W) are the default training algorithms
  for many deep learning architectures, such as transformers. Their diagonal preconditioner
  is based on the gradient outer product which is incorporated into the parameter
  update via a square root. While these methods are often motivated as approximate
  second-order methods, the square root represents a fundamental difference. In this
  work, we investigate how the behavior of adaptive methods changes when we remove
  the root, i.e. strengthen their second-order motivation. Surprisingly, we find that
  such square-root-free adaptive methods close the generalization gap to SGD on convolutional
  architectures, while maintaining their root-based counterpartâ€™s performance on transformers.
  The second-order perspective also has practical benefits for the development of
  non-diagonal adaptive methods through the concept of preconditioner invariance.
  In contrast to root-based methods like Shampoo, the root-free counterparts do not
  require numerically unstable matrix root decompositions and inversions, thus work
  well in half precision. Our findings provide new insights into the development of
  adaptive methods and raise important questions regarding the currently overlooked
  role of adaptivity for their success.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin24e
month: 0
tex_title: Can We Remove the Square-Root in Adaptive Gradient Methods? {A} Second-Order
  Perspective
firstpage: 29949
lastpage: 29973
page: 29949-29973
order: 29949
cycles: false
bibtex_author: Lin, Wu and Dangel, Felix and Eschenhagen, Runa and Bae, Juhan and
  Turner, Richard E. and Makhzani, Alireza
author:
- given: Wu
  family: Lin
- given: Felix
  family: Dangel
- given: Runa
  family: Eschenhagen
- given: Juhan
  family: Bae
- given: Richard E.
  family: Turner
- given: Alireza
  family: Makhzani
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/lin24e/lin24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

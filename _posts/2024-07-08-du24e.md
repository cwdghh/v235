---
title: Improving Factuality and Reasoning in Language Models through Multiagent Debate
openreview: zj7YuTE4t8
abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
  language generation, understanding, and few-shot learning in recent years. An extensive
  body of work has explored how their performance may be further improved through
  the tools of prompting, ranging from verification, self-consistency, or intermediate
  scratchpads. In this paper, we present a complementary approach to improve language
  responses where multiple language model instances propose and debate their individual
  responses and reasoning processes over multiple rounds to arrive at a common final
  answer. Our findings indicate that this approach significantly enhances mathematical
  and strategic reasoning across a number of tasks. We also demonstrate that our approach
  improves the factual validity of generated content, reducing fallacious answers
  and hallucinations that contemporary models are prone to. Our approach may be directly
  applied to existing black-box models and uses identical procedure and prompts for
  all tasks we investigate. Overall, our findings suggest that such "society of minds"
  approach has the potential to significantly advance the capabilities of LLMs and
  pave the way for further breakthroughs in language generation and understanding.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: du24e
month: 0
tex_title: Improving Factuality and Reasoning in Language Models through Multiagent
  Debate
firstpage: 11733
lastpage: 11763
page: 11733-11763
order: 11733
cycles: false
bibtex_author: Du, Yilun and Li, Shuang and Torralba, Antonio and Tenenbaum, Joshua
  B. and Mordatch, Igor
author:
- given: Yilun
  family: Du
- given: Shuang
  family: Li
- given: Antonio
  family: Torralba
- given: Joshua B.
  family: Tenenbaum
- given: Igor
  family: Mordatch
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/du24e/du24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Position: Automatic Environment Shaping is the Next Frontier in RL'
openreview: dslUyy1rN4
abstract: Many roboticists dream of presenting a robot with a task in the evening
  and returning the next morning to find the robot capable of solving the task. What
  is preventing us from achieving this? Sim-to-real reinforcement learning (RL) has
  achieved impressive performance on challenging robotics tasks, but requires substantial
  human effort to set up the task in a way that is amenable to RL. It’s our position
  that algorithmic improvements in policy optimization and other ideas should be guided
  towards resolving the primary bottleneck of shaping the training environment, i.e.,
  designing observations, actions, rewards and simulation dynamics. Most practitioners
  don’t tune the RL algorithm, but other environment parameters to obtain a desirable
  controller. We posit that scaling RL to diverse robotic tasks will only be achieved
  if the community focuses on automating environment shaping procedures.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: park24i
month: 0
tex_title: 'Position: Automatic Environment Shaping is the Next Frontier in {RL}'
firstpage: 39781
lastpage: 39792
page: 39781-39792
order: 39781
cycles: false
bibtex_author: Park, Younghyo and Margolis, Gabriel B. and Agrawal, Pulkit
author:
- given: Younghyo
  family: Park
- given: Gabriel B.
  family: Margolis
- given: Pulkit
  family: Agrawal
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/park24i/park24i.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

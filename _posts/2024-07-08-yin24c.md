---
title: Characterizing Truthfulness in Large Language Model Generations with Local
  Intrinsic Dimension
openreview: 7DbIyQlfaO
abstract: We study how to characterize and predict the truthfulness of texts generated
  from large language models (LLMs), which serves as a crucial step in building trust
  between humans and LLMs. Although several approaches based on entropy or verbalized
  uncertainty have been proposed to calibrate model predictions, these methods are
  often intractable, sensitive to hyperparameters, and less reliable when applied
  in generative tasks with LLMs. In this paper, we suggest investigating internal
  activations and quantifying LLMâ€™s truthfulness using the local intrinsic dimension
  (LID) of model activations. Through experiments on four question answering (QA)
  datasets, we demonstrate the effectiveness of our proposed method. Additionally,
  we study intrinsic dimensions in LLMs and their relations with model layers, autoregressive
  language modeling, and the training of LLMs, revealing that intrinsic dimensions
  can be a powerful approach to understanding LLMs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yin24c
month: 0
tex_title: Characterizing Truthfulness in Large Language Model Generations with Local
  Intrinsic Dimension
firstpage: 57069
lastpage: 57084
page: 57069-57084
order: 57069
cycles: false
bibtex_author: Yin, Fan and Srinivasa, Jayanth and Chang, Kai-Wei
author:
- given: Fan
  family: Yin
- given: Jayanth
  family: Srinivasa
- given: Kai-Wei
  family: Chang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/yin24c/yin24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

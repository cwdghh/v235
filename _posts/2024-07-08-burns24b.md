---
title: 'Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision'
openreview: ghNRg2mEgN
abstract: 'Widely used alignment techniques, such as reinforcement learning from human
  feedback (RLHF), rely on the ability of humans to supervise model behaviorâ€”for example,
  to evaluate whether a model faithfully followed instructions or generated safe outputs.
  However, future superhuman models will behave in complex ways too difficult for
  humans to reliably evaluate; humans will only be able to <em>weakly supervise</em>
  superhuman models. We study an analogy to this problem: can weak model supervision
  elicit the full capabilities of a much stronger model? We test this using a range
  of pretrained language models in the GPT-4 family on natural language processing
  (NLP), chess, and reward modeling tasks. We find that when we naively finetune strong
  pretrained models on labels generated by a weak model, they consistently perform
  better than their weak supervisors, a phenomenon we call <em>weak-to-strong generalization</em>.
  However, we are still far from recovering the full capabilities of strong models
  with naive finetuning alone, suggesting that techniques like RLHF may scale poorly
  to superhuman models without further work. We find that simple methods can often
  significantly improve weak-to-strong generalization: for example, when finetuning
  GPT-4 with a GPT-2-level supervisor and an auxiliary confidence loss, we can recover
  close to GPT-3.5-level performance on NLP tasks. Our results suggest that it is
  feasible to make empirical progress today on a fundamental challenge of aligning
  superhuman models.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: burns24b
month: 0
tex_title: 'Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak
  Supervision'
firstpage: 4971
lastpage: 5012
page: 4971-5012
order: 4971
cycles: false
bibtex_author: Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker,
  Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien
  and Joglekar, Manas and Leike, Jan and Sutskever, Ilya and Wu, Jeffrey
author:
- given: Collin
  family: Burns
- given: Pavel
  family: Izmailov
- given: Jan Hendrik
  family: Kirchner
- given: Bowen
  family: Baker
- given: Leo
  family: Gao
- given: Leopold
  family: Aschenbrenner
- given: Yining
  family: Chen
- given: Adrien
  family: Ecoffet
- given: Manas
  family: Joglekar
- given: Jan
  family: Leike
- given: Ilya
  family: Sutskever
- given: Jeffrey
  family: Wu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/burns24b/burns24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

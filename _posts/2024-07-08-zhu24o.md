---
title: Language Models Represent Beliefs of Self and Others
openreview: asJTE8EBjg
abstract: Understanding and attributing mental states, known as Theory of Mind (ToM),
  emerges as a fundamental capability for human social reasoning. While Large Language
  Models (LLMs) appear to possess certain ToM abilities, the mechanisms underlying
  these capabilities remain elusive. In this study, we discover that it is possible
  to linearly decode the belief status from the perspectives of various agents through
  neural activations of language models, indicating the existence of internal representations
  of self and others’ beliefs. By manipulating these representations, we observe dramatic
  changes in the models’ ToM performance, underscoring their pivotal role in the social
  reasoning process. Additionally, our findings extend to diverse social reasoning
  tasks that involve different causal inference patterns, suggesting the potential
  generalizability of these representations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhu24o
month: 0
tex_title: Language Models Represent Beliefs of Self and Others
firstpage: 62638
lastpage: 62681
page: 62638-62681
order: 62638
cycles: false
bibtex_author: Zhu, Wentao and Zhang, Zhining and Wang, Yizhou
author:
- given: Wentao
  family: Zhu
- given: Zhining
  family: Zhang
- given: Yizhou
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhu24o/zhu24o.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

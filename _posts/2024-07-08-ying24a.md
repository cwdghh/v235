---
title: 'MMT-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large Vision-Language
  Models Towards Multitask AGI'
openreview: R4Ng8zYaiz
abstract: Large Vision-Language Models (LVLMs) show significant strides in general-propose
  multimodal applications such as visual dialogue and embodied navigation. However,
  existing multimodal evaluation benchmarks cover a limited number of multimodal tasks
  testing rudimentary capabilities, falling short in tracking LVLM development. In
  this study, we present MMT-Bench, a comprehensive benchmark designed to assess LVLMs
  across massive multimodal tasks requiring expert knowledge and deliberate visual
  recognition, localization, and reasoning. MMT-Bench comprises $31,325$ meticulously
  curated multi-choice visual questions from various multimodal scenarios such as
  vehicle driving and embodied navigation, covering $32$ core meta-tasks and $162$
  subtasks in multimodal understanding. Due to its extensive task coverage, MMT-Bench
  enables the evaluation of LVLMs using a task map, facilitating the discovery of
  in- and out-of-domain tasks. Evaluation results involving $20$ publicly available
  LVLMs such as the proprietary GeminiProVision model, underscore the significant
  challenges posed by MMT-Bench. We anticipate that MMT-Bench will inspire the community
  to develop next-generation multimodal foundation models aimed at achieving general-purpose
  multimodal intelligence.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: ying24a
month: 0
tex_title: "{MMT}-Bench: A Comprehensive Multimodal Benchmark for Evaluating Large
  Vision-Language Models Towards Multitask {AGI}"
firstpage: 57116
lastpage: 57198
page: 57116-57198
order: 57116
cycles: false
bibtex_author: Ying, Kaining and Meng, Fanqing and Wang, Jin and Li, Zhiqian and Lin,
  Han and Yang, Yue and Zhang, Hao and Zhang, Wenbo and Lin, Yuqi and Liu, Shuo and
  Lei, Jiayi and Lu, Quanfeng and Chen, Runjian and Xu, Peng and Zhang, Renrui and
  Zhang, Haozhe and Gao, Peng and Wang, Yali and Qiao, Yu and Luo, Ping and Zhang,
  Kaipeng and Shao, Wenqi
author:
- given: Kaining
  family: Ying
- given: Fanqing
  family: Meng
- given: Jin
  family: Wang
- given: Zhiqian
  family: Li
- given: Han
  family: Lin
- given: Yue
  family: Yang
- given: Hao
  family: Zhang
- given: Wenbo
  family: Zhang
- given: Yuqi
  family: Lin
- given: Shuo
  family: Liu
- given: Jiayi
  family: Lei
- given: Quanfeng
  family: Lu
- given: Runjian
  family: Chen
- given: Peng
  family: Xu
- given: Renrui
  family: Zhang
- given: Haozhe
  family: Zhang
- given: Peng
  family: Gao
- given: Yali
  family: Wang
- given: Yu
  family: Qiao
- given: Ping
  family: Luo
- given: Kaipeng
  family: Zhang
- given: Wenqi
  family: Shao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/ying24a/ying24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

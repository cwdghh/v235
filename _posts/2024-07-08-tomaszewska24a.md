---
title: 'Position: Do Not Explain Vision Models Without Context'
openreview: 6UGSDDPkJw
abstract: Does the stethoscope in the picture make the adjacent person a doctor or
  a patient? This, of course, depends on the contextual relationship of the two objects.
  If it’s obvious, why don’t explanation methods for vision models use contextual
  information? In this paper, we (1) review the most popular methods of explaining
  computer vision models by pointing out that they do not take into account context
  information, (2) show examples of failures of popular XAI methods, (3) provide examples
  of real-world use cases where spatial context plays a significant role, (4) propose
  new research directions that may lead to better use of context information in explaining
  computer vision models, (5) argue that a change in approach to explanations is needed
  from <em>where</em> to <em>how</em>.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: tomaszewska24a
month: 0
tex_title: 'Position: Do Not Explain Vision Models Without Context'
firstpage: 48390
lastpage: 48403
page: 48390-48403
order: 48390
cycles: false
bibtex_author: Tomaszewska, Paulina and Biecek, Przemyslaw
author:
- given: Paulina
  family: Tomaszewska
- given: Przemyslaw
  family: Biecek
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/tomaszewska24a/tomaszewska24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

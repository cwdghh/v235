---
title: 'Provable Benefits of Local Steps in Heterogeneous Federated Learning for Neural
  Networks: A Feature Learning Perspective'
openreview: yHRxnhKyEJ
abstract: Local steps are crucial for Federated Learning (FL) algorithms and have
  witnessed great empirical success in reducing communication costs and improving
  the generalization performance of deep neural networks. However, there are limited
  studies on the effect of local steps on heterogeneous FL. A few works investigate
  this problem from the optimization perspective. Woodworth et al. (2020a) showed
  that the iteration complexity of Local SGD, the most popular FL algorithm, is dominated
  by the baseline mini-batch SGD, which does not show the benefits of local steps.
  In addition, Levy (2023) proposed a new local update method that provably benefits
  over mini-batch SGD. However, in the same setting, there is still no work analyzing
  the effects of local steps to generalization in a heterogeneous FL setting. Motivated
  by our experimental findings where Local SGD learns more distinguishing features
  than parallel SGD, this paper studies the generalization benefits of local steps
  from a feature learning perspective. We propose a novel federated data model that
  exhibits a new form of data heterogeneity, under which we show that a convolutional
  neural network (CNN) trained by GD with <em>global</em> updates will miss some pattern-related
  features, while the network trained by GD with <em>local</em> updates can learn
  all features in polynomial time. Consequently, local steps help CNN generalize better
  in our data model. In a different parameter setting, we also prove that Local GD
  with <em>one-shot</em> model averaging can learn all features and generalize well
  in all clients. Our experimental results also confirm the benefits of local steps
  in improving test accuracy on real-world data.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: bao24a
month: 0
tex_title: 'Provable Benefits of Local Steps in Heterogeneous Federated Learning for
  Neural Networks: A Feature Learning Perspective'
firstpage: 2857
lastpage: 2902
page: 2857-2902
order: 2857
cycles: false
bibtex_author: Bao, Yajie and Crawshaw, Michael and Liu, Mingrui
author:
- given: Yajie
  family: Bao
- given: Michael
  family: Crawshaw
- given: Mingrui
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/bao24a/bao24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Disentangled Continual Graph Neural Architecture Search with Invariant Modular
  Supernet
openreview: Hg7C5YYifi
abstract: The existing graph neural architecture search (GNAS) methods assume that
  the graph tasks are static during the search process, ignoring the ubiquitous scenarios
  where sequential graph tasks come in a continual fashion. Moreover, existing GNAS
  works resort to entangled graph factors during the architecture search process,
  resulting in the catastrophic forgetting problems. In this paper, we study the problem
  of continual graph neural architecture search that is expected to continually search
  the architecture to learn new graph tasks without forgetting the past, which remains
  largely unexplored in the literature. However, this problem poses the challenge
  of architecture conflicts, i.e., the optimal architecture for the new graph task
  may have performance deterioration and thus sub-optimal for past tasks. To address
  the challenge, we propose a novel Disentangled Continual Graph Neural Architecture
  Search with Invariant Modularization (GASIM) method, which is able to continually
  search the optimal architectures without forgetting past knowledge. Specifically,
  we first design a modular graph architecture super-network incorporating multiple
  modules to enable searching architecture with factor expertise. Second, we propose
  a factor-based task-module router that discovers the latent graph factors and routes
  the incoming task to the best suitable architecture module to alleviate the forgetting
  problem induced by architecture conflicts. Finally, we propose an invariant architecture
  search mechanism to capture the shared knowledge among tasks. Extensive experiments
  on real-world datasets demonstrate that the proposed method achieves state-of-the-art
  performance against baselines in continual graph neural architecture search.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24bm
month: 0
tex_title: Disentangled Continual Graph Neural Architecture Search with Invariant
  Modular Supernet
firstpage: 59975
lastpage: 59991
page: 59975-59991
order: 59975
cycles: false
bibtex_author: Zhang, Zeyang and Wang, Xin and Qin, Yijian and Chen, Hong and Zhang,
  Ziwei and Chu, Xu and Zhu, Wenwu
author:
- given: Zeyang
  family: Zhang
- given: Xin
  family: Wang
- given: Yijian
  family: Qin
- given: Hong
  family: Chen
- given: Ziwei
  family: Zhang
- given: Xu
  family: Chu
- given: Wenwu
  family: Zhu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/zhang24bm/zhang24bm.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Do Large Language Models Perform the Way People Expect? Measuring the Human
  Generalization Function
openreview: JIWtKcR78C
abstract: 'What makes large language models (LLMs) impressive is also what makes them
  hard to evaluate: their diversity of uses. To evaluate these models, we must understand
  the purposes they will be used for. We consider a setting where these deployment
  decisions are made by people, and in particular, people’s beliefs about where an
  LLM will perform well. We model such beliefs as the consequence of a human generalization
  function: having seen what an LLM gets right or wrong, people generalize to where
  else it might succeed. We collect a dataset of 19K examples of how humans make generalizations
  across 79 tasks from the MMLU and BIG-Bench benchmarks. We show that the human generalization
  function can be predicted using NLP methods: people have consistent structured ways
  to generalize. We then evaluate LLM alignment with the human generalization function.
  Our results show that – especially for cases where the cost of mistakes is high
  – more capable models (e.g. GPT-4) can do worse on the instances people choose to
  use them for, exactly because they are not aligned with the human generalization
  function.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: vafa24a
month: 0
tex_title: Do Large Language Models Perform the Way People Expect? {M}easuring the
  Human Generalization Function
firstpage: 48919
lastpage: 48937
page: 48919-48937
order: 48919
cycles: false
bibtex_author: Vafa, Keyon and Rambachan, Ashesh and Mullainathan, Sendhil
author:
- given: Keyon
  family: Vafa
- given: Ashesh
  family: Rambachan
- given: Sendhil
  family: Mullainathan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/vafa24a/vafa24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

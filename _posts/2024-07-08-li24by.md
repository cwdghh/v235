---
title: 'Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice via
  HyperAgent'
openreview: OF7e0w1uon
abstract: We propose HyperAgent, a reinforcement learning (RL) algorithm based on
  the hypermodel framework for exploration in RL. HyperAgent allows for the efficient
  incremental approximation of posteriors associated with an optimal action-value
  function ($Q^\star$) without the need for conjugacy and follows the greedy policies
  w.r.t. these approximate posterior samples. We demonstrate that HyperAgent offers
  robust performance in large-scale deep RL benchmarks. It can solve Deep Sea hard
  exploration problems with episodes that optimally scale with problem size and exhibits
  significant efficiency gains in the Atari suite. Implementing HyperAgent requires
  minimal code addition to well-established deep RL frameworks like DQN. We theoretically
  prove that, under tabular assumptions, HyperAgent achieves logarithmic per-step
  computational complexity while attaining sublinear regret, matching the best known
  randomized tabular RL algorithm.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24by
month: 0
tex_title: 'Q-Star Meets Scalable Posterior Sampling: Bridging Theory and Practice
  via {H}yper{A}gent'
firstpage: 29022
lastpage: 29062
page: 29022-29062
order: 29022
cycles: false
bibtex_author: Li, Yingru and Xu, Jiawei and Han, Lei and Luo, Zhi-Quan
author:
- given: Yingru
  family: Li
- given: Jiawei
  family: Xu
- given: Lei
  family: Han
- given: Zhi-Quan
  family: Luo
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/li24by/li24by.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

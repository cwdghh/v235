---
title: Collaborative Learning with Different Labeling Functions
openreview: UKHfmzLR7P
abstract: We study a variant of Collaborative PAC Learning, in which we aim to learn
  an accurate classifier for each of the $n$ data distributions, while minimizing
  the number of samples drawn from them in total. Unlike in the usual collaborative
  learning setup, it is not assumed that there exists a single classifier that is
  simultaneously accurate for all distributions. We show that, when the data distributions
  satisfy a weaker realizability assumption, which appeared in (Crammer & Mansour,
  2012) in the context of multi-task learning, sample-efficient learning is still
  feasible. We give a learning algorithm based on Empirical Risk Minimization (ERM)
  on a natural augmentation of the hypothesis class, and the analysis relies on an
  upper bound on the VC dimension of this augmented class. In terms of the computational
  efficiency, we show that ERM on the augmented hypothesis class is $\mathsf{NP}$-hard,
  which gives evidence against the existence of computationally efficient learners
  in general. On the positive side, for two special cases, we give learners that are
  both sample- and computationally-efficient.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: deng24d
month: 0
tex_title: Collaborative Learning with Different Labeling Functions
firstpage: 10530
lastpage: 10552
page: 10530-10552
order: 10530
cycles: false
bibtex_author: Deng, Yuyang and Qiao, Mingda
author:
- given: Yuyang
  family: Deng
- given: Mingda
  family: Qiao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/deng24d/deng24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

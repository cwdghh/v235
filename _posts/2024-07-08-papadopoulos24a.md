---
title: Arrows of Time for Large Language Models
openreview: UpSe7ag34v
abstract: 'We study the probabilistic modeling performed by Autoregressive Large Language
  Models (LLMs) through the angle of time directionality, addressing a question first
  raised in (Shannon, 1951). For large enough models, we empirically find a time asymmetry
  in their ability to learn natural language: a difference in the average log-perplexity
  when trying to predict the next token versus when trying to predict the previous
  one. This difference is at the same time subtle and very consistent across various
  modalities (language, model size, training time, ...). Theoretically, this is surprising:
  from an information-theoretic point of view, there should be no such difference.
  We provide a theoretical framework to explain how such an asymmetry can appear from
  sparsity and computational complexity considerations, and outline a number of perspectives
  opened by our results.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: papadopoulos24a
month: 0
tex_title: Arrows of Time for Large Language Models
firstpage: 39509
lastpage: 39528
page: 39509-39528
order: 39509
cycles: false
bibtex_author: Papadopoulos, Vassilis and Wenger, J\'{e}r\'{e}mie and Hongler, Cl\'{e}ment
author:
- given: Vassilis
  family: Papadopoulos
- given: Jérémie
  family: Wenger
- given: Clément
  family: Hongler
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/papadopoulos24a/papadopoulos24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

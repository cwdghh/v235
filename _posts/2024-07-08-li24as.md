---
title: Preventing Model Collapse in Gaussian Process Latent Variable Models
openreview: 4byOXWrJay
abstract: Gaussian process latent variable models (GPLVMs) are a versatile family
  of unsupervised learning models commonly used for dimensionality reduction. However,
  common challenges in modeling data with GPLVMs include inadequate kernel flexibility
  and improper selection of the projection noise, leading to a type of model collapse
  characterized by vague latent representations that do not reflect the underlying
  data structure. This paper addresses these issues by, first, theoretically examining
  the impact of projection variance on model collapse through the lens of a linear
  GPLVM. Second, we tackle model collapse due to inadequate kernel flexibility by
  integrating the spectral mixture (SM) kernel and a differentiable random Fourier
  feature (RFF) kernel approximation, which ensures computational scalability and
  efficiency through off-the-shelf automatic differentiation tools for learning the
  kernel hyperparameters, projection variance, and latent representations within the
  variational inference framework. The proposed GPLVM, named <em>advised</em>RFLVM,
  is evaluated across diverse datasets and consistently outperforms various salient
  competing models, including state-of-the-art variational autoencoders (VAEs) and
  other GPLVM variants, in terms of informative latent representations and missing
  data imputation.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24as
month: 0
tex_title: Preventing Model Collapse in {G}aussian Process Latent Variable Models
firstpage: 28278
lastpage: 28308
page: 28278-28308
order: 28278
cycles: false
bibtex_author: Li, Ying and Lin, Zhidi and Yin, Feng and Zhang, Michael Minyi
author:
- given: Ying
  family: Li
- given: Zhidi
  family: Lin
- given: Feng
  family: Yin
- given: Michael Minyi
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24as/li24as.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

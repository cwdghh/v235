---
title: In-Context Reinforcement Learning for Variable Action Spaces
openreview: pp3v2ch5Sd
abstract: Recently, it has been shown that transformers pre-trained on diverse datasets
  with multi-episode contexts can generalize to new reinforcement learning tasks in-context.
  A key limitation of previously proposed models is their reliance on a predefined
  action space size and structure. The introduction of a new action space often requires
  data re-collection and model re-training, which can be costly for some applications.
  In our work, we show that it is possible to mitigate this issue by proposing the
  Headless-AD model that, despite being trained only once, is capable of generalizing
  to discrete action spaces of variable size, semantic content and order. By experimenting
  with Bernoulli and contextual bandits, as well as a gridworld environment, we show
  that Headless-AD exhibits significant capability to generalize to action spaces
  it has never encountered, even outperforming specialized models trained for a specific
  set of actions on several environment configurations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sinii24a
month: 0
tex_title: In-Context Reinforcement Learning for Variable Action Spaces
firstpage: 45773
lastpage: 45793
page: 45773-45793
order: 45773
cycles: false
bibtex_author: Sinii, Viacheslav and Nikulin, Alexander and Kurenkov, Vladislav and
  Zisman, Ilya and Kolesnikov, Sergey
author:
- given: Viacheslav
  family: Sinii
- given: Alexander
  family: Nikulin
- given: Vladislav
  family: Kurenkov
- given: Ilya
  family: Zisman
- given: Sergey
  family: Kolesnikov
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/sinii24a/sinii24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

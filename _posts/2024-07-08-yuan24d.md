---
title: Self-Rewarding Language Models
openreview: 0NphYCmgua
abstract: We posit that to achieve superhuman agents, future models require superhuman
  feedback in order to provide an adequate training signal. Current approaches commonly
  train reward models from human preferences, which may then be bottlenecked by human
  performance level, and secondly these reward models require additional human preferences
  data to further improve.In this work, we study Self-Rewarding Language Models, where
  the language model itself is used via LLM-as-a-Judge prompting to provide its own
  rewards during training. We show that during Iterative DPO training, not only does
  instruction following ability improve, but also the ability to provide high-quality
  rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields
  a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard,
  including Claude 2, Gemini Pro, and GPT-4 0613. While there is much left still to
  explore, this work opens the door to the possibility of models that can continually
  improve in both axes.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yuan24d
month: 0
tex_title: Self-Rewarding Language Models
firstpage: 57905
lastpage: 57923
page: 57905-57923
order: 57905
cycles: false
bibtex_author: Yuan, Weizhe and Pang, Richard Yuanzhe and Cho, Kyunghyun and Li, Xian
  and Sukhbaatar, Sainbayar and Xu, Jing and Weston, Jason E
author:
- given: Weizhe
  family: Yuan
- given: Richard Yuanzhe
  family: Pang
- given: Kyunghyun
  family: Cho
- given: Xian
  family: Li
- given: Sainbayar
  family: Sukhbaatar
- given: Jing
  family: Xu
- given: Jason E
  family: Weston
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/yuan24d/yuan24d.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

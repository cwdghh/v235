---
title: 'Relational Learning in Pre-Trained Models: A Theory from Hypergraph Recovery
  Perspective'
openreview: puSMYmHmJW
abstract: 'Foundation Models (FMs) have demonstrated remarkable insights into the
  relational dynamics of the world, leading to the crucial question: <em>how do these
  models acquire an understanding of world hybrid relations?</em> Traditional statistical
  learning, particularly for prediction problems, may overlook the rich and inherently
  structured information from the data, especially regarding the relationships between
  objects. We introduce a mathematical model that formalizes relational learning as
  hypergraph recovery to study pre-training of FMs. In our framework, the world is
  represented as a hypergraph, with data abstracted as random samples from hyperedges.
  We theoretically examine the feasibility of a Pre-Trained Model (PTM) to recover
  this hypergraph and analyze the data efficiency in a minimax near-optimal style.
  By integrating rich graph theories into the realm of PTMs, our mathematical framework
  offers powerful tools for an in-depth understanding of pre-training from a unique
  perspective and can be used under various scenarios. As an example, we extend the
  framework to entity alignment in multimodal learning.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24l
month: 0
tex_title: 'Relational Learning in Pre-Trained Models: A Theory from Hypergraph Recovery
  Perspective'
firstpage: 6666
lastpage: 6698
page: 6666-6698
order: 6666
cycles: false
bibtex_author: Chen, Yang and Fang, Cong and Lin, Zhouchen and Liu, Bing
author:
- given: Yang
  family: Chen
- given: Cong
  family: Fang
- given: Zhouchen
  family: Lin
- given: Bing
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/chen24l/chen24l.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

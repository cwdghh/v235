---
title: Modeling Caption Diversity in Contrastive Vision-Language Pretraining
openreview: iaV2fU6Dif
abstract: There are a thousand ways to caption an image. Contrastive Language Pretraining
  (CLIP) on the other hand, works by mapping an image and its caption to a single
  vector – limiting how well CLIP-like models can represent the diverse ways to describe
  an image. In this work, we introduce Llip, Latent Language Image Pretraining, which
  models the diversity of captions that could match an image. Llip’s vision encoder
  outputs a set of visual features that are mixed into a final representation by conditioning
  on information derived from the text. We show that Llip outperforms non-contextualized
  baselines like CLIP and SigLIP on a variety of tasks even with large-scale encoders.
  Llip improves zero-shot classification by an average of 2.9% zero-shot classification
  benchmarks with a ViT-G/14 encoder. Specifically, Llip attains a zero-shot top-1
  accuracy of 83.5% on ImageNet outperforming a similarly sized CLIP by 1.4%. We also
  demonstrate improvement on zero-shot retrieval on MS-COCO by 6.0%. We provide a
  comprehensive analysis of the components introduced by the method and demonstrate
  that Llip leads to richer visual representations.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lavoie24a
month: 0
tex_title: Modeling Caption Diversity in Contrastive Vision-Language Pretraining
firstpage: 26070
lastpage: 26084
page: 26070-26084
order: 26070
cycles: false
bibtex_author: Lavoie, Samuel and Kirichenko, Polina and Ibrahim, Mark and Assran,
  Mido and Wilson, Andrew Gordon and Courville, Aaron and Ballas, Nicolas
author:
- given: Samuel
  family: Lavoie
- given: Polina
  family: Kirichenko
- given: Mark
  family: Ibrahim
- given: Mido
  family: Assran
- given: Andrew Gordon
  family: Wilson
- given: Aaron
  family: Courville
- given: Nicolas
  family: Ballas
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/lavoie24a/lavoie24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

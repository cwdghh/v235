---
title: 'Revisiting Zeroth-Order Optimization for Memory-Efficient LLM Fine-Tuning:
  A Benchmark'
openreview: THPjMr2r0S
abstract: In the evolving landscape of natural language processing (NLP), fine-tuning
  pre-trained Large Language Models (LLMs) with first-order (FO) optimizers like SGD
  and Adam has become standard. Yet, as LLMs grow in size, the substantial memory
  overhead from back-propagation (BP) for FO gradient computation presents a significant
  challenge. Addressing this issue is crucial, especially for applications like on-device
  training where memory efficiency is paramount. This paper proposes a shift towards
  BP-free, zeroth-order (ZO) optimization as a solution for reducing memory costs
  during LLM fine-tuning, building on the initial concept introduced by (Malladi et
  al., 2023). Unlike traditional ZO-SGD methods, ouè®©work expands the exploration to
  a wider array of ZO optimization techniques, through a comprehensive, first-of-its-kind
  benchmarking study across five LLM families, three task complexities, and five fine-tuning
  schemes. Our study unveils previously overlooked optimization principles, highlighting
  the importance of task alignment, the role of the forward gradient method, and the
  balance between algorithm complexity and fine-tuning performance. We further introduce
  novel enhancements to ZO optimization, including block-wise descent, hybrid training,
  and gradient sparsity. Our study offers a promising direction for achieving further
  memory-efficient LLM fine-tuning. Codes to reproduce all our experiments will be
  made public.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24ad
month: 0
tex_title: 'Revisiting Zeroth-Order Optimization for Memory-Efficient {LLM} Fine-Tuning:
  A Benchmark'
firstpage: 59173
lastpage: 59190
page: 59173-59190
order: 59173
cycles: false
bibtex_author: Zhang, Yihua and Li, Pingzhi and Hong, Junyuan and Li, Jiaxiang and
  Zhang, Yimeng and Zheng, Wenqing and Chen, Pin-Yu and Lee, Jason D. and Yin, Wotao
  and Hong, Mingyi and Wang, Zhangyang and Liu, Sijia and Chen, Tianlong
author:
- given: Yihua
  family: Zhang
- given: Pingzhi
  family: Li
- given: Junyuan
  family: Hong
- given: Jiaxiang
  family: Li
- given: Yimeng
  family: Zhang
- given: Wenqing
  family: Zheng
- given: Pin-Yu
  family: Chen
- given: Jason D.
  family: Lee
- given: Wotao
  family: Yin
- given: Mingyi
  family: Hong
- given: Zhangyang
  family: Wang
- given: Sijia
  family: Liu
- given: Tianlong
  family: Chen
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zhang24ad/zhang24ad.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient LLMs
  Under Compression'
openreview: e3Dpq3WdMv
abstract: Compressing high-capability Large Language Models (LLMs) has emerged as
  a favored strategy for resource-efficient inferences. While state-of-the-art (SoTA)
  compression methods boast impressive advancements in preserving benign task performance,
  the potential risks of compression in terms of safety and trustworthiness have been
  largely neglected. This study conducts the first, thorough evaluation of <b>three
  (3) leading LLMs</b> using <b>five (5) SoTA compression techniques</b> across <b>eight
  (8) trustworthiness dimensions</b>. Our experiments highlight the intricate interplay
  between compression and trustworthiness, revealing some interesting patterns. We
  find that quantization is currently a more effective approach than pruning in achieving
  efficiency and trustworthiness simultaneously. For instance, a 4-bit quantized model
  retains the trustworthiness of its original counterpart, but model pruning significantly
  degrades trustworthiness, even at 50% sparsity. Moreover, employing quantization
  within a moderate bit range could unexpectedly improve certain trustworthiness dimensions
  such as ethics and fairness. Conversely, extreme quantization to very low bit levels
  (3 bits) tends to reduce trustworthiness significantly. This increased risk cannot
  be uncovered by looking at benign performance alone, in turn, mandating comprehensive
  trustworthiness evaluation in practice. These findings culminate in practical recommendations
  for simultaneously achieving high utility, efficiency, and trustworthiness in LLMs.
  Code and models are available at https://decoding-comp-trust.github.io.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hong24a
month: 0
tex_title: 'Decoding Compressed Trust: Scrutinizing the Trustworthiness of Efficient
  {LLM}s Under Compression'
firstpage: 18611
lastpage: 18633
page: 18611-18633
order: 18611
cycles: false
bibtex_author: Hong, Junyuan and Duan, Jinhao and Zhang, Chenhui and Li, Zhangheng
  and Xie, Chulin and Lieberman, Kelsey and Diffenderfer, James and Bartoldson, Brian
  R. and Jaiswal, Ajay Kumar and Xu, Kaidi and Kailkhura, Bhavya and Hendrycks, Dan
  and Song, Dawn and Wang, Zhangyang and Li, Bo
author:
- given: Junyuan
  family: Hong
- given: Jinhao
  family: Duan
- given: Chenhui
  family: Zhang
- given: Zhangheng
  family: Li
- given: Chulin
  family: Xie
- given: Kelsey
  family: Lieberman
- given: James
  family: Diffenderfer
- given: Brian R.
  family: Bartoldson
- given: Ajay Kumar
  family: Jaiswal
- given: Kaidi
  family: Xu
- given: Bhavya
  family: Kailkhura
- given: Dan
  family: Hendrycks
- given: Dawn
  family: Song
- given: Zhangyang
  family: Wang
- given: Bo
  family: Li
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/hong24a/hong24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Private Truly-Everlasting Robust-Prediction
openreview: BdQTCAuT6L
abstract: Private everlasting prediction (PEP), recently introduced by Naor et al.
  [2023], is a model for differentially private learning in which the learner never
  publicly releases a hypothesis. Instead, it provides black-box access to a "prediction
  oracle" that can predict the labels of an <em>endless stream</em> of unlabeled examples
  drawn from the underlying distribution. Importantly, PEP provides privacy both for
  the initial training set and for the endless stream of classification queries. We
  present two conceptual modifications to the definition of PEP, as well as new constructions
  exhibiting significant improvements over prior work. Specifically, we incorporate
  robustness against poisoning attacks into the definition of PEP; we present a relaxed
  privacy definition, suitable for PEP, that allows us to disconnect the privacy parameter
  $\delta$ from the number of total time steps $T$; and we present new constructions
  for axis-aligned rectangles and decision-stumps exhibiting improved sample complexity
  and runtime.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: stemmer24a
month: 0
tex_title: Private Truly-Everlasting Robust-Prediction
firstpage: 46591
lastpage: 46604
page: 46591-46604
order: 46591
cycles: false
bibtex_author: Stemmer, Uri
author:
- given: Uri
  family: Stemmer
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/stemmer24a/stemmer24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

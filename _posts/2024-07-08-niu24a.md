---
title: Test-Time Model Adaptation with Only Forward Passes
openreview: qz1Vx1v9iK
abstract: 'Test-time adaptation has proven effective in adapting a given trained model
  to unseen test samples with potential distribution shifts. However, in real-world
  scenarios, models are usually deployed on resource-limited devices, e.g., FPGAs,
  and are often quantized and hard-coded with non-modifiable parameters for acceleration.
  In light of this, existing methods are often infeasible since they heavily depend
  on computation-intensive backpropagation for model updating that may be not supported.
  To address this, we propose a test-time Forward-Optimization Adaptation (FOA) method.
  In FOA, we seek to solely learn a newly added prompt (as modelâ€™s input) via a derivative-free
  covariance matrix adaptation evolution strategy. To make this strategy work stably
  under our online unsupervised setting, we devise a novel fitness function by measuring
  test-training statistic discrepancy and model prediction entropy. Moreover, we design
  an activation shifting scheme that directly tunes the model activations for shifted
  test samples, making them align with the source training domain, thereby further
  enhancing adaptation performance. Without using any backpropagation and altering
  model weights, FOA runs on quantized 8-bit ViT outperforms gradient-based TENT on
  full-precision 32-bit ViT, while achieving an up to <em>24</em>-fold memory reduction
  on ImageNet-C. The source code is available at: https://github.com/mr-eggplant/FOA.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: niu24a
month: 0
tex_title: Test-Time Model Adaptation with Only Forward Passes
firstpage: 38298
lastpage: 38315
page: 38298-38315
order: 38298
cycles: false
bibtex_author: Niu, Shuaicheng and Miao, Chunyan and Chen, Guohao and Wu, Pengcheng
  and Zhao, Peilin
author:
- given: Shuaicheng
  family: Niu
- given: Chunyan
  family: Miao
- given: Guohao
  family: Chen
- given: Pengcheng
  family: Wu
- given: Peilin
  family: Zhao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/niu24a/niu24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'Position: Intent-aligned AI Systems Must Optimize for Agency Preservation'
openreview: rfvgdfd1K9
abstract: 'A central approach to AI-safety research has been to generate aligned AI
  systems: i.e. systems that do not deceive users and yield actions or recommendations
  that humans might judge as consistent with their intentions and goals. Here we argue
  that truthful AIs aligned solely to human intent are insufficient and that preservation
  of long-term agency of humans may be a more robust standard that may need to be
  separated and explicitly optimized for. We discuss the science of intent and control
  and how human intent can be manipulated and we provide a formal definition of agency-preserving
  AI-human interactions focusing on forward-looking explicit agency evaluations. Our
  work points to a novel pathway for human harm in AI-human interactions and proposes
  solutions to this challenge.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: mitelut24a
month: 0
tex_title: 'Position: Intent-aligned {AI} Systems Must Optimize for Agency Preservation'
firstpage: 35851
lastpage: 35875
page: 35851-35875
order: 35851
cycles: false
bibtex_author: Mitelut, Catalin and Smith, Benjamin and Vamplew, Peter
author:
- given: Catalin
  family: Mitelut
- given: Benjamin
  family: Smith
- given: Peter
  family: Vamplew
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/mitelut24a/mitelut24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

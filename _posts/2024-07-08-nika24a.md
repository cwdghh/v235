---
title: 'Reward Model Learning vs. Direct Policy Optimization: A Comparative Analysis
  of Learning from Human Preferences'
openreview: JQlEUfzhuA
abstract: In this paper, we take a step towards a deeper understanding of learning
  from human preferences by systematically comparing the paradigm of reinforcement
  learning from human feedback (RLHF) with the recently proposed paradigm of direct
  preference optimization (DPO). We focus our attention on the class of loglinear
  policy parametrization and linear reward functions. In order to compare the two
  paradigms, we first derive minimax statistical bounds on the suboptimality gap induced
  by both RLHF and DPO, assuming access to an oracle that exactly solves the optimization
  problems. We provide a detailed discussion on the relative comparison between the
  two paradigms, simultaneously taking into account the sample size, policy and reward
  class dimensions, and the regularization temperature. Moreover, we extend our analysis
  to the approximate optimization setting and derive exponentially decaying convergence
  rates for both RLHF and DPO. Next, we analyze the setting where the ground-truth
  reward is not realizable and find that, while RLHF incurs a constant additional
  error, DPO retains its asymptotically decaying gap by just tuning the temperature
  accordingly. Finally, we extend our comparison to the Markov decision process setting,
  where we generalize our results with exact optimization. To the best of our knowledge,
  we are the first to provide such a comparative analysis for RLHF and DPO.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nika24a
month: 0
tex_title: 'Reward Model Learning vs. Direct Policy Optimization: A Comparative Analysis
  of Learning from Human Preferences'
firstpage: 38145
lastpage: 38186
page: 38145-38186
order: 38145
cycles: false
bibtex_author: Nika, Andi and Mandal, Debmalya and Kamalaruban, Parameswaran and Tzannetos,
  Georgios and Radanovic, Goran and Singla, Adish
author:
- given: Andi
  family: Nika
- given: Debmalya
  family: Mandal
- given: Parameswaran
  family: Kamalaruban
- given: Georgios
  family: Tzannetos
- given: Goran
  family: Radanovic
- given: Adish
  family: Singla
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/nika24a/nika24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: On Prompt-Driven Safeguarding for Large Language Models
openreview: ugxGpOEkox
abstract: Prepending model inputs with safety prompts is a common practice for safeguarding
  large language models (LLMs) against queries with harmful intents. However, the
  underlying working mechanisms of safety prompts have not been unraveled yet, restricting
  the possibility of automatically optimizing them to improve LLM safety. In this
  work, we investigate how LLMs’ behavior (i.e., complying with or refusing user queries)
  is affected by safety prompts from the perspective of model representation. We find
  that in the representation space, the input queries are typically moved by safety
  prompts in a "higher-refusal" direction, in which models become more prone to refusing
  to provide assistance, even when the queries are harmless. On the other hand, LLMs
  are naturally capable of distinguishing harmful and harmless queries without safety
  prompts. Inspired by these findings, we propose a method for safety prompt optimization,
  namely DRO (Directed Representation Optimization). Treating a safety prompt as continuous,
  trainable embeddings, DRO learns to move the queries’ representations along or opposite
  the refusal direction, depending on their harmfulness. Experiments with eight LLMs
  on out-of-domain and jailbreak benchmarks demonstrate that DRO remarkably improves
  the safeguarding performance of human-crafted safety prompts, without compromising
  the models’ general performance.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zheng24n
month: 0
tex_title: On Prompt-Driven Safeguarding for Large Language Models
firstpage: 61593
lastpage: 61613
page: 61593-61613
order: 61593
cycles: false
bibtex_author: Zheng, Chujie and Yin, Fan and Zhou, Hao and Meng, Fandong and Zhou,
  Jie and Chang, Kai-Wei and Huang, Minlie and Peng, Nanyun
author:
- given: Chujie
  family: Zheng
- given: Fan
  family: Yin
- given: Hao
  family: Zhou
- given: Fandong
  family: Meng
- given: Jie
  family: Zhou
- given: Kai-Wei
  family: Chang
- given: Minlie
  family: Huang
- given: Nanyun
  family: Peng
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zheng24n/zheng24n.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

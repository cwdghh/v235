---
title: 'RoSA: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation'
openreview: FYvpxyS43U
abstract: We investigate parameter-efficient fine-tuning (PEFT) methods that can provide
  good accuracy under limited computational and memory budgets in the context of large
  language models (LLMs). We present a new PEFT method called Robust Adaptation (RoSA)
  inspired by robust principal component analysis that jointly trains $\textit{low-rank}$
  and <em>highly-sparse</em> components on top of a set of fixed pretrained weights
  to efficiently approximate the performance of a full-fine-tuning (FFT) solution.
  Across a series of challenging generative tasks such as grade-school math and SQL
  query generation, which require fine-tuning for good performance, we show that RoSA
  outperforms LoRA, pure sparse fine-tuning, and alternative hybrid methods at the
  same parameter budget, and can even recover the performance of FFT on some tasks.
  We provide system support for RoSA to complement the training algorithm, specifically
  in the form of sparse GPU kernels which enable memory- and computationally-efficient
  training, and show that it is also compatible with low-precision base weights, resulting
  in the first joint representation combining quantization, low-rank and sparse approximations.
  Our code is available at https://github.com/IST-DASLab/RoSA.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: nikdan24a
month: 0
tex_title: "{R}o{SA}: Accurate Parameter-Efficient Fine-Tuning via Robust Adaptation"
firstpage: 38187
lastpage: 38206
page: 38187-38206
order: 38187
cycles: false
bibtex_author: Nikdan, Mahdi and Tabesh, Soroush and Crn\v{c}evi\'{c}, Elvir and Alistarh,
  Dan
author:
- given: Mahdi
  family: Nikdan
- given: Soroush
  family: Tabesh
- given: Elvir
  family: Crnčević
- given: Dan
  family: Alistarh
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/nikdan24a/nikdan24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

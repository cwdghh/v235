---
title: Exploring the LLM Journey from Cognition to Expression with Linear Representations
openreview: WtvI3QijEF
abstract: 'This paper presents an in-depth examination of the evolution and interplay
  of cognitive and expressive capabilities in large language models (LLMs), with a
  specific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese and
  English) LLM series. We define and explore the model’s cognitive and expressive
  capabilities through linear representations across three critical phases: Pretraining,
  Supervised Fine-Tuning (SFT), and Reinforcement Learning from Human Feedback (RLHF).
  Cognitive capability is defined as the quantity and quality of information conveyed
  by the neuron output vectors within the network, similar to the neural signal processing
  in human cognition. Expressive capability is defined as the model’s capability to
  produce word-level output. Our findings unveil a sequential development pattern,
  where cognitive abilities are largely established during Pretraining, whereas expressive
  abilities predominantly advance during SFT and RLHF. Statistical analyses confirm
  a significant correlation between the two capabilities, suggesting that cognitive
  capacity may limit expressive potential. The paper also explores the theoretical
  underpinnings of these divergent developmental trajectories and their connection
  to the LLMs’ architectural design. Moreover, we evaluate various optimization-independent
  strategies, such as few-shot learning and repeated sampling, which bridge the gap
  between cognitive and expressive capabilities. This research reveals the potential
  connection between the hidden space and the output space, contributing valuable
  insights into the interpretability and controllability of their training processes.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: yan24c
month: 0
tex_title: Exploring the {LLM} Journey from Cognition to Expression with Linear Representations
firstpage: 55778
lastpage: 55796
page: 55778-55796
order: 55778
cycles: false
bibtex_author: Yan, Yuzi and Li, Jialian and Zhang, Yipin and Yan, Dong
author:
- given: Yuzi
  family: Yan
- given: Jialian
  family: Li
- given: Yipin
  family: Zhang
- given: Dong
  family: Yan
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/yan24c/yan24c.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

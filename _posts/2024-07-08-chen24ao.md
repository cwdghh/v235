---
title: 'SelfIE: Self-Interpretation of Large Language Model Embeddings'
openreview: gjgRKbdYR7
abstract: How do large language models (LLMs) obtain their answers? The ability to
  explain and control an LLM’s reasoning process is key for reliability, transparency,
  and future model developments. We propose SelfIE (Self-Interpretation of Embeddings),
  a framework that enables LLMs to interpret their own embeddings in natural language
  by leveraging their ability to respond to inquiries about a given passage. Capable
  of interpreting open-world concepts in the hidden embeddings, SelfIE reveals LLM
  internal reasoning in cases such as making ethical decisions, internalizing prompt
  injection, and recalling harmful knowledge. SelfIE’s text descriptions on hidden
  embeddings open avenues to control LLM reasoning. We propose Supervised Control,
  which allows editing open-ended concepts while only requiring gradient computation
  of individual layer. We extend RLHF to hidden embeddings and propose Reinforcement
  Control that erases harmful knowledge in LLM without supervision targets.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: chen24ao
month: 0
tex_title: "{S}elf{IE}: Self-Interpretation of Large Language Model Embeddings"
firstpage: 7373
lastpage: 7388
page: 7373-7388
order: 7373
cycles: false
bibtex_author: Chen, Haozhe and Vondrick, Carl and Mao, Chengzhi
author:
- given: Haozhe
  family: Chen
- given: Carl
  family: Vondrick
- given: Chengzhi
  family: Mao
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/chen24ao/chen24ao.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

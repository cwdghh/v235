---
title: Privacy-Preserving Embedding via Look-up Table Evaluation with Fully Homomorphic
  Encryption
openreview: apxON2uH4N
abstract: In privacy-preserving machine learning (PPML), homomorphic encryption (HE)
  has emerged as a significant primitive, allowing the use of machine learning (ML)
  models while protecting the confidentiality of input data. Although extensive research
  has been conducted on implementing PPML with HE by developing the efficient construction
  of private counterparts to ML models, the efficient HE implementation of embedding
  layers for token inputs such as words remains inadequately addressed. Thus, our
  study proposes an efficient algorithm for privacy-preserving embedding via look-up
  table evaluation with HE(HELUT) by developing an encrypted indicator function (EIF)
  that assures high precision with the use of the approximate HE scheme(CKKS). Based
  on the proposed EIF, we propose the CodedHELUT algorithm to facilitate an encrypted
  embedding layer for the first time. CodedHELUT leverages coded inputs to improve
  overall efficiency and optimize memory usage. Our comprehensive empirical analysis
  encompasses both synthetic tables and real-world largescale word embedding models.
  CodedHELUT algorithm achieves amortized evaluation time of 0.018-0.242s for GloVe6B50d,
  0.104-01.298s for GloVe42300d, 0.262-3.283s for GPT-2 and BERT embedding layers
  while maintaining high precision (16 bits)
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kim24ab
month: 0
tex_title: Privacy-Preserving Embedding via Look-up Table Evaluation with Fully Homomorphic
  Encryption
firstpage: 24437
lastpage: 24457
page: 24437-24457
order: 24437
cycles: false
bibtex_author: Kim, Jae-Yun and Park, Saerom and Lee, Joohee and Cheon, Jung Hee
author:
- given: Jae-Yun
  family: Kim
- given: Saerom
  family: Park
- given: Joohee
  family: Lee
- given: Jung Hee
  family: Cheon
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/kim24ab/kim24ab.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Revisiting Scalable Hessian Diagonal Approximations for Applications in Reinforcement
  Learning
openreview: yrFUJzcTsk
abstract: Second-order information is valuable for many applications but challenging
  to compute. Several works focus on computing or approximating Hessian diagonals,
  but even this simplification introduces significant additional costs compared to
  computing a gradient. In the absence of efficient exact computation schemes for
  Hessian diagonals, we revisit an early approximation scheme proposed by Becker and
  LeCun (1989, BL89), which has a cost similar to gradients and appears to have been
  overlooked by the community. We introduce HesScale, an improvement over BL89, which
  adds negligible extra computation. On small networks, we find that this improvement
  is of higher quality than all alternatives, even those with theoretical guarantees,
  such as unbiasedness, while being much cheaper to compute. We use this insight in
  reinforcement learning problems where small networks are used and demonstrate HesScale
  in second-order optimization and scaling the step-size parameter. In our experiments,
  HesScale optimizes faster than existing methods and improves stability through step-size
  scaling. These findings are promising for scaling second-order methods in larger
  models in the future.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: elsayed24a
month: 0
tex_title: Revisiting Scalable Hessian Diagonal Approximations for Applications in
  Reinforcement Learning
firstpage: 12448
lastpage: 12468
page: 12448-12468
order: 12448
cycles: false
bibtex_author: Elsayed, Mohamed and Farrahi, Homayoon and Dangel, Felix and Mahmood,
  A. Rupam
author:
- given: Mohamed
  family: Elsayed
- given: Homayoon
  family: Farrahi
- given: Felix
  family: Dangel
- given: A. Rupam
  family: Mahmood
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/elsayed24a/elsayed24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

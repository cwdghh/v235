---
title: 'How Deep Do We Need: Accelerating Training and Inference of Neural ODEs via
  Control Perspective'
openreview: f6QenZyyeP
abstract: Neural Ordinary Differential Equations (ODEs) have shown promise in learning
  continuous dynamics. However, their slow training and inference speed hinder wider
  applications. In this paper, we propose to optimize Neural ODEs from a spatial and
  temporal perspective, drawing inspiration from control theory. We aim to find a
  reasonable depth of the network, accelerating both training and inference while
  maintaining network performance. Two approaches are proposed. One reformulates training
  as a minimum-time optimal control problem directly in a single stage to search for
  the terminal time and network weights. The second approach uses pre-training coupled
  with a Lyapunov method in an initial stage, and then at a secondary stage introduces
  a safe terminal time updating mechanism in the forward direction. Experimental results
  demonstrate the effectiveness of speeding up Neural ODEs.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: miao24a
month: 0
tex_title: 'How Deep Do We Need: Accelerating Training and Inference of Neural {ODE}s
  via Control Perspective'
firstpage: 35528
lastpage: 35545
page: 35528-35545
order: 35528
cycles: false
bibtex_author: Miao, Keyan and Gatsis, Konstantinos
author:
- given: Keyan
  family: Miao
- given: Konstantinos
  family: Gatsis
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/miao24a/miao24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: 'MLAgentBench: Evaluating Language Agents on Machine Learning Experimentation'
openreview: 1Fs1LvjYQW
abstract: A central aspect of machine learning research is experimentation, the process
  of designing and running experiments, analyzing the results, and iterating towards
  some positive outcome (e.g., improving accuracy). Could agents driven by powerful
  language models perform machine learning experimentation effectively? To answer
  this question, we introduce MLAgentBench, a suite of 13 tasks ranging from improving
  model performance on CIFAR-10 to recent research problems like BabyLM. For each
  task, an agent can perform actions like reading/writing files, executing code, and
  inspecting outputs. We then construct an agent that can perform ML experimentation
  based on ReAct framework. We benchmark agents based on Claude v1.0, Claude v2.1,
  Claude v3 Opus, GPT-4, GPT-4-turbo, Gemini-Pro, and Mixtral and find that a Claude
  v3 Opus agent is the best in terms of success rate. It can build compelling ML models
  over many tasks in MLAgentBench with 37.5% average success rate. Our agents also
  display highly interpretable plans and actions. However, the success rates vary
  considerably; they span from 100% on well-established older datasets to as low as
  0% on recent Kaggle challenges created potentially after the underlying LM was trained.
  Finally, we identify several key challenges for LM-based agents such as long-term
  planning and reducing hallucination.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: huang24y
month: 0
tex_title: "{MLA}gent{B}ench: Evaluating Language Agents on Machine Learning Experimentation"
firstpage: 20271
lastpage: 20309
page: 20271-20309
order: 20271
cycles: false
bibtex_author: Huang, Qian and Vora, Jian and Liang, Percy and Leskovec, Jure
author:
- given: Qian
  family: Huang
- given: Jian
  family: Vora
- given: Percy
  family: Liang
- given: Jure
  family: Leskovec
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/huang24y/huang24y.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

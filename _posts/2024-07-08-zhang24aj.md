---
title: Multi-Factor Adaptive Vision Selection for Egocentric Video Question Answering
openreview: u00dmbI8Db
abstract: The challenge of interpreting the world from a human perspective in Artificial
  Intelligence (AI) is particularly evident in egocentric video question answering,
  which grapples with issues like small object recognition, noise suppression, and
  spatial-temporal reasoning. To address these challenges, we introduce the Multi-Factor
  Adaptive vision Selection (MFAS) framework. MFAS integrates a patch partition and
  merging module for enhanced small object recognition, a prior-guided patch selection
  module for noise suppression and focused analysis, and a hierarchical aggregation
  network to aggregate visual semantics guided by questions. Extensive experiments
  on several public egocentric datasets have validated the effectiveness and generalization
  of our framework. Code and data are available in https://github.com/Hyu-Zhang/EgoVideoQA.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zhang24aj
month: 0
tex_title: Multi-Factor Adaptive Vision Selection for Egocentric Video Question Answering
firstpage: 59310
lastpage: 59328
page: 59310-59328
order: 59310
cycles: false
bibtex_author: Zhang, Haoyu and Liu, Meng and Liu, Zixin and Song, Xuemeng and Wang,
  Yaowei and Nie, Liqiang
author:
- given: Haoyu
  family: Zhang
- given: Meng
  family: Liu
- given: Zixin
  family: Liu
- given: Xuemeng
  family: Song
- given: Yaowei
  family: Wang
- given: Liqiang
  family: Nie
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/zhang24aj/zhang24aj.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

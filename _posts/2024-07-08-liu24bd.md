---
title: Perfect Alignment May be Poisonous to Graph Contrastive Learning
openreview: wdezvnc9EG
abstract: Graph Contrastive Learning (GCL) aims to learn node representations by aligning
  positive pairs and separating negative ones. However, few of researchers have focused
  on the inner law behind specific augmentations used in graph-based learning. What
  kind of augmentation will help downstream performance, how does contrastive learning
  actually influence downstream tasks, and why the magnitude of augmentation matters
  so much? This paper seeks to address these questions by establishing a connection
  between augmentation and downstream performance. Our findings reveal that GCL contributes
  to downstream tasks mainly by separating different classes rather than gathering
  nodes of the same class. So perfect alignment and augmentation overlap which draw
  all intra-class samples the same can not fully explain the success of contrastive
  learning. Therefore, in order to understand how augmentation aids the contrastive
  learning process, we conduct further investigations into the generalization, finding
  that perfect alignment that draw positive pair the same could help contrastive loss
  but is poisonous to generalization, as a result, perfect alignment may not lead
  to best downstream performance, so specifically designed augmentation is needed
  to achieve appropriate alignment performance and improve downstream accuracy. We
  further analyse the result by information theory and graph spectrum theory and propose
  two simple but effective methods to verify the theories. The two methods could be
  easily applied to various GCL algorithms and extensive experiments are conducted
  to prove its effectiveness. The code is available at https://github.com/somebodyhh1/GRACEIS
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24bd
month: 0
tex_title: Perfect Alignment May be Poisonous to Graph Contrastive Learning
firstpage: 31890
lastpage: 31916
page: 31890-31916
order: 31890
cycles: false
bibtex_author: Liu, Jingyu and Tang, Huayi and Liu, Yong
author:
- given: Jingyu
  family: Liu
- given: Huayi
  family: Tang
- given: Yong
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24bd/liu24bd.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

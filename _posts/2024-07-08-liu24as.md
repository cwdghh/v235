---
title: Revisiting Context Aggregation for Image Matting
openreview: sjJZHPV9Id
abstract: Traditional studies emphasize the significance of context information in
  improving matting performance. Consequently, deep learning-based matting methods
  delve into designing pooling or affinity-based context aggregation modules to achieve
  superior results. However, these modules cannot well handle the context scale shift
  caused by the difference in image size during training and inference, resulting
  in matting performance degradation. In this paper, we revisit the context aggregation
  mechanisms of matting networks and find that a basic encoder-decoder network without
  any context aggregation modules can actually learn more universal context aggregation,
  thereby achieving higher matting performance compared to existing methods. Building
  on this insight, we present AEMatter, a matting network that is straightforward
  yet very effective. AEMatter adopts a Hybrid-Transformer backbone with appearance-enhanced
  axis-wise learning (AEAL) blocks to build a basic network with strong context aggregation
  learning capability. Furthermore, AEMatter leverages a large image training strategy
  to assist the network in learning context aggregation from data. Extensive experiments
  on five popular matting datasets demonstrate that the proposed AEMatter outperforms
  state-of-the-art matting methods by a large margin. The source code is available
  at https://github.com/aipixel/AEMatter.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: liu24as
month: 0
tex_title: Revisiting Context Aggregation for Image Matting
firstpage: 31629
lastpage: 31644
page: 31629-31644
order: 31629
cycles: false
bibtex_author: Liu, Qinglin and Lv, Xiaoqian and Meng, Quanling and Li, Zonglin and
  Lan, Xiangyuan and Yang, Shuo and Zhang, Shengping and Nie, Liqiang
author:
- given: Qinglin
  family: Liu
- given: Xiaoqian
  family: Lv
- given: Quanling
  family: Meng
- given: Zonglin
  family: Li
- given: Xiangyuan
  family: Lan
- given: Shuo
  family: Yang
- given: Shengping
  family: Zhang
- given: Liqiang
  family: Nie
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/liu24as/liu24as.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

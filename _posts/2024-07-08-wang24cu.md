---
title: 'Neural Collapse meets Differential Privacy: Curious behaviors of NoisyGD with
  Near-Perfect Representation Learning'
openreview: 7rrN6E4KU0
abstract: A recent study by De et al. (2022) shows that large-scale representation
  learning through pre-training on a public dataset significantly enhances differentially
  private (DP) learning in downstream tasks. To explain this, we consider a layer-peeled
  model in representation learning, resulting in Neural Collapse (NC) phenomena. Within
  NC, we establish that the misclassification error is independent of dimension when
  the distance between actual and ideal features is below a threshold. We empirically
  evaluate feature quality in the last layer under different pre-trained models, showing
  that a more powerful pre-trained model improves feature representation. Moreover,
  we show that DP fine-tuning is less robust compared to non-DP fine-tuning, especially
  with perturbations. Supported by theoretical analyses and experiments, we suggest
  strategies like feature normalization and dimension reduction methods such as PCA
  to enhance DP fine-tuning robustness. Conducting PCA on last-layer features significantly
  improves testing accuracy.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: wang24cu
month: 0
tex_title: 'Neural Collapse meets Differential Privacy: Curious behaviors of {N}oisy{GD}
  with Near-Perfect Representation Learning'
firstpage: 52334
lastpage: 52360
page: 52334-52360
order: 52334
cycles: false
bibtex_author: Wang, Chendi and Zhu, Yuqing and Su, Weijie J and Wang, Yu-Xiang
author:
- given: Chendi
  family: Wang
- given: Yuqing
  family: Zhu
- given: Weijie J
  family: Su
- given: Yu-Xiang
  family: Wang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/wang24cu/wang24cu.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

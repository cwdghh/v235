---
title: Plug-in Performative Optimization
openreview: jh7FDDwDBf
abstract: When predictions are performative, the choice of which predictor to deploy
  influences the distribution of future observations. The overarching goal in learning
  under performativity is to find a predictor that has low performative risk, that
  is, good performance on its induced distribution. One family of solutions for optimizing
  the performative risk, including bandits and other derivative-free methods, is agnostic
  to any structure in the performative feedback, leading to exceedingly slow convergence
  rates. A complementary family of solutions makes use of explicit models for the
  feedback, such as best-response models in strategic classification, enabling faster
  rates. However, these rates critically rely on the feedback model being correct.
  In this work we study a general protocol for making use of possibly misspecified
  models in performative prediction, called plug-in performative optimization. We
  show this solution can be far superior to model-agnostic strategies, as long as
  the misspecification is not too extreme. Our results support the hypothesis that
  models, even if misspecified, can indeed help with learning in performative settings.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: lin24ab
month: 0
tex_title: Plug-in Performative Optimization
firstpage: 30546
lastpage: 30565
page: 30546-30565
order: 30546
cycles: false
bibtex_author: Lin, Licong and Zrnic, Tijana
author:
- given: Licong
  family: Lin
- given: Tijana
  family: Zrnic
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/lin24ab/lin24ab.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Logistic Variational Bayes Revisited
openreview: 3FBO41d4T2
abstract: 'Variational logistic regression is a popular method for approximate Bayesian
  inference seeing wide-spread use in many areas of machine learning including: Bayesian
  optimization, reinforcement learning and multi-instance learning to name a few.
  However, due to the intractability of the Evidence Lower Bound, authors have turned
  to the use of Monte Carlo, quadrature or bounds to perform inference, methods which
  are costly or give poor approximations to the true posterior. In this paper we introduce
  a new bound for the expectation of softplus function and subsequently show how this
  can be applied to variational logistic regression and Gaussian process classification.
  Unlike other bounds, our proposal does not rely on extending the variational family,
  or introducing additional parameters to ensure the bound is tight. In fact, we show
  that this bound is tighter than the state-of-the-art, and that the resulting variational
  posterior achieves state-of-the-art performance, whilst being significantly faster
  to compute than Monte-Carlo methods.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: komodromos24a
month: 0
tex_title: Logistic Variational {B}ayes Revisited
firstpage: 25087
lastpage: 25104
page: 25087-25104
order: 25087
cycles: false
bibtex_author: Komodromos, Michael and Evangelou, Marina and Filippi, Sarah Lucie
author:
- given: Michael
  family: Komodromos
- given: Marina
  family: Evangelou
- given: Sarah Lucie
  family: Filippi
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/komodromos24a/komodromos24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

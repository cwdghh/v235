---
title: Tandem Transformers for Inference Efficient LLMs
openreview: TN3fi7dwPo
abstract: 'The autoregressive nature of conventional large language models (LLMs)
  inherently limits inference speed, as tokens are generated sequentially. While speculative
  (Leviathan et al., 2023) and parallel (Stern et al., 2018) decoding techniques attempt
  to mitigate this, they face limitations: either relying on less accurate smaller
  models for generation or failing to fully leverage the base LLM’s representations.
  We introduce a novel architecture, Tandem transformers, to address these issues.
  This architecture uniquely combines (1) a small autoregressive model and (2) a large
  model operating in block mode (processing multiple tokens simultaneously). The small
  model’s predictive accuracy is substantially enhanced by granting it attention to
  the large model’s richer representations. On the PaLM2 pretraining dataset, a tandem
  of PaLM2-Bison and PaLM2-Gecko demonstrates a 3.3% improvement in next-token prediction
  accuracy over a standalone PaLM2-Gecko, offering a 1.16x speedup compared to a PaLM2-Otter
  model with comparable downstream performance. We further incorporate the Tandem
  model within the speculative decoding (SPEED) framework where the large model validates
  tokens from the small model. This ensures that the tandem of PaLM2-Bison and PaLM2-Gecko
  achieves substantial speedup (around 1.14x faster than using vanilla PaLM2-Gecko
  in SPEED) while maintaining identical downstream task accuracy.'
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: s24a
month: 0
tex_title: Tandem Transformers for Inference Efficient {LLM}s
firstpage: 42906
lastpage: 42917
page: 42906-42917
order: 42906
cycles: false
bibtex_author: S, Aishwarya P and Nair, Pranav Ajit and L, Yashas Samaga B and Boyd,
  Toby James and Kumar, Sanjiv and Jain, Prateek and Netrapalli, Praneeth
author:
- given: Aishwarya P
  family: S
- given: Pranav Ajit
  family: Nair
- given: Yashas Samaga B
  family: L
- given: Toby James
  family: Boyd
- given: Sanjiv
  family: Kumar
- given: Prateek
  family: Jain
- given: Praneeth
  family: Netrapalli
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/s24a/s24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

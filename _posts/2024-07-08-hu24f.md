---
title: Accelerated Speculative Sampling Based on Tree Monte Carlo
openreview: stMhi1Sn2G
abstract: Speculative Sampling (SpS) has been introduced to speed up inference of
  large language models (LLMs) by generating multiple tokens in a single forward pass
  under the guidance of a reference model, while preserving the original distribution.
  We observe that SpS can be derived through maximum coupling on the token distribution.
  However, we find that this approach is not optimal as it applies maximum coupling
  incrementally for each new token, rather than seeking a global maximum coupling
  that yields a faster algorithm, given the tree-space nature of LLM generative distributions.
  In this paper, we shift our focus from distributions on a token space to those on
  a tree space. We propose a novel class of Tree Monte Carlo (TMC) methods, demonstrating
  their unbiasedness and convergence. As a particular instance of TMC, our new algorithm,
  Accelerated Speculative Sampling (ASpS), outperforms traditional SpS by generating
  more tokens per step on average, achieving faster inference, while maintaining the
  original distribution.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: hu24f
month: 0
tex_title: Accelerated Speculative Sampling Based on Tree {M}onte {C}arlo
firstpage: 19216
lastpage: 19251
page: 19216-19251
order: 19216
cycles: false
bibtex_author: Hu, Zhengmian and Huang, Heng
author:
- given: Zhengmian
  family: Hu
- given: Heng
  family: Huang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/hu24f/hu24f.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

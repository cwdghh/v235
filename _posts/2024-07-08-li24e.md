---
title: Purifying Quantization-conditioned Backdoors via Layer-wise Activation Correction
  with Distribution Approximation
openreview: CEfr3h68KU
abstract: Model quantization is a compression technique that converts a full-precision
  model to a more compact low-precision version for better storage. Despite the great
  success of quantization, recent studies revealed the feasibility of malicious exploiting
  model quantization via implanting quantization-conditioned backdoors (QCBs). These
  special backdoors remain dormant in full-precision models but are exposed upon quantization.
  Unfortunately, existing defenses have limited effects on mitigating QCBs. In this
  paper, we conduct an in-depth analysis of QCBs. We reveal an intriguing characteristic
  of QCBs, where activation of backdoor-related neurons on even benign samples enjoy
  a distribution drift after quantization, although this drift is more significant
  on poisoned samples. Motivated by this finding, we propose to purify the backdoor-exposed
  quantized model by aligning its layer-wise activation with its full-precision version.
  To further exploit the more pronounced activation drifts on poisoned samples, we
  design an additional module to layer-wisely approximate poisoned activation distribution
  based on batch normalization statistics of the full-precision model. Extensive experiments
  are conducted, verifying the effectiveness of our defense. Our code is publicly
  available.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: li24e
month: 0
tex_title: Purifying Quantization-conditioned Backdoors via Layer-wise Activation
  Correction with Distribution Approximation
firstpage: 27439
lastpage: 27456
page: 27439-27456
order: 27439
cycles: false
bibtex_author: Li, Boheng and Cai, Yishuo and Cai, Jisong and Li, Yiming and Qiu,
  Han and Wang, Run and Zhang, Tianwei
author:
- given: Boheng
  family: Li
- given: Yishuo
  family: Cai
- given: Jisong
  family: Cai
- given: Yiming
  family: Li
- given: Han
  family: Qiu
- given: Run
  family: Wang
- given: Tianwei
  family: Zhang
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://raw.githubusercontent.com/mlresearch/v235/main/assets/li24e/li24e.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Learning Latent Dynamic Robust Representations for World Models
openreview: C4jkx6AgWc
abstract: Visual Model-Based Reinforcement Learning (MBRL) promises to encapsulate
  agentâ€™s knowledge about the underlying dynamics of the environment, enabling learning
  a world model as a useful planner. However, top MBRL agents such as Dreamer often
  struggle with visual pixel-based inputs in the presence of exogenous or irrelevant
  noise in the observation space, due to failure to capture task-specific features
  while filtering out irrelevant spatio-temporal details. To tackle this problem,
  we apply a spatio-temporal masking strategy, a bisimulation principle, combined
  with latent reconstruction, to capture endogenous task-specific aspects of the environment
  for world models, effectively eliminating non-essential information. Joint training
  of representations, dynamics, and policy often leads to instabilities. To further
  address this issue, we develop a Hybrid Recurrent State-Space Model (HRSSM) structure,
  enhancing state representation robustness for effective policy learning. Our empirical
  evaluation demonstrates significant performance improvements over existing methods
  in a range of visually complex control tasks such as Maniskill with exogenous distractors
  from the Matterport environment. Our code is avaliable at https://github.com/bit1029public/HRSSM.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: sun24n
month: 0
tex_title: Learning Latent Dynamic Robust Representations for World Models
firstpage: 47234
lastpage: 47260
page: 47234-47260
order: 47234
cycles: false
bibtex_author: Sun, Ruixiang and Zang, Hongyu and Li, Xin and Islam, Riashat
author:
- given: Ruixiang
  family: Sun
- given: Hongyu
  family: Zang
- given: Xin
  family: Li
- given: Riashat
  family: Islam
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/sun24n/sun24n.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

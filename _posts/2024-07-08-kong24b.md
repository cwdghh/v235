---
title: Generalist Equivariant Transformer Towards 3D Molecular Interaction Learning
openreview: dWxb80a0TW
abstract: Many processes in biology and drug discovery involve various 3D interactions
  between molecules, such as protein and protein, protein and small molecule, etc.
  Given that different molecules are usually represented in different granularity,
  existing methods usually encode each type of molecules independently with different
  models, leaving it defective to learn the various underlying interaction physics.
  In this paper, we first propose to universally represent an arbitrary 3D complex
  as a geometric graph of sets, shedding light on encoding all types of molecules
  with one model. We then propose a Generalist Equivariant Transformer (GET) to effectively
  capture both domain-specific hierarchies and domain-agnostic interaction physics.
  To be specific, GET consists of a bilevel attention module, a feed-forward module
  and a layer normalization module, where each module is E(3) equivariant and specialized
  for handling sets of variable sizes. Notably, in contrast to conventional pooling-based
  hierarchical models, our GET is able to retain fine-grained information of all levels.
  Extensive experiments on the interactions between proteins, small molecules and
  RNA/DNAs verify the effectiveness and generalization capability of our proposed
  method across different domains.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: kong24b
month: 0
tex_title: Generalist Equivariant Transformer Towards 3{D} Molecular Interaction Learning
firstpage: 25149
lastpage: 25175
page: 25149-25175
order: 25149
cycles: false
bibtex_author: Kong, Xiangzhe and Huang, Wenbing and Liu, Yang
author:
- given: Xiangzhe
  family: Kong
- given: Wenbing
  family: Huang
- given: Yang
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/assets/kong24b/kong24b.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

---
title: Compressing Large Language Models by Joint Sparsification and Quantization
openreview: sCGRhnuMUJ
abstract: In this paper, we introduce a novel model compression technique named Joint
  Sparsification and Quantization (JSQ), explicitly tailored for large language models
  (LLMs). Traditional methods employ either sparsification or quantization individually
  to compress LLMs, leading to performance degradation at high compression ratios.
  In contrast, our JSQ approach integrates sparsification and quantization cohesively.
  As sparsification tend to preserve outliers that is harmful to quantization, we
  introduce a novel sparsity metric to serves as a bridge between the sparsification
  and quantization. Moreover, it is proven outliers in LLMs have significant impact
  but harmful to compression. Current solutions are highly coupled with quantization
  process, which is not helpful to sparsification. To this end, we also introduce
  a search-based activation editor to automatically eliminate relatively useless outliers.
  Comprehensive experiments across various datasets and architectures affirm the efficacy
  of our JSQ framework. Notably, our JSQ achieves 7.96$\times$ computation reduction
  without crashing for the representative model LLaMA. This accomplishment stands
  in stark contrast to the limitations of most state-of-the-art LLM compression methods,
  which typically fail under such extreme compression ratios. Our code is released
  at https://github.com/uanu2002/JSQ.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: guo24g
month: 0
tex_title: Compressing Large Language Models by Joint Sparsification and Quantization
firstpage: 16945
lastpage: 16957
page: 16945-16957
order: 16945
cycles: false
bibtex_author: Guo, Jinyang and Wu, Jianyu and Wang, Zining and Liu, Jiaheng and Yang,
  Ge and Ding, Yifu and Gong, Ruihao and Qin, Haotong and Liu, Xianglong
author:
- given: Jinyang
  family: Guo
- given: Jianyu
  family: Wu
- given: Zining
  family: Wang
- given: Jiaheng
  family: Liu
- given: Ge
  family: Yang
- given: Yifu
  family: Ding
- given: Ruihao
  family: Gong
- given: Haotong
  family: Qin
- given: Xianglong
  family: Liu
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/guo24g/guo24g.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---

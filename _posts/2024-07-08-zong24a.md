---
title: 'Safety Fine-Tuning at (Almost) No Cost: A Baseline for Vision Large Language
  Models'
openreview: bWZKvF0g7G
abstract: Current vision large language models (VLLMs) exhibit remarkable capabilities
  yet are prone to generate harmful content and are vulnerable to even the simplest
  jailbreaking attacks. Our initial analysis finds that this is due to the presence
  of harmful data during vision-language instruction fine-tuning, and that VLLM fine-tuning
  can cause forgetting of safety alignment previously learned by the underpinning
  LLM. To address this issue, we first curate a vision-language safe instruction-following
  dataset VLGuard covering various harmful categories. Our experiments demonstrate
  that integrating this dataset into standard vision-language fine-tuning or utilizing
  it for post-hoc fine-tuning effectively safety aligns VLLMs. This alignment is achieved
  with minimal impact on, or even enhancement of, the modelsâ€™ helpfulness. The versatility
  of our safety fine-tuning dataset makes it a valuable resource for safety-testing
  existing VLLMs, training new models or safeguarding pre-trained VLLMs. Empirical
  results demonstrate that fine-tuned VLLMs effectively reject unsafe instructions
  and substantially reduce the success rates of several black-box adversarial attacks,
  which approach zero in many cases. The code and dataset will be open-sourced.
layout: inproceedings
series: Proceedings of Machine Learning Research
publisher: PMLR
issn: 2640-3498
id: zong24a
month: 0
tex_title: 'Safety Fine-Tuning at ({A}lmost) No Cost: A Baseline for Vision Large
  Language Models'
firstpage: 62867
lastpage: 62891
page: 62867-62891
order: 62867
cycles: false
bibtex_author: Zong, Yongshuo and Bohdal, Ondrej and Yu, Tingyang and Yang, Yongxin
  and Hospedales, Timothy
author:
- given: Yongshuo
  family: Zong
- given: Ondrej
  family: Bohdal
- given: Tingyang
  family: Yu
- given: Yongxin
  family: Yang
- given: Timothy
  family: Hospedales
date: 2024-07-08
address:
container-title: Proceedings of the 41st International Conference on Machine Learning
volume: '235'
genre: inproceedings
issued:
  date-parts:
  - 2024
  - 7
  - 8
pdf: https://proceedings.mlr.press/v235/zong24a/zong24a.pdf
extras: []
# Format based on Martin Fenner's citeproc: https://blog.front-matter.io/posts/citeproc-yaml-for-bibliographies/
---
